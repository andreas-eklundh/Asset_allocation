{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Momentum Overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data needed for computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import Utils\n",
    "from scipy.optimize import minimize \n",
    "import Backtest as bt   \n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET GLOBAL VALUES\n",
    "mu_target = 75 / 10000 # Target\n",
    "w_current = np.array([0,0.4, 0.6]) # current strategy\n",
    "bond = pd.read_csv(\"Data_clean/bond_returns.csv\")\n",
    "stock = pd.read_csv(\"Data_clean/6_Portfolios_ME_Prior_12_2_returns.csv\")\n",
    "bond, stock =bond[[\"Date\", \"10YrReturns\"]], stock[[\"Date\", \"Market Return\"]]\n",
    "stock[\"Market Return\"] = stock[\"Market Return\"] /100  \n",
    "data = pd.merge(bond,stock, how='left', on = \"Date\")\n",
    "RF = pd.read_csv(\"Data_clean/FF_cleaned.csv\")\n",
    "data = pd.merge(data.copy(),RF[[\"Date\",\"RF\"]], 'left',on = \"Date\" )\n",
    "data[\"RF\"] = data[\"RF\"] /100 # assumed this must hold\n",
    "\n",
    "MOMdep = pd.read_csv(\"Data_clean/25_Portfolios_ME_Prior_12_2_returns.csv\")\n",
    "MOMdep = MOMdep[[\"Date\", \"BIG LoPRIOR\", \"BIG HiPRIOR\"]]\n",
    "data = pd.merge(data.copy(),MOMdep, 'left',on = \"Date\" )\n",
    "data[\"BIG LoPRIOR\"], data[\"BIG HiPRIOR\"] =data[\"BIG LoPRIOR\"] /100, data[\"BIG HiPRIOR\"] /100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>10YrReturns</th>\n",
       "      <th>Market Return</th>\n",
       "      <th>RF</th>\n",
       "      <th>BIG LoPRIOR</th>\n",
       "      <th>BIG HiPRIOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-31</td>\n",
       "      <td>-0.025702</td>\n",
       "      <td>-0.0724</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-02-28</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-03-31</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>0.0334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-04-30</td>\n",
       "      <td>-0.017928</td>\n",
       "      <td>-0.0266</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>-0.0619</td>\n",
       "      <td>-0.0179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-05-31</td>\n",
       "      <td>0.035839</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>0.0999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>-0.006376</td>\n",
       "      <td>-0.0190</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>-0.0899</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>-0.035790</td>\n",
       "      <td>-0.0480</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>-0.0491</td>\n",
       "      <td>-0.0676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>-0.018635</td>\n",
       "      <td>-0.0261</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>0.044330</td>\n",
       "      <td>0.0930</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0.043286</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.0354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  10YrReturns  Market Return      RF  BIG LoPRIOR  BIG HiPRIOR\n",
       "0    1990-01-31    -0.025702        -0.0724  0.0057       0.0009      -0.0942\n",
       "1    1990-02-28     0.001547         0.0167  0.0057       0.0439       0.0113\n",
       "2    1990-03-31    -0.002251         0.0246  0.0064      -0.0129       0.0334\n",
       "3    1990-04-30    -0.017928        -0.0266  0.0069      -0.0619      -0.0179\n",
       "4    1990-05-31     0.035839         0.0909  0.0068       0.1079       0.0999\n",
       "..          ...          ...            ...     ...          ...          ...\n",
       "403  2023-08-31    -0.006376        -0.0190  0.0045      -0.0899       0.0136\n",
       "404  2023-09-30    -0.035790        -0.0480  0.0043      -0.0491      -0.0676\n",
       "405  2023-10-31    -0.018635        -0.0261  0.0047      -0.0494      -0.0282\n",
       "406  2023-11-30     0.044330         0.0930  0.0044       0.0784       0.1205\n",
       "407  2023-12-31     0.043286         0.0524  0.0043       0.0792       0.0354\n",
       "\n",
       "[408 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial overlay\n",
    "olay = 0.25\n",
    "# The new Equity time-series:\n",
    "data_ol = data.copy()\n",
    "\n",
    "data_ol[\"Market Return\"] =  data_ol[\"Market Return\"] - olay * data_ol[\"BIG LoPRIOR\"] + olay * data_ol[\"BIG HiPRIOR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu [0.00213848 0.00432316 0.01020772] Sigma [[ 3.53053036e-06  4.63693106e-06 -3.58629318e-08]\n",
      " [ 4.63693106e-06  4.51987323e-04 -1.16761672e-05]\n",
      " [-3.58629318e-08 -1.16761672e-05  1.77650363e-03]]\n"
     ]
    }
   ],
   "source": [
    "mu = np.mean([data_ol[\"RF\"],data_ol[\"10YrReturns\"],data_ol[\"Market Return\"]],axis=1)\n",
    "sigma = np.cov([data_ol[\"RF\"],data_ol[\"10YrReturns\"],data_ol[\"Market Return\"]])\n",
    "mu0 = np.mean(data_ol[\"RF\"])\n",
    "mu_e = np.mean([data_ol[\"10YrReturns\"]-data_ol[\"RF\"],data_ol[\"Market Return\"]-data_ol[\"RF\"]],axis=1)\n",
    "sigma_e = np.cov([data_ol[\"10YrReturns\"]-data_ol[\"RF\"],data_ol[\"Market Return\"]-data_ol[\"RF\"]])\n",
    "print(\"Mu\", mu,\"Sigma\", sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0. , 0.4, 0.6]), array([0.        , 0.46014004, 0.53985996]), array([-0.07340605,  0.56079855,  0.51260749]), array([0.        , 0.70697303, 0.29302697]), array([-0.28954266,  0.85717736,  0.4323653 ])]\n"
     ]
    }
   ],
   "source": [
    "# Test weights:\n",
    "test = Utils.get_weights(mu,sigma, mu_target)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preliminaries\n",
    "mu_vec = np.array([mu_target + i*0.0001 for i in range(-80,40)])\n",
    "sigma_vec = [Utils.mv_analysis(mu, sigma,i)[1] for i in mu_vec]\n",
    "sigma_vec_cml = [0]+ sigma_vec\n",
    "cml = [ mu0 + np.sqrt(mu_e @ np.linalg.inv(sigma_e) @ mu_e) * i for i in sigma_vec_cml]\n",
    "sigma_test, mu_test = [np.sqrt(w @ sigma @ w) for w in test],  [w @ mu for w in test]\n",
    "\n",
    "# plot\n",
    "plt.plot(sigma_vec[30:100], mu_vec[30:100], color = \"black\",label = \"Mean-Variance Frontier\")\n",
    "plt.plot(sigma_vec_cml[30:100], cml[30:100], color = \"blue\",label = \"CML\")\n",
    "plt.plot(sigma_test[0],mu_test[0],marker='o', color = \"red\", label = \"40/60 Portfolio\")\n",
    "plt.plot(sigma_test[1],mu_test[1],marker='o', color = \"cyan\", label = \"Optimal Markowitz Portfolio\")\n",
    "plt.plot(sigma_test[2],mu_test[2],marker='o', color = \"green\", label = \"Optimal Markowitz with RF levered Portfolio\")\n",
    "plt.plot(sigma_test[3],mu_test[3],marker='o', color = \"yellow\", label = \"Risk Parity\")\n",
    "plt.plot(sigma_test[4],mu_test[4],marker='o', color = \"magenta\", label = \"Risk Parity leveraged\")\n",
    "plt.xlim(left = 0.0,right= 0.07)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Standard deviation\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:562: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\andre\\Asset_allocation\\Backtest.py:124: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sigma_roll = np.cov([train['RF'][:-m],train['10YrReturns'][:-m],train['Market Return'][:-m]])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\Asset_allocation\\Backtest.py:124: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sigma_roll = np.cov([train['RF'][:-m],train['10YrReturns'][:-m],train['Market Return'][:-m]])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    }
   ],
   "source": [
    "initial_fits = 3\n",
    "\n",
    "test1, weights1 = bt.backtest_k(ind=data_ol, mu_target=mu_target,m=initial_fits,l=1,K=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_3276\\4048542202.py:15: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = pd.date_range(test1[\"Date\"][0],test1[\"Date\"][len(test1[\"Date\"]) -1 ], freq = 'ME')\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.plot(time,test1[\"R_40/60\"], label=\"40/60\")\n",
    "ax.plot(time,test1[\"R_MV\"], label=\"Mean-Var\")\n",
    "ax.plot(time,test1[\"R_MVL\"], label=\"Mean-Var Leveraged\")\n",
    "ax.plot(time,test1[\"R_RP\"], label=\"Risk Parity\")\n",
    "ax.plot(time,test1[\"R_RPL\"], label=\"Risk Parity Leveraged\")\n",
    "ax.plot(time[initial_fits:], [(mu_target+1)**t for t in range(0,len(time)-initial_fits)],\n",
    "         label = \"Benchmark of 75Bps/Month\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(5))  # Set a tick at the start of every year\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.legend(framealpha=0.05,loc='center', bbox_to_anchor=(0.5, -0.5), ncol=3,prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Cumulative return\")\n",
    "plt.title(\"Entire Period: 1990-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the backtest is less volatile using the momentum overlay. Might be preferable but overall return would be lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.b Adding the cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:562: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\andre\\Asset_allocation\\Backtest.py:124: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sigma_roll = np.cov([train['RF'][:-m],train['10YrReturns'][:-m],train['Market Return'][:-m]])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\Asset_allocation\\Backtest.py:124: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sigma_roll = np.cov([train['RF'][:-m],train['10YrReturns'][:-m],train['Market Return'][:-m]])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Subtract cost in the backtest implementation. \u001b[39;00m\n\u001b[0;32m      6\u001b[0m initial_fits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m----> 8\u001b[0m test2, weights2 \u001b[38;5;241m=\u001b[39m \u001b[43mbt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbacktest_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_ol_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmu_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_fits\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32mc:\\Users\\andre\\Asset_allocation\\Backtest.py:127\u001b[0m, in \u001b[0;36mbacktest_k\u001b[1;34m(ind, mu_target, m, l, K)\u001b[0m\n\u001b[0;32m    125\u001b[0m sigma_roll \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mdiagonal(sigma_roll)[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Get training weights.\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_weights2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43msigma_roll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m weights\u001b[38;5;241m.\u001b[39mappend(w)\n\u001b[0;32m    129\u001b[0m w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(w)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(w),\u001b[38;5;28mlen\u001b[39m(mu))) \u001b[38;5;66;03m# slight format change\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\Asset_allocation\\Utils.py:154\u001b[0m, in \u001b[0;36mget_weights2\u001b[1;34m(mu, sigma, mu_target, sigma_roll)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_weights2\u001b[39m(mu,sigma, mu_target, sigma_roll):\n\u001b[0;32m    153\u001b[0m     w_4060 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0.40\u001b[39m,\u001b[38;5;241m0.60\u001b[39m])\n\u001b[1;32m--> 154\u001b[0m     w_MV \u001b[38;5;241m=\u001b[39m \u001b[43mmin_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_target\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    155\u001b[0m     w_MVL \u001b[38;5;241m=\u001b[39m min_var_rf(mu,sigma, mu_target)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    156\u001b[0m     w_RP \u001b[38;5;241m=\u001b[39m rp_gb(sigma_roll)\n",
      "File \u001b[1;32mc:\\Users\\andre\\Asset_allocation\\Utils.py:59\u001b[0m, in \u001b[0;36mmin_var\u001b[1;34m(mu, sigma, mu_target)\u001b[0m\n\u001b[0;32m     54\u001b[0m constraints \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     55\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meq\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m weights: np\u001b[38;5;241m.\u001b[39msum(weights) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m}, \n\u001b[0;32m     56\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meq\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m weights: np\u001b[38;5;241m.\u001b[39mdot(weights, mu) \u001b[38;5;241m-\u001b[39m mu_target}  \n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m bounds \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m),(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 59\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrust-constr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m w \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n\u001b[0;32m     62\u001b[0m w[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# just for prettyness\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:746\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    743\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[0;32m    744\u001b[0m                           constraints, callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-constr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 746\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_trustregion_constr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdogleg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    750\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_dogleg(fun, x0, args, jac, hess,\n\u001b[0;32m    751\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\minimize_trustregion_constr.py:528\u001b[0m, in \u001b[0;36m_minimize_trustregion_constr\u001b[1;34m(fun, x0, args, grad, hess, hessp, bounds, constraints, xtol, gtol, barrier_tol, sparse_jacobian, callback, maxiter, verbose, finite_diff_rel_step, initial_constr_penalty, initial_tr_radius, initial_barrier_parameter, initial_barrier_tolerance, factorization_method, disp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     _, result \u001b[38;5;241m=\u001b[39m equality_constrained_sqp(\n\u001b[0;32m    520\u001b[0m         fun_and_constr, grad_and_jac, lagrangian_hess,\n\u001b[0;32m    521\u001b[0m         x0, objective\u001b[38;5;241m.\u001b[39mf, objective\u001b[38;5;241m.\u001b[39mg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m         initial_constr_penalty, initial_tr_radius,\n\u001b[0;32m    525\u001b[0m         factorization_method)\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr_interior_point\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 528\u001b[0m     _, result \u001b[38;5;241m=\u001b[39m \u001b[43mtr_interior_point\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlagrangian_hess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanonical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_ineq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanonical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_eq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcanonical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanonical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_ineq0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ_ineq0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_eq0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ_eq0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcanonical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_feasible\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_barrier_parameter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_barrier_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_constr_penalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_tr_radius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfactorization_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;66;03m# Status 3 occurs when the callback function requests termination,\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;66;03m# this is assumed to not be a success.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m result\u001b[38;5;241m.\u001b[39msuccess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\tr_interior_point.py:321\u001b[0m, in \u001b[0;36mtr_interior_point\u001b[1;34m(fun, grad, lagr_hess, n_vars, n_ineq, n_eq, constr, jac, x0, fun0, grad0, constr_ineq0, jac_ineq0, constr_eq0, jac_eq0, stop_criteria, enforce_feasibility, xtol, state, initial_barrier_parameter, initial_tolerance, initial_penalty, initial_trust_radius, factorization_method)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# Solves a sequence of barrier problems\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;66;03m# Solve SQP subproblem\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m     z, state \u001b[38;5;241m=\u001b[39m \u001b[43mequality_constrained_sqp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubprob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_and_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubprob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_and_jacobian\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubprob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlagrangian_hessian\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun0_subprob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad0_subprob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstr0_subprob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac0_subprob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubprob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_penalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_radius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfactorization_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_lb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_ub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubprob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subprob\u001b[38;5;241m.\u001b[39mterminate:\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:132\u001b[0m, in \u001b[0;36mequality_constrained_sqp\u001b[1;34m(fun_and_constr, grad_and_jac, lagr_hess, x0, fun0, grad0, constr0, jac0, stop_criteria, state, initial_penalty, initial_trust_radius, factorization_method, trust_lb, trust_ub, scaling)\u001b[0m\n\u001b[0;32m    130\u001b[0m lb_t \u001b[38;5;241m=\u001b[39m trust_lb \u001b[38;5;241m-\u001b[39m dn\n\u001b[0;32m    131\u001b[0m ub_t \u001b[38;5;241m=\u001b[39m trust_ub \u001b[38;5;241m-\u001b[39m dn\n\u001b[1;32m--> 132\u001b[0m dt, cg_info \u001b[38;5;241m=\u001b[39m \u001b[43mprojected_cg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtrust_radius_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlb_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mub_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Compute update (normal + tangential steps).\u001b[39;00m\n\u001b[0;32m    137\u001b[0m d \u001b[38;5;241m=\u001b[39m dn \u001b[38;5;241m+\u001b[39m dt\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\qp_subproblem.py:510\u001b[0m, in \u001b[0;36mprojected_cg\u001b[1;34m(H, c, Z, Y, b, trust_radius, lb, ub, tol, max_iter, max_infeasible_iter, return_all)\u001b[0m\n\u001b[0;32m    507\u001b[0m rt_g \u001b[38;5;241m=\u001b[39m norm(g)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# g.T g = r.T Z g = r.T g (ref [1]_ p.1389)\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# If x > trust-region the problem does not have a solution.\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m tr_distance \u001b[38;5;241m=\u001b[39m trust_radius \u001b[38;5;241m-\u001b[39m \u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tr_distance \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrust region problem does not have a solution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2796\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2794\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x_real\u001b[38;5;241m.\u001b[39mdot(x_real) \u001b[38;5;241m+\u001b[39m x_imag\u001b[38;5;241m.\u001b[39mdot(x_imag)\n\u001b[0;32m   2795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2796\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2797\u001b[0m ret \u001b[38;5;241m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The new Equity time-series:\n",
    "data_ol_cost = data_ol.copy()\n",
    "\n",
    "data_ol_cost[\"Market Return\"] =  data_ol[\"Market Return\"] - Utils.manager_fee(data_ol[\"Market Return\"] )\n",
    "# Subtract cost in the backtest implementation. \n",
    "initial_fits = 3\n",
    "\n",
    "test2, weights2 = bt.backtest_k(ind=data_ol_cost, mu_target=mu_target,m=initial_fits,l=1,K=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_22936\\3323095644.py:15: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = pd.date_range(test2[\"Date\"][0],test2[\"Date\"][len(test2[\"Date\"]) -1 ], freq = 'ME')\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.plot(time,test2[\"R_40/60\"], label=\"40/60\")\n",
    "ax.plot(time,test2[\"R_MV\"], label=\"Mean-Var\")\n",
    "ax.plot(time,test2[\"R_MVL\"], label=\"Mean-Var Leveraged\")\n",
    "ax.plot(time,test2[\"R_RP\"], label=\"Risk Parity\")\n",
    "ax.plot(time,test2[\"R_RPL\"], label=\"Risk Parity Leveraged\")\n",
    "ax.plot(time[initial_fits:], [(mu_target+1)**t for t in range(0,len(time)-initial_fits)],\n",
    "         label = \"Benchmark of 75Bps/Month\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(5))  # Set a tick at the start of every year\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.legend(framealpha=0.05,loc='center', bbox_to_anchor=(0.5, -0.5), ncol=3,prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Cumulative return\")\n",
    "plt.title(\"Entire Period: 1990-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.c b decreases performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial overlay\n",
    "olay = 0.50\n",
    "# The new Equity time-series:\n",
    "data_ol = data.copy()\n",
    "data_ol[\"Market Return\"] =  data_ol[\"Market Return\"] - olay * data_ol[\"BIG LoPRIOR\"] + olay * data_ol[\"BIG HiPRIOR\"]\n",
    "\n",
    "data_ol_cost[\"Market Return\"] =  data_ol[\"Market Return\"] - Utils.manager_fee(data_ol[\"Market Return\"] )\n",
    "\n",
    "data_ol[\"Market Return\"] =  data_ol[\"Market Return\"] - olay * data_ol[\"BIG LoPRIOR\"] + olay * data_ol[\"BIG HiPRIOR\"]\n",
    "mu = np.mean([data_ol[\"RF\"],data_ol[\"10YrReturns\"],data_ol[\"Market Return\"]],axis=1)\n",
    "sigma = np.cov([data_ol[\"RF\"],data_ol[\"10YrReturns\"],data_ol[\"Market Return\"]])\n",
    "mu0 = np.mean(data_ol[\"RF\"])\n",
    "mu_e = np.mean([data_ol[\"10YrReturns\"]-data_ol[\"RF\"],data_ol[\"Market Return\"]-data_ol[\"RF\"]],axis=1)\n",
    "sigma_e = np.cov([data_ol[\"10YrReturns\"]-data_ol[\"RF\"],data_ol[\"Market Return\"]-data_ol[\"RF\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:562: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\_methods.py:139: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Users\\andre\\Asset_allocation\\Backtest.py:124: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sigma_roll = np.cov([train['RF'][:-m],train['10YrReturns'][:-m],train['Market Return'][:-m]])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\Asset_allocation\\Backtest.py:124: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sigma_roll = np.cov([train['RF'][:-m],train['10YrReturns'][:-m],train['Market Return'][:-m]])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:2848: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n"
     ]
    }
   ],
   "source": [
    "initial_fits = 3\n",
    "\n",
    "test3, weights3 = bt.backtest_k(ind=data_ol_cost, mu_target=mu_target,m=initial_fits,l=1,K=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_22936\\2436538126.py:15: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = pd.date_range(test3[\"Date\"][0],test3[\"Date\"][len(test3[\"Date\"]) -1 ], freq = 'ME')\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.plot(time,test3[\"R_40/60\"], label=\"40/60\")\n",
    "ax.plot(time,test3[\"R_MV\"], label=\"Mean-Var\")\n",
    "ax.plot(time,test3[\"R_MVL\"], label=\"Mean-Var Leveraged\")\n",
    "ax.plot(time,test3[\"R_RP\"], label=\"Risk Parity\")\n",
    "ax.plot(time,test3[\"R_RPL\"], label=\"Risk Parity Leveraged\")\n",
    "ax.plot(time[initial_fits:], [(mu_target+1)**t for t in range(0,len(time)-initial_fits)],\n",
    "         label = \"Benchmark of 75Bps/Month\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(5))  # Set a tick at the start of every year\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.legend(framealpha=0.05,loc='center', bbox_to_anchor=(0.5, -0.5), ncol=3,prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Cumulative return\")\n",
    "plt.title(\"Entire Period: 1990-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_22936\\3834158626.py:18: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_fits = 3\n",
    "\n",
    "test3, w0t,w1t,w2t  = bt.backtest_naive(ind=data_ol, mu_target=mu_target) \n",
    "time = pd.date_range(test3[\"Date\"][0],test3[\"Date\"][len(test3[\"Date\"]) -1 ], freq = 'ME')\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.plot(time,test3[\"R_40/60\"], label=\"40/60\")\n",
    "ax.plot(time,test3[\"R_MV\"], label=\"Mean-Var\")\n",
    "ax.plot(time,test3[\"R_MVL\"], label=\"Mean-Var Leveraged\")\n",
    "ax.plot(time,test3[\"R_RP\"], label=\"Risk Parity\")\n",
    "ax.plot(time,test3[\"R_RPL\"], label=\"Risk Parity Leveraged\")\n",
    "ax.plot(time[initial_fits:], [(mu_target+1)**t for t in range(0,len(time)-initial_fits)],\n",
    "         label = \"Benchmark of 75Bps/Month\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(5))  # Set a tick at the start of every year\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.legend(framealpha=0.05,loc='center', bbox_to_anchor=(0.5, -0.5), ncol=3,prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Cumulative return\")\n",
    "plt.title(\"Entire Period: 1990-2023\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

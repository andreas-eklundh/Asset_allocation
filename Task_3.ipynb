{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Momentum Overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data needed for computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import Utils\n",
    "from scipy.optimize import minimize \n",
    "import Backtest as bt   \n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET GLOBAL VALUES\n",
    "mu_target = 75 / 10000 # Target\n",
    "w_current = np.array([0,0.4, 0.6]) # current strategy\n",
    "bond = pd.read_csv(\"Data_clean/bond_returns.csv\")\n",
    "stock = pd.read_csv(\"Data_clean/6_Portfolios_ME_Prior_12_2_returns.csv\")\n",
    "bond, stock =bond[[\"Date\", \"10YrReturns\"]], stock[[\"Date\", \"Market Return\"]]\n",
    "stock[\"Market Return\"] = stock[\"Market Return\"] /100  \n",
    "data = pd.merge(bond,stock, how='left', on = \"Date\")\n",
    "RF = pd.read_csv(\"Data_clean/FF_cleaned.csv\")\n",
    "data = pd.merge(data.copy(),RF[[\"Date\",\"RF\"]], 'left',on = \"Date\" )\n",
    "data[\"RF\"] = data[\"RF\"] /100 # assumed this must hold\n",
    "\n",
    "MOMdep = pd.read_csv(\"Data_clean/25_Portfolios_ME_Prior_12_2_returns.csv\")\n",
    "MOMdep = MOMdep[[\"Date\", \"BIG LoPRIOR\", \"BIG HiPRIOR\"]]\n",
    "data = pd.merge(data.copy(),MOMdep, 'left',on = \"Date\" )\n",
    "data[\"BIG LoPRIOR\"], data[\"BIG HiPRIOR\"] =data[\"BIG LoPRIOR\"] /100, data[\"BIG HiPRIOR\"] /100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>10YrReturns</th>\n",
       "      <th>Market Return</th>\n",
       "      <th>RF</th>\n",
       "      <th>BIG LoPRIOR</th>\n",
       "      <th>BIG HiPRIOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-31</td>\n",
       "      <td>-0.025702</td>\n",
       "      <td>-0.0724</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-02-28</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-03-31</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>-0.0129</td>\n",
       "      <td>0.0334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-04-30</td>\n",
       "      <td>-0.017928</td>\n",
       "      <td>-0.0266</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>-0.0619</td>\n",
       "      <td>-0.0179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-05-31</td>\n",
       "      <td>0.035839</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>0.0999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>-0.006376</td>\n",
       "      <td>-0.0190</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>-0.0899</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>-0.035790</td>\n",
       "      <td>-0.0480</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>-0.0491</td>\n",
       "      <td>-0.0676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>-0.018635</td>\n",
       "      <td>-0.0261</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.0494</td>\n",
       "      <td>-0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>0.044330</td>\n",
       "      <td>0.0930</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>0.043286</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.0354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  10YrReturns  Market Return      RF  BIG LoPRIOR  BIG HiPRIOR\n",
       "0    1990-01-31    -0.025702        -0.0724  0.0057       0.0009      -0.0942\n",
       "1    1990-02-28     0.001547         0.0167  0.0057       0.0439       0.0113\n",
       "2    1990-03-31    -0.002251         0.0246  0.0064      -0.0129       0.0334\n",
       "3    1990-04-30    -0.017928        -0.0266  0.0069      -0.0619      -0.0179\n",
       "4    1990-05-31     0.035839         0.0909  0.0068       0.1079       0.0999\n",
       "..          ...          ...            ...     ...          ...          ...\n",
       "403  2023-08-31    -0.006376        -0.0190  0.0045      -0.0899       0.0136\n",
       "404  2023-09-30    -0.035790        -0.0480  0.0043      -0.0491      -0.0676\n",
       "405  2023-10-31    -0.018635        -0.0261  0.0047      -0.0494      -0.0282\n",
       "406  2023-11-30     0.044330         0.0930  0.0044       0.0784       0.1205\n",
       "407  2023-12-31     0.043286         0.0524  0.0043       0.0792       0.0354\n",
       "\n",
       "[408 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial overlay\n",
    "olay = 0.25\n",
    "# The new Equity time-series:\n",
    "data_ol = data.copy()\n",
    "\n",
    "data_ol[\"Market Return\"] =  data_ol[\"Market Return\"] - olay * data_ol[\"BIG LoPRIOR\"] + olay * data_ol[\"BIG HiPRIOR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu [0.00213848 0.00432316 0.01020772] Sigma [[ 3.53053036e-06  4.63693106e-06 -3.58629318e-08]\n",
      " [ 4.63693106e-06  4.51987323e-04 -1.16761672e-05]\n",
      " [-3.58629318e-08 -1.16761672e-05  1.77650363e-03]]\n"
     ]
    }
   ],
   "source": [
    "mu = np.mean([data_ol[\"RF\"],data_ol[\"10YrReturns\"],data_ol[\"Market Return\"]],axis=1)\n",
    "sigma = np.cov([data_ol[\"RF\"],data_ol[\"10YrReturns\"],data_ol[\"Market Return\"]])\n",
    "mu0 = np.mean(data_ol[\"RF\"])\n",
    "mu_e = np.mean([data_ol[\"10YrReturns\"]-data_ol[\"RF\"],data_ol[\"Market Return\"]-data_ol[\"RF\"]],axis=1)\n",
    "sigma_e = np.cov([data_ol[\"10YrReturns\"]-data_ol[\"RF\"],data_ol[\"Market Return\"]-data_ol[\"RF\"]])\n",
    "print(\"Mu\", mu,\"Sigma\", sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0. , 0.4, 0.6]), array([0.        , 0.46014004, 0.53985996]), array([-0.07341663,  0.56081306,  0.51260357]), array([0.        , 0.70697303, 0.29302697]), array([-0.28954246,  0.85717709,  0.43236538])]\n"
     ]
    }
   ],
   "source": [
    "# Test weights:\n",
    "test = Utils.get_weights(mu,sigma, mu_target)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preliminaries\n",
    "mu_vec = np.array([mu_target + i*0.0001 for i in range(-80,40)])\n",
    "sigma_vec = [Utils.mv_analysis(mu, sigma,i)[1] for i in mu_vec]\n",
    "sigma_vec_cml = [0]+ sigma_vec\n",
    "cml = [ mu0 + np.sqrt(mu_e @ np.linalg.inv(sigma_e) @ mu_e) * i for i in sigma_vec_cml]\n",
    "sigma_test, mu_test = [np.sqrt(w @ sigma @ w) for w in test],  [w @ mu for w in test]\n",
    "\n",
    "# plot\n",
    "plt.plot(sigma_vec[30:100], mu_vec[30:100], color = \"black\",label = \"Mean-Variance Frontier\")\n",
    "plt.plot(sigma_vec_cml[30:100], cml[30:100], color = \"blue\",label = \"CML\")\n",
    "plt.plot(sigma_test[0],mu_test[0],marker='o', color = \"red\", label = \"40/60 Portfolio\")\n",
    "plt.plot(sigma_test[1],mu_test[1],marker='o', color = \"cyan\", label = \"Optimal Markowitz Portfolio\")\n",
    "plt.plot(sigma_test[2],mu_test[2],marker='o', color = \"green\", label = \"Optimal Markowitz with RF levered Portfolio\")\n",
    "plt.plot(sigma_test[3],mu_test[3],marker='o', color = \"yellow\", label = \"Risk Parity\")\n",
    "plt.plot(sigma_test[4],mu_test[4],marker='o', color = \"magenta\", label = \"Risk Parity leveraged\")\n",
    "plt.xlim(left = 0.0,right= 0.07)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Standard deviation\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n"
     ]
    }
   ],
   "source": [
    "initial_fits = 3\n",
    "\n",
    "test1, weights1 = bt.backtest_k(ind=data_ol, mu_target=mu_target,m=initial_fits,l=1,K=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24228\\4048542202.py:15: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = pd.date_range(test1[\"Date\"][0],test1[\"Date\"][len(test1[\"Date\"]) -1 ], freq = 'ME')\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.plot(time,test1[\"R_40/60\"], label=\"40/60\")\n",
    "ax.plot(time,test1[\"R_MV\"], label=\"Mean-Var\")\n",
    "ax.plot(time,test1[\"R_MVL\"], label=\"Mean-Var Leveraged\")\n",
    "ax.plot(time,test1[\"R_RP\"], label=\"Risk Parity\")\n",
    "ax.plot(time,test1[\"R_RPL\"], label=\"Risk Parity Leveraged\")\n",
    "ax.plot(time[initial_fits:], [(mu_target+1)**t for t in range(0,len(time)-initial_fits)],\n",
    "         label = \"Benchmark of 75Bps/Month\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(5))  # Set a tick at the start of every year\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.legend(framealpha=0.05,loc='center', bbox_to_anchor=(0.5, -0.5), ncol=3,prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Cumulative return\")\n",
    "plt.title(\"Entire Period: 1990-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the backtest is less volatile using the momentum overlay. Might be preferable but overall return would be lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.b Adding the cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n"
     ]
    }
   ],
   "source": [
    "# The new Equity time-series:\n",
    "data_ol_cost = data_ol.copy()\n",
    "\n",
    "data_ol_cost[\"Market Return\"] =  data_ol[\"Market Return\"] - Utils.manager_fee(data_ol[\"Market Return\"] )\n",
    "# Subtract cost in the backtest implementation. \n",
    "initial_fits = 3\n",
    "\n",
    "test2, weights2 = bt.backtest_k(ind=data_ol_cost, mu_target=mu_target,m=initial_fits,l=1,K=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24228\\3323095644.py:15: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = pd.date_range(test2[\"Date\"][0],test2[\"Date\"][len(test2[\"Date\"]) -1 ], freq = 'ME')\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.plot(time,test2[\"R_40/60\"], label=\"40/60\")\n",
    "ax.plot(time,test2[\"R_MV\"], label=\"Mean-Var\")\n",
    "ax.plot(time,test2[\"R_MVL\"], label=\"Mean-Var Leveraged\")\n",
    "ax.plot(time,test2[\"R_RP\"], label=\"Risk Parity\")\n",
    "ax.plot(time,test2[\"R_RPL\"], label=\"Risk Parity Leveraged\")\n",
    "ax.plot(time[initial_fits:], [(mu_target+1)**t for t in range(0,len(time)-initial_fits)],\n",
    "         label = \"Benchmark of 75Bps/Month\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(5))  # Set a tick at the start of every year\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.legend(framealpha=0.05,loc='center', bbox_to_anchor=(0.5, -0.5), ncol=3,prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Cumulative return\")\n",
    "plt.title(\"Entire Period: 1990-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.c b decreases performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial overlay\n",
    "olay = 0.50\n",
    "# The new Equity time-series:\n",
    "data_ol = data.copy()\n",
    "data_ol[\"Market Return\"] =  data_ol[\"Market Return\"] - olay * data_ol[\"BIG LoPRIOR\"] + olay * data_ol[\"BIG HiPRIOR\"]\n",
    "\n",
    "data_ol_cost[\"Market Return\"] =  data_ol[\"Market Return\"] - Utils.manager_fee(data_ol[\"Market Return\"] )\n",
    "\n",
    "data_ol[\"Market Return\"] =  data_ol[\"Market Return\"] - olay * data_ol[\"BIG LoPRIOR\"] + olay * data_ol[\"BIG HiPRIOR\"]\n",
    "mu = np.mean([data_ol[\"RF\"],data_ol[\"10YrReturns\"],data_ol[\"Market Return\"]],axis=1)\n",
    "sigma = np.cov([data_ol[\"RF\"],data_ol[\"10YrReturns\"],data_ol[\"Market Return\"]])\n",
    "mu0 = np.mean(data_ol[\"RF\"])\n",
    "mu_e = np.mean([data_ol[\"10YrReturns\"]-data_ol[\"RF\"],data_ol[\"Market Return\"]-data_ol[\"RF\"]],axis=1)\n",
    "sigma_e = np.cov([data_ol[\"10YrReturns\"]-data_ol[\"RF\"],data_ol[\"Market Return\"]-data_ol[\"RF\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:217: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:316: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(self.x - self.x_prev, self.g - self.g_prev)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:81: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n"
     ]
    }
   ],
   "source": [
    "initial_fits = 3\n",
    "\n",
    "test3, weights3 = bt.backtest_k(ind=data_ol_cost, mu_target=mu_target,m=initial_fits,l=1,K=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24228\\2436538126.py:15: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAGvCAYAAAAaFKJoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzddXhU19bA4d9o3N2NQCA4Ce6uQVtKS0tLvXDrevtRu9T1tqVut9Sx4l5cE0gCBIi7uydj5/vjwNAUDQQSYL/Pkzaz58w5aw6QWdmytkKSJAlBEARBEAShVSlbOwBBEARBEARBJGWCIAiCIAhtgkjKBEEQBEEQ2gCRlAmCIAiCILQBIikTBEEQBEFoA0RSJgiCIAiC0AaIpEwQBEEQBKENEEmZIAiCIAhCGyCSMkEQBEEQhDZAJGWCIACgUCh45ZVXWjuMFjV06FCGDh3aYufLyMhAoVDwww8/tNg5BUEQThNJmSC0UT/88AMKheK8X/v372/2OdetW9fqidc/35elpSXt27dn/vz5FBYWtmpsV1t+fj7PP/88w4YNw87ODoVCwfbt2895rF6v59VXXyU4OBgLCwuCg4NZuHAhBoPhrGMPHTrE2LFjsbe3x87OjtGjRxMXF3fO8+7du5eBAwdibW2Np6cnjz76KDU1NZcU/9atW5k7dy7t27fH2tqa4OBg7rvvPvLz8y/7WtHR0cyfP5/w8HBsbGzw9/fn1ltvJSkp6azzff311wwZMgQPDw8sLCwICgrinnvuISMj45LiF4S2Tt3aAQiCcGGvvfYaQUFBZ7W3a9eu2edat24dixYtOmdiVl9fj1p97X4knH5fDQ0N7N69m88//5x169Zx7NgxrK2tW+QamzZtapHztJTExETefvttQkND6dKlC/v27TvvsbNnz2bJkiXMnTuXiIgI9u/fz4IFC8jKyuKrr74yH3f48GEGDhyIn58fL7/8MiaTic8++4whQ4Zw8OBBOnToYD42Li6OESNG0LFjRz744ANycnJ47733SE5OZv369ReN/7nnnqOsrIxbbrmF0NBQ0tLS+PTTT1mzZg1xcXF4eno2+1pvv/02e/bs4ZZbbqFr164UFBTw6aef0rNnT/bv30/nzp3Nx8bGxhIUFERUVBROTk6kp6fz9ddfs2bNGuLj4/H29r7kPwtBaJMkQRDapO+//14CpOjo6BY757x586Qr+WdfU1NzxTGc7309+eSTEiD98ssvV3yN2traKz7HuaSnp0uA9P3331/W66uqqqTS0lJJkiRpyZIlEiBt27btrOMOHjwoAdKCBQuatD/11FOSQqGQ4uPjzW3jx4+XnJycpJKSEnNbXl6eZGtrK02bNq3J68eNGyd5eXlJlZWV5ravv/5aAqSNGzdeNP4dO3ZIRqPxrDZAevHFFy/rWnv27JEaGxubvDYpKUmysLCQ7rjjjovGFBMTIwHSm2++edFjBaGtE8OXgnCdOz3P6b333uOrr74iJCQECwsLIiMjiY6ONh939913s2jRIoAmw4en/XNO2SuvvIJCoeD48ePcfvvtODk5MXDgQPPzP/30E7169cLKygpnZ2duu+02srOzL/t9DB8+HID09PRmXWPo0KF07tyZQ4cOMXjwYKytrfn3v/9tfu6fc8qKioq499578fDwwNLSkm7duvG///3vrHgqKiq4++67cXBwwNHRkTlz5lBRUXHWcXq9npMnT553CO/v7OzscHZ2vuhxu3btAuC2225r0n7bbbchSRK///57k2NHjhyJi4uLuc3Ly4shQ4awZs0a83BhVVUVmzdvZvbs2djb25uPveuuu7C1teWPP/64aFyDBw9GqVSe1ebs7MyJEyfMbc25Vv/+/dFqtU3OGRoaSnh4eJNznk9gYCDAOf9sBOF6I4YvBaGNq6yspKSkpEmbQqFo8iEM8Msvv1BdXc2DDz6IQqHgnXfeYdq0aaSlpaHRaHjwwQfJy8tj8+bNLF68+JKvf3qo6o033kCSJABef/11FixYwK233sp9991HcXExn3zyCYMHDyY2NhZHR8dmv8/U1FQA8/tqzjVKS0sZN24ct912G7Nnz8bDw+Oc16ivr2fo0KGkpKQwf/58goKCWLJkCXfffTcVFRU89thjAEiSxOTJk9m9ezcPPfQQHTt2ZMWKFcyZM+esc+bm5tKxY0fmzJnTYgsAGhsbAbCysmrSfnpY99ChQ02O/edxp4/V6XQcO3aMvn37cvToUQwGAxEREU2O02q1dO/endjY2MuKtaamhpqaGlxdXc1tV3otSZIoLCwkPDz8nM+XlpZiNBrJysritddeA2DEiBGXFb8gtCmt21EnCML5nB7mO9eXhYWF+bjTQ2ouLi5SWVmZuX3lypUSIK1evdrcdqHhS0B6+eWXzY9ffvllCZBmzZrV5LiMjAxJpVJJr7/+epP2o0ePSmq1+qz2872vLVu2SMXFxVJ2drb022+/SS4uLpKVlZWUk5PTrGsMGTJEAqQvvvjirGsNGTJEGjJkiPnxRx99JAHSTz/9ZG7T6XRSv379JFtbW6mqqkqSJEn6888/JUB65513zMcZDAZp0KBBZw1fnr7/c+bMueD7/qcLDV8uW7ZMAqTFixc3af/iiy8kQOrcubO5rUuXLlL79u0lg8FgbmtsbJT8/f0lQFq6dGmT6+3cufOs691yyy2Sp6dns+I/7T//+Y8ESFu3bj3rvV3utRYvXiwB0rfffnvO5y0sLMz/FlxcXKSPP/74smIXhLZG9JQJQhu3aNEi2rdv36RNpVKdddzMmTNxcnIyPx40aBAAaWlpV3T9hx56qMnj5cuXYzKZuPXWW5v04Hl6ehIaGsq2bdvMw4cXMnLkyCaPAwIC+Pnnn/Hx8eHDDz9s1jUsLCy45557LnrNdevW4enpyaxZs8xtGo2GRx99lFmzZrFjxw4mTpzIunXrUKvVPPzww+bjVCoV//rXv8xDi6cFBgaaexBbyvjx4wkICODpp5/G2tqaXr16ceDAAV588UXUajX19fXmYx955BEefvhh7r33Xp599llMJhMLFy40D6eePvb0/y0sLM66nqWlZZNzXqqdO3fy6quvcuutt5qHn6/0WidPnmTevHn069fvnD2TAOvXr6ehoYETJ07w008/UVtb2+zYBaEtEkmZILRxvXv3PmsY6Fz8/f2bPD6doJWXl1/R9f+58jM5ORlJkggNDT3n8RqN5pLOezrZVKvVeHh40KFDB/N8peZew8fH56x5SeeSmZlJaGjoWfOiOnbsaH7+9P+9vLywtbVtctzfVzJeTZaWlqxdu5Zbb72V6dOnA3KC88477/D66683ieuhhx4iOzubd9991zw3LiIigmeffbbJsaeHOE8Pjf5dQ0OD+XmdTkdZWVmT593c3M76ReDkyZNMnTqVzp0788033zR57lKv9U8FBQVMmDABBwcHli5des5fPgCGDRsGwLhx45g8eTKdO3fG1taW+fPnn/N4QbheiKRMEG4Q5/sAu9JenH9+gJpMJhQKBevXrz/nNf+ZyJzPhZLN5l7jfB/y17Pw8HCOHTvG8ePHKS8vp1OnTlhZWfHEE08wZMiQJse+/vrrPP300yQkJODg4ECXLl3MPYmne1m9vLwAzrkgIT8/31xOYu/eveak57T09HTzhHqA7OxsRo8ejYODA+vWrcPOzq7J8Zd6rb+rrKxk3LhxVFRUsGvXrksubxESEkKPHj34+eefRVImXPdEUiYIN5G/r7a8XCEhIUiSRFBQ0FnDqi3lal0jICCAI0eOYDKZmvSWnTx50vz86f9v3bqVmpqaJglgYmJii8VyKRQKRZPJ7uvWrcNkMp019AuctTp2y5Yt+Pr6EhYWBkDnzp1Rq9XExMRw6623mo/T6XTExcWZ27p168bmzZubnPvv9cdKS0sZPXo0jY2NbN261ZyA/d2lXuu0hoYGJk2aRFJSElu2bKFTp06XdH9Oq6+vP2evnCBcb0RJDEG4idjY2ABXVj5g2rRpqFQqXn311bN64SRJorS09EpCvKrXGD9+PAUFBU1KShgMBj755BNsbW3NPVDjx4/HYDDw+eefm48zGo188sknZ52zOSUxrkR9fT0LFizAy8uryZy4c/n999+Jjo7m8ccfNyefDg4OjBw5kp9++onq6mrzsYsXL6ampoZbbrkFkJO7kSNHNvmytLQEoLa2lvHjx5Obm8u6devOO7x8qdcC+b7OnDmTffv2sWTJEvr163fOcxoMhnMOxR88eJCjR49e0hC/ILR1oqdMENq49evXm3ty/q5///4EBwc361y9evUC4NFHH2XMmDGoVKqzamFdTEhICAsXLuSFF14gIyODKVOmYGdnR3p6OitWrOCBBx7g6aefbtY5r9U1HnjgAb788kvuvvtuDh06RGBgIEuXLmXPnj189NFH5mG4SZMmMWDAAJ5//nkyMjLo1KkTy5cvp7Ky8qxzNrckxsKFCwFISEgA5ERl9+7dAPzf//2f+bhbb70Vb29vOnXqRFVVFd999x1paWmsXbu2yXDhzp07ee211xg9ejQuLi7s37+f77//nrFjx5pLfJz2+uuv079/f4YMGcIDDzxATk4O77//PqNHj2bs2LEXjf2OO+7g4MGDzJ07lxMnTjSpI2Zra8uUKVOafa2nnnqKVatWMWnSJMrKyvjpp5+aXHP27NmAXHrDz8+PmTNnmrdkOnr0KN9//z0ODg4sWLDgovELQpvXWss+BUG4sAuVxOBvZRlOl2R49913zzoH/yhzYTAYpH/961+Sm5ubpFAompTH+Oexp0tiFBcXnzO+ZcuWSQMHDpRsbGwkGxsbKSwsTJo3b56UmJh4Se/rUnYquJRrDBkyRAoPDz/n6/9ZEkOSJKmwsFC65557JFdXV0mr1UpdunQ5Z4X+0tJS6c4775Ts7e0lBwcH6c4775RiY2OvuCTGhf5M/+7tt9+WwsLCJEtLS8nJyUmKioqSYmNjzzpfSkqKNHr0aMnV1VWysLCQwsLCpDfffPOsKvmn7dq1S+rfv79kaWkpubm5SfPmzTOXArmYgICA88YeEBBwWdc6XdLkYveksbFReuyxx6SuXbtK9vb2kkajkQICAqR7771XSk9Pv6T4BaGtU0hSC6/lFgRBEARBEJpNzCkTBEEQBEFoA0RSJgiCIAiC0AaIpEwQBEEQBKENEEmZIAiCIAhCGyCSMkEQBEEQhDZAJGWCIAiCIAhtwE1fPNZkMpGXl4ednV2LbEEjCIIgCIJwmiRJVFdX4+3t3WR7t3O56ZOyvLw8/Pz8WjsMQRAEQRBuYNnZ2fj6+l7wmJs+KTu9XUl2djb29vYtem69Xs+mTZsYPXo0Go2mRc99IxD358LE/bkwcX8uTtyjCxP358LE/bmwS70/VVVV+Pn5Ndke7Xxu+qTs9JClvb39VUnKrK2tsbe3F3+hz0HcnwsT9+fCxP25OHGPLkzcnwsT9+fCmnt/LmWKlJjoLwiCIAiC0AaIpEwQBEEQBKENEEmZIAiCIAhCGyCSMkEQBEEQhDZAJGWCIAiCIAhtgEjKBEEQBEEQ2gCRlAmCIAiCcNMy6HTUVpS3dhiASMoEQRAEQbgJNdTWcODPJXzzr3vZ+u3nrR0OIIrHCoIgCIJwE6kuLeHQupUc2bIBfUM9AAVpyega6tFaWrVqbCIpEwRBEAThhleSlUHMmhWc2L0dk9EIgIuvP5FR0wkbMBiVuvV3Lbhpk7JFixaxaNEijKf+YARBEARBuLFIkkTuiQSiVy8j7XC0ud23U2cio6YT1D3ikrY/ulZu2qRs3rx5zJs3j6qqKhwcHFo7HEEQBEEQWohkMpESs5/olcvIT0mUGxUK2vfuT0TUNLzadWjdAM/jpk3KBEEQBEG4sRj0eo7v/IuY1cspz88FQKXR0HnoSHpNmIKTl08rR3hhIikTBEEQBOG61lhXS/zm9Rxet9Jc3sLCxobuoyfSY+xEbBydWjnCSyOSMkEQBEEQrks1ZaWnVlKuR1cvr6S0dXElYsIUugwfjdbKupUjbB6RlAmCIAiCcF0pzc0mZvVyju/chsloANreSsrLIZIyQRAEQRCuC3lJJ4letZSUmAMgSQD4hHUiMmoGwT0iUCiv75r4IikTBEEQBKHNkkwm0mJjiF61jNyTCeb2kIi+REZNx6dDx1aMrmWJpEwQBEEQhDbHaNBzcs9OolctozQnCwClSk3HQUOJnDQdF1+/Vo6w5YmkTBAEQRCENkNXX8eRrRs5tG4lNaUlAGitrOg6chw9x0dh5+zayhFePSIpEwRBEASh1dVWlBO7YTVxm9bSWFsLgI2jEz3HT6bryLFY2ti2coRXn0jKBEEQBEFoNeUFecSsXk7Cjq0Y9XoAnLx8iJg0jU6DhqHWals5wmtHJGWCIAiCIFxzBanJRK9cStLBveaVlF7tOhA5eTohEX1QKlWtHOG1J5IyQRAEQRCuCUmSyIw/zMFVy8hOOGJuD+oRQe+oGfh0DG9TG4RfayIpEwRBEAThqjIZjSTu20X0qmUUZ6YDoFSpCOs/mIio6bj5B7ZugG2ESMoEQRAEQbgq9A0NHN22mUNrV1BVXASAxsKSLiPG0GvCZOxd3Vs5wrZFJGWCIAiCILSouqpKYjesIW7jGhpqqgGwsneg59hJdBszAStbu1aOsG0SSZkgCIIgCC2isqiAmDUrOLZtCwZdIwCOHl5ETJpKpyEj0GgtWjnCtk0kZYIgCIIgXJHC9FSiVy0jad9uJMkEgEdwOyKjZhDap99NuZLycoikTBAEQRCEZpMkiayj8USvXkbmkVhze2C3nkRGTccvvOtNvZLycoikTBAEQRCES2YyGkk6sIfoVcsoSk8FQKFU0qHfICKjpuMeGNzKEV6/RFImCIIgCMJF6RsbSNi+lZi1K6gsLABArbWgy/DR9JowBQd3j1aO8PonkjJBEARBEM6rvrqKmG2biF2/mvrqKgCs7OzpPmYi3cdMwNreoZUjvHGIpEwQBEEQhLNUlRRRHLOX75f9iKFRXklp7+ZBxKSpdB46Eo2FZStHeOMRSZkgCIIgCGZFGWnErF7Oyb07kUzySkr3wBAio6bRvu9AlCqxkvJqEUmZIAiCINzkJEkiO+Eo0auWkhF/2Nxu5enDmDn3EdwjQqykvAZEUiYIgiAINymTyUjygX1Er1pGYVoyAAqFkvZ9B9Bj/GRiTiTi36W7SMiuEZGUCYIgCMJNRq9r5PiOrcSsXkFFYT4Aao2WzsNH0WvCVBw9PNHr9XAisZUjvbmIpEwQBEEQbhINNTXEbVpL7IbV1FVWAGBpa0f3MRPpMXaiWEnZykRSJgiCIAg3uKqSYg6vW8mRrRvRN9QDYOfqRsSEKXQePhqtpVUrRyiASMoEQRAE4YZVkp1JzOrlnNi9HZPRCICrfyC9o6bTvt8gVGqRBrQl4k9DEARBEG4wOScTiF65lLTD0eY2v05diIyaTmD3XmLifhslkjJBEARBuAFIJhOphw4SvWoZeUkn5EaFgtDe/YicNB2v0A6tG6BwUSIpEwRBEITrmEGv5+Tu7USvXk5ZbjYAKrWaTkNGEDFxGs7ePq0coXCpRFImCIIgCNehxro6jmzdwOG1f1JTXgaA1sqa7qPH02NcFLZOzq0codBcIikTBEEQhOtITXkZh9evIn7TOnT1dQDYOjnTc/xkuo4ch4W1dStHKFwukZQJgiAIwnWgLC+HmNXLOb7zL4wGAwDO3r5ERk0nbOBQ1BpNK0coXCmRlAmCIAhCG5afnMjBlUtJidkPkgSAd/uORE6eQUjPSBRKZStHKLQUkZQJgiAIQhsjSRLpsTFEr1pGzolj5vbgXr3pHTUDn7BOrRidcLWIpEwQBEEQ2gijwcDJPTuIWb2ckuxMAJQqNR0HDSVy0jRcfP1bOULhahJJmSAIgiC0Ml1DPUe3buTQ2pVUlxYDoLWyouvIcfQcF4Wdi2srRyhcCyIpEwRBEIRWUldZweH1q4nftJaG2hoArB0c6Tl+Mt1GjcPSxraVIxSuJZGUCYIgCMI1Vl6Qx6E1K0jYvhWDXgeAk5c3EZOm0WnQcNRabStHeG3pjXo0KrF6VCRlgiAIgnCNFKQmE71qGckH9iJJJgA827Wnd9QMQiL7oFSqWjnCa29jxkae2/kcD3d7mAe7Pdja4bQqkZQJgiAIwlUkSRKZ8YeJXr2MrGNHzO1BPSKIjJqOb8fON/UG4b+c+AWjZOTTuE9RKpTc2elOLNWWrR1WqxBJmSAIgiBcBSajkcR9u4hetYzizHQAlCoVYf0HExE1HTf/wNYNsJX9mPAjKRUpHCk+k6h+HPsxu3N388PYH27KRPWGSMqmTp3K9u3bGTFiBEuXLm3tcARBEISbmL6hgaPbNnNo7QqqiosA0FhY0mXEGHpNmIy9q3srR9j6EkoTeDfmXfNjNys3Hun+CK/vf53DRYcpqC1ApVSx+Phi5oTPwdXq3KtPP4v7DIPJwNzOc7HVXv+LIm6IpOyxxx5j7ty5/O9//2vtUARBEISbVF1VJXEb1xC7cS0N1VUAWNk70HPsJLqNmYCVrV0rR9g21Onr+CDmgyZtPT16MqP9DP5I/IMTZSc4WnKUvXl7WZa8jIrGCv4z4D9nnSevJo/P4z8HYEnSEsYGjuWxno81KzkzSSa+O/YdQ32H0s6p3ZW9sRZwQyRlQ4cOZfv27a0dhiAIgnATqiwqIGbNnxzbthmDrhEABw9PIiZOI3zoCDRai1aOsO3IqMxgzoY5lDWUoVaq8bD2ILcml3FB4wDo4tqFE2UnOFZyjOiCaAC2Z2/HYDKgVjZNWVIqUszfVzRW8Fvib/ja+TInfM4lxxNXFMd/D/+Xb49+y86ZO1t9Behlb5il0+nIyckhKyuryVdz7dy5k0mTJuHt7Y1CoeDPP/8865hFixYRGBiIpaUlffr04eDBg5cbtiAIgiC0iML0VNb89x2+ffQB4jauwaBrxCO4HRMff465H31J99HjRUL2N5Ik8ePxHylrKMPbxpt3B7/LLxN+YdGIRQz3Gw5AZ9fOAGzJ2kJWtZxTVDRWMOi3QXx06KMm50uvlOfpjfAfwX1d7gNgX96+ZsW0KXMTAMP8hrV6QgaX0VOWnJzM3Llz2bt3b5N2SZJQKBQYjcZmna+2tpZu3boxd+5cpk2bdtbzv//+O08++SRffPEFffr04aOPPmLMmDEkJibi7t78cfnGxkYaGxvNj6uq5C5mvV6PXq9v9vku5PT5Wvq8Nwpxfy5M3J8LE/fn4sQ9urDLuT+SJJGdcIRDa1aQfSze3O7fpQe9Jk7Bt1OXU5+FJoxGU4vHfC215N+f9w+9z8q0ldTo5QK5C/osoI9nHwD6efTDYDAAEOYYBkB2dXaT19foa/j22LfojXr+yv6L1/q9Rkq53FMWbB/MKL9RfHP0Gw4VHqK2oRat6uJ13kySiU0ZclI23Hd4s9/npd6f5pxXIUmntpy/RAMGDECtVvP888/j5eV11uqIbt26Ned0TYNRKFixYgVTpkwxt/Xp04fIyEg+/fRTAEwmE35+fvzrX//i+eefNx+3fft2Pv3004tO9H/llVd49dVXz2r/5ZdfsLa2vuzYBUEQhBuXZDJRk51OxfEjNJaXyI0KBbb+wTh16oaFk0vrBtiG6SU9r1ae+dy1VFjyb/t/o1ScPVhnkkwsrFyIDrmgrp/Kj2xj9lnHAVgprKiX6rnV+la6aLrwdtXb1Eg1zLWZS7Am+KJxZRoy+brmayyw4AWHF1Arrs6Mrrq6Om6//XYqKyuxt7e/4LHNjiAuLo5Dhw4RFhZ22QFeKp1Ox6FDh3jhhRfMbUqlkpEjR7JvX/O6KE974YUXePLJJ82Pq6qq8PPzY/To0Re9Wc2l1+vZvHkzo0aNQqNp/W7RtkbcnwsT9+fCxP25OHGPLuxS7o++sZETO//i8Po1VBUVAqDWagkfOoruYyfh4O5xLUO+pi73709xfTHvHXqP2OJYJgdPpqd7T9h25vlZHWcxsfvE876+JrGGDw5/gEEy8NKwl/C39WdZyjK+OvZVk+PqpXoApg2ZRnun9uzdu5f1Gesx+BsY32P8Wec1moy8GfMmViornuz5JB/FfgQnYXjgcKL6R13y+zvtUu/P6RG5S9HspKxTp06UlJQ092WXpaSkBKPRiIdH07/0Hh4enDx50vx45MiRxMfHU1tbi6+vL0uWLKFfv37nPKeFhQUWFmeP8Ws0mqv2Q+tqnvtGIO7PhYn7c2Hi/lycuEcXdq77U19dRdymtcSuX039qZWUlnb29Bgzke5jJmBt79AaobaKi/39SatMw9fW1zxk+OauN9mevR2A7xK+43DxYQDGBo5lRMAIhvoORaM+//nu7Hwno4NGU9JQQrhLOACjgkaZk7IZ7WewNOnMqFiIcwgatYaRASNZn7GeJclLuDP8TjxtPJuc948Tf7A8Zbn5fLvzdwMwPGD4Ff37uNj9ac65m52Uvf322zz77LO88cYbdOnS5ayLtXRv06XYsmXLNb+mIAiCcOOpKi4iZu0Kjv61CcOp+cf2bh5ETJpK56Ej0VjcnJXmzye6IJq5G+cy1Hcon4z4hNSKVLZnb0eBAidLJ8oayogtigXOJGWXwsPGAw+bMx0yHZw6EO4STn5tPvO6zyO+OJ7k8mQAc/X/kQEj6eHeg9iiWD449AFvDXoLAKVCSUFtAZ/EfmI+31sH3yK9Mh2VQkV/7/4tcStaRLOTspEjRwIwYkTTG3u5E/0vxNXVFZVKRWFhYZP2wsJCPD09z/MqQRAEQWie4sx0olct4+TenUgmeYK+W2AwvaOm077vQJSqm29PykuxNWsrANtztrMndw+LTywG5NWML/R5gdnrZlNYV4injSf9vM89gtVYbyBxfwGhEe5Y2Z17gr5CoeDHcT9iMBmw1ljz4dAPmbd1HpNDJpuPUSqUvND7BW5dcyvr09cTWxSLSTKxZNIS3j74NrX6WgLtA8moyuBkmTza1tOjJ/baa9+ZdD7NTsq2bdt28YNaiFarpVevXmzdutU8+d9kMrF161bmz59/zeIQBEEQbjySJFFXmMfKd/9DZvxhc7t/525ERk0noGuPm3Krn+bIq8kzf//QlocAUCvVPNDtATxtPNk0YxPVumqsNdZolOcexju8IYPDG7OI25zFrJf7oLE4dwKsVWnNQ6QB9gGsmbrmrGM6unSkr1df9ufvp6C2AIC71t9FZlUmaoWa94e+zx+Jf/B74u8A5lIcbUWzkjK9Xs9rr73GF198QWhoaIsEUFNTQ0rKmQJw6enpxMXF4ezsjL+/P08++SRz5swhIiKC3r1789FHH1FbW8s999zTItcXBEEQbi4mk5HU6AMcWLmEwlR5CEyhUBLadwC9o6bjEdz6ld2vF0nlSU0eO1k48d6Q98xzwZQKJQ4W555/ZzSYMJkkkqPlraiqyxpY/t4hhszqgGfw5c/Zu6vTXezP329+nFmVCcCc8Dm0d2rP//X9P6aHTie5IpnxQWcvCGhNzUrKNBoNR44cufiBzRATE8OwYcPMj0+vjJwzZw4//PADM2fOpLi4mJdeeomCggK6d+/Ohg0bzpr8LwiCIAgXYtDpOL7rL2JWr6A8PxcAhUpF56Gj6B01HUdPr1aO8PpSrasmt0a+j9tu3YYCBfZa+0sqwmoymlj+7iGKMqubtJdk17B20RHufmcAKtXl1bcf6DOQ+d3n42DhwJKkJSSVJ9Hfuz/ze5wZYevo0pGOLh0v6/xXU7OHL2fPns23337LW2+91SIBDB06lIuVSps/f36LD1cuWrSIRYsWtegcOEEQBKHtaaitIX7zemLXr6K2ohwACxsbuo4cR7HKkmHTpovVqZfh9DZHHtYe590w/HxO7i9okpC5B9gxYV43fn55Pw21esryajE0GtnxWxJDZnXAK+TsnjNJkti3IhXJJBExIQgLKzmlUSgUPNjtQQD6ePVhZ85Obml/y1nbNLVFzY7QYDDw3XffsWXLFnr16oWNjU2T5z/44IPzvLJtmTdvHvPmzaOqqgoHh5tnabMgCMLNorqshMPrVnFky3p09XJNK1sXVyImTKHL8NEo1BrWrVvXylFev5LK5KHL9k7tm/W6tLhiDqxMa9LmGeKAtb0WN387chPLKcqoIvt4GaU5NRzemMmER7qedZ7q0gZiN8lbMZ3cX0CHPp70nhSE1vJMahPkEESQQ9AF4ylIr8Q9wB6lsvXnDzY7KTt27Bg9e/YEICmp6ViymBApCIIgtLbSnGyiVy/jxK7tmIzy9j0uvv5ERk0nbMAQVGr5o09sP3Vlkivk+XihTpc+xzwtrpj1XxwFwMHNCv9wF07uzyd8oA8AHoFnkrLc5AoAsk+UodcZ0WibLgAoy681f99Qoyd+azZ2zpZ0G+F3yfGUF9Sy7O1D2DpZMPs//VCpL3tL8BbRpldfCoIgCMKlyk08QfSqpaTGHDC3+YSF03vyDIK690KhbN0P3BtNVpXcSxVoH3jRY2vKGynLr+HYTnkOWrsIdwbPbI+lrYZBM0PNnTruAXJ5ipMHCjAZ5KlNRr2Jrx7dQVA3V8Y/fKbHrLygDoDg7m7Yu1kRtzmLnJNlzUrKUg8XA+DsbdPqCRlcRlImCIIgCG2FZDKRFhvNwZXLyEs8LjcqFLSL6Etk1DS827e9ydw3iqxqOSnzt/e/6LGbvjlGfmql+XGfqOAmNclMtbUobWxwD5STstMJ2d+lx5ew6/ckMo6VMvLuTlQUyD1lzj42BHV1JW5zFnnJFZiMJpSXuEggNVZe+RnS0/2Sjr/amp2UDRs27ILDlH/99dcVBSQIgiAIF2M06DmxazvRq5dTlitvWK1Sq+k0eDgRk6bh7O3bugHe4PRGPfm1+QD4252dlBn0RkpyanD2tMGgNzVJyJy9bXB0tzY/rly9mrxnnsVmyGA8X3kFG0cLaivk3RSCu7uRmVCKUS8X9D2yLQeA5e8ewsZBTuqcPK1x9bPDwlpNY52B4uwaPAIvXhC2oqiOkuwaFEoFwd3cLvNOtKxmJ2Xdu3dv8liv1xMXF8exY8eYM2dOS8UlCIIgCGdprKvjyNYNHF63kpqyUgC0VtZ0Gz2enmMnYevs0soRti5JktiXtw9rjTXd3btftevk1uRikkxYqa3OWnmZfbyM9V8eRd9oxDPYgU4Dz5QaUSgVRIwPRJIkCv/zH3Q5OehS5Un/tTt2kjZ6DL3nPsdhbTC1FY30nRLM6PvDiducxf4/my4OqK3UAeDkaYNSqcCrnSMZR0rITSw/b1KWmVCKSq3Et4MTabHy0KVPe0csbdvG6ttmJ2UffvjhOdtfeeUVampqrjggQRAEQfin2opyDq9bSfzm9TTWycNWNk7O9Bo/ma4jx2JhbXORM9z4dEYdj217jN25u7FSW7H7tt3mCviXa2P9Rj5e8TE/T/i5yQbf2dVy76S/dQD7V6YR0sMN9wB7TCaJnb8noW+Uy00VpFVSkCb3kkWMDyRiQiAqlZLS73+g/Jdfm1zLon17GpOSUHy5kJl796BycDQPQ/qHu5iTsva9PUg6eGb7RUcPudfNv5MzGUdKOLYjly7DfM9aGJCXXMGaT+JRKhXMXtiPzGNyUh/cvW30kgG02Ky22bNn891337XU6QRBEASB8vxcNn/1KV/Pn8vBlUtprKvFyduX0Q89yn2ffEtk1HSRkJ2yIWMDu3N3A1BvqCe9Mv2Kzpdfm8+uxl0U1RexOXNzk+dOzycLLxnA4Q2ZLHkzBoPOSFpsMRWFdVhYq4kYH9jkNQGdXVBKJgrffZeid99t8pzdqFEEr1qJtl2IHH9MDAoF1CckIJlMuPra4uxtg4W1mn5T22HrbGF+7enkK6y/F7ZOFlSXnSmVcZrRYGL7L4kAmEwShzZkmodU/cPbTu9qi03037dvH5aWli11uqtOFI8VBEFou/JTEoleuYzk6H1wqsC4V/swekfNIKRXb7GS8hy2Zm5t8jilIoUOzh0u+3y/J/1u/r60vtT8fVJ5EitTVgLgXO1jbv9r8UmyjsvHdRnqS8T4QHT1BkrzanD2ssUj0J7ynxZT9q3cgeM46zakujoq163H5b57AbDp0xddSip1+w/QmJhEyaJFuD/zNC733su0Z3ph1Juwttcy4ZGurHjvMB37e5uvr9Gq6D+9HZu+SeDIX3JPXn21joG3hhK3JYvy/FqUKgUmo0TCqVWgjp7WGDcsQz96NBqP1p/s3+ykbNq0aU0eS5JEfn4+MTExLFiwoMUCu9pE8VhBEIS2RZIkMuIOcXDVUnKOHzO3B/eMJHLyDHzDwlsxurat3lDP3ry9AHRx7cLRkqOkVqRe9vkqGytZnrLc/Ph0z1iNroY56+dQo5enK1lW22M4dUxytDyk6B5gR+dIe6TqSgbeKpe7qD1wkKK336Lsp5/lY559Fpe59yCZTHgsWIDK1hYA6z69Kf/5Z6q3b8NULV+jcuUqXO69V67YbyVfy9XXjnvfH4RSpUSXmYmxshLLLl0I6emOvVsaVcX1RK+RewotbTXmnrOhd4QRu1lO0AB83IwUvv46xR99ROiunSitzyxAaA3NTsrs7e2brL5UKpV06NCB1157jdGjR7docIIgCMKNz2gwkLhvF9GrllGSlQGAUqWi48BhREyaiqtfQOsG2IbpTXoaDY3sz99Pg7EBbxtvJgRP4GjJUfbk7cHFyoVb2t/SZG6ZzqgjuzqbEMcQ9EY9RsmIhcqiyWf7N0e/MSdecKYm2dasreZ2haTAVCJPkA/pZAuW1ji6WxFcsY+sYXcB4DB9Gl6vvkru009hLC4BQOXkhNPts+RzKJXmhAzAOjISFAoMefnmtsakJGp27cKiQweU1tbo0tOx6tIFhVJB/iuvUPGb3KNn0aEDfp8tottwX3b9nmx+fczaDAB8OjgS1s+TgM4uxG/NpjS3Bu+Tv2IE7MePa/WEDC4jKfvhhx+uQhiCIAjCzUbXUM+xvzYRs/ZPqkvklXAaSyu6jhxLr/GTsXNp3n6KN6P7N93PidITOFs6AzAmcIx526Pjpcc5XnoctULNzLCZ5tc8v+t5Nmdu5t7O9/Jb4m/U6mtRK9W4W7nT17svk0Mm88uJXwAYZzmO9Q3ryarOQpIk1qevB2BKuymMsB9Hwv4GlMZG/L96nA779mAoKiJ96pn5YpXLlqN2czMnZAAu992H8jzTndROTtj060ftXrnXT6HVIul0ZN//AGpvLyxC2lG7axceLy3AOiJCTsgUChSWljQmJlL0/vuEvfEOx3fno1IrzPtrKlUKht/VEYVCgbW9ln5TQ9Dl5JA6ejUATnfe2SJ/Hleq2UlZcHAw0dHRuLg0nRhXUVFBz549SUtLO88rBUEQBAHqKiuI3biGuA1raKiVe12sHRzpOS6KbqPGY/m3nhPh/DIqMzhUeAiAupo6HCwcmNt5LiZMTY47UHCAmWEziS2KZWXKSvOk/W+PfWs+xmAykFebx/Lk5SxPloct+3j2oU99HzY2bqTeUE9SeRL78/cDcH+X+2lI1JLAcWxrclEY9GQ/9DD6nBwknQ6bIYNRu7lRuXQZpV98CYDT7bfjNHs22qDAC74vvy8+p/qvbRhKSsBkpPCNN+UY8/LNPWhF772P8+zZAFj36YPHC8+TPnkKVes34PLQQ9y2oDcAx/fkcXR7DsNmh2HvYkX9kSMotFosw8KoWr0aTCZs+vfDsn3z9u+8WpqdlGVkZJxzcnxjYyO5ubktEpQgCIJw46koyCdmzQoStm/BoJdrTDl6ehE5aTqdBg9Hrb2y8g03g4zKDPbm7WVSyCS2ZjWd2P9EzydwtHQ86zWVjZUU1hYyd+NcDCZDk+c0Sg1/TPwDW60tqRWpvLT3JYrqirDT2PFSn5eI3RGLl7UXubW5LEtehlEy0sGpA/72/uzNTgHArkYu6Fp/SE4QtUFBeL32HxRKBXX7D6DPkZ93vGUGFsEX3hwc5N4x+7FjAJD0eiSjiZqdO6jbt998jFRXR+lXXwFg1b0blh06YDdmDNUbN1Ky6DN8//sRAJ0GeNNpgLwYoHr7dnIemYfC0pJ2W7dQFx0NgO3IkReN6Vq55KRs1apV5u83btzYZHK80Whk69atBAYGtmhwgiAIwvWvMC2Fg6uWkbx/D5Ik9+J4hoQSOXkG7SL7olSqLnIGAWBTxiae3vE0EhLxxfHmWmHPRj5Ld7fudHHrYj72tf6v8d2x78ioyiC9Mp19+fvMCVlvz96MDRrLf/b9h4e6PUQ7p3YAeNp48u3ob/n66NdMaTcFLxsvYonFz86P3Npc84rLHu49AChNk4ecbRqLCVyyhJptf6GwssL5jjvM87OC166hau06lFaWWHZs/pZXCo0Gl3vuxn78OFKGjwCjEdd58yhZtMh8jHUPOR7XeY9QvWkT1Rs30nDyJJUrVqDLzcXn3XfRZWSQ++RTYDLJKz5X/EldXLz8+l69mh3X1XLJSdmUKVMAUCgUZ1Xu12g0BAYG8v7777docIIgCML1SZIkMo/EEr1qGVnH4s3tgd170TtqOr6dulxwyz7hbL8n/o6EXB5kXfo6ABQoGBc07qyq+lNDpzIyYCT9f+1PcX2xuVft/i7382jPRwGYEDQBa03Tye2BDoG8PvB1QN6xByDMOYz9BfupM8gbgHdz7wZARW41oMbJ1x6rLp2x6tL5rJiVFhY4Tpt6xe9d4+GB91tvYSgswHnuXMp//RVjWRkAVt3keCzbt8d+3Fiq1q0na+695ucL33iDmp27kOrqUDk5YSwvp+idd+T47O2xCA294vhayiUnZSaT/NtNUFAQ0dHRuLqKCZiCIAhCUyajkcT9u4letYziDHmOsUKpJGzAECInTcMt4OLDV8LZJEkiqTwJAGdLZ8oa5IRjWui0sxKysrxaVBoFDm52uFq5UlJfwvbs7QD08epjPu6fCdn5jAscxw/HfzA/7u7WHZPRRHW9XCvOtUvg5b2pZnKYNNH8vf2ECZQvXgyAytHR3O722GPU7j9gTsgAKpYsBUAbEoLfl1+SNnEiUkMDIPeytaWad82eU5aefqZCcENDw3VVMFYQBEG4OvQNDRzbvpmYNX9SVSzXq1JbWNB1+Bh6TZiCvVvrF+a8nhXVFVHRWIFKoeL9Ie9z/+b7ifCI4MU+L5qPkUwSO39L4tjOXCxtNNzzzgCCHIIoqZdXPlqoLJq9H6ZJD07VXk3afGx9qCqpR0KJ0qjDpcflF6i9XO6PP4ak12E3fHiTdm1AAMGrVlL88SeoPdyp3bmL+vh4LDt3xvfj/6Lx9sbjxX9TsOAlAKx7977msV9Is5Myk8nE66+/zhdffEFhYSFJSUkEBwezYMECAgMDuffee69GnC1OVPQXBEG4cnVVlcRtXEPsxrU0VFcBYGXvQM+xk+g2ejxWdufeGFponsRyeYugQPtAIjwj2H7rdmw1tqj+Nh8vLb6YY6cq1TfU6qksrsfL5kxCNTF4IhYqCy6VJEkUH7Bm+ZZYHpn+JJ/lfcBQv6EoFArKsisAsKovxrLjmBZ4h82jtLHB65VXzvmc2tUVr9deBcD5zjupizmE7cABKE4tJHG65RasunShZucuHGfOPOc5Wkuzk7KFCxfyv//9j3feeYf777/f3N65c2c++uij6yYpExX9BUEQLl9lUQExa/7k2LbNGHSNADh4eBIxcRrhQ0eg0V76h79wcaeHLts7y6UbHCzO/txKiytu8rgsr5bu7t1ZlboKe609z/V+rlnXLEitQl8tJ30RuiG8N8SbCI8IAEqPy4sMbIwVqN3bzobe/6Syt8du+LCz2i3DwrAMC2uFiC6s2UnZjz/+yFdffcWIESN46KGHzO3dunXj5MmTLRqcIAiC0LYUpqcSs3o5ift2IZ2aa+weFELvyTMI7d0fpUqspGxJlY2VPLXjKQ7kHwCgg9O5hwqNRhOZR+V9Jx3crKgsrqcsv5bJYydjqbJkgM8ArNRWzbr2kb9yzN/XV+kZEyj3iKUfKeHg7hpAgb0tYsFGC2p2Upabm0u7du3OajeZTOaVGoIgCMKNQ5Ikso7FE71qGZlHYs3tAV17EBk1Hf/O3cQH81VgMBl4cvuTHCw4aG47Xa3/n/KSK2isM2Blp6HTQG/2rUilNLeGulIDk0ImNfvaBemVZB49M1m+PF+ujF9b0cj6z+KRkP+8nbxFod+W1OykrFOnTuzatYuAgKZ7kS1dupQep2qFCIIgCNc/k8lI8oG9RK9aRmGaXChUoVTSod8gIqOm4x4Y3MoR3th25+7mYMFBrNXWjA0aS2VjJb29mk5M3/q/4xSkVWFhLX+cB3Vzw9nbBoDUw8WkHi5mwryuBHY5s0Iz+0QZJ/fl029qO9LiimisM6C1VGNlr8G7nRM2jlr2LJH3jrSqK6Te2oPyTDlBO7ok2pyQKUxGvDp5XPX7cDNpdlL20ksvMWfOHHJzczGZTCxfvpzExER+/PFH1qxZczViFARBEK4hva6RhO1biVmznMrCAgDUWgs6DxtFxMQpOLh7tnKEN4fTWyhNCJ7AS/1eOuv5mvIGTu4rMD9WaZT0GhsA/+i0TI4pNCdlDbV6Nn2bQEONnpzEcuoqdU2OVSjAP9yFgrQq1EoTnY9/R3TEC9Q2qtDrDCRGF4HSkQ5JvxLS0x2fyQta+F3f3JqdlE2ePJnVq1fz2muvYWNjw0svvUTPnj1ZvXo1o0aNuhoxCoIgCNdAfU018RvXcnjDauqrKgGwtLWjx9iJdB8zEWt7sSjqWjpcdBg4U0EfoL5aR35KJQGdXUiLK2lyfK+xAdi7WiGZpCbtujoDRoOJ1Z/Ek5tYbm4/nZAFdnVFY6GiorCO4qxqMo/Jc9Pa5W/CtiYHtaEOg9qak6tiqVE6ojTq6PfdK9gE+lyV930za1ZSZjAYeOONN5g7dy6bN2++WjEJgiAI11BVSTGH1/3JkS0b0TfKRTXt3dzpNWEqXYaNQiPqUV5z9YZ6jpceB6CnR09AHnZc9/kRDDoTnQf7UF5QC0C3EX64+dnSLsKdsp9+pnb/PoKcRpBeLifR5QV15KdUNEnI3PztKM6qxs3fjjFzO1D89lvUHTpMVs+7OF7ghJcuFa8TqzFZWWJVV0S1fSAJ2zIBZ9w05SIhu0qalZSp1Wreeecd7rrrrqsVjyAIgnCNlGRlEL16OSf37MB0qmajW0AQkVHTad93ICp1swdThBZyrOQYBpMBd2t3vG3kDbVjN2Vi0MkrXk/XIwPoOswXe1crqjZuonDhQgCC2Eq/1Vv45f1EqkrqyTi1MtPO2ZIx93fGwd2K2FUnsF/xEWnDTmIslxM2z6T/w8naBW1dKSo7OzLvuw+7vQ1UA6VGZwB8wlyu1W246TT7X9yIESPYsWOH2HxcEAThOiRJErknEohevYy0w9Hmdr/wrvSOmk5At55iJWUbsDZtLSAPXSoUCrmQa3YNIM8dM+rl5Cy4hxv2rnKpi/Jff21yDmXKMTSWlugbjOYkrs/kYCyPbKNwyVIcY2IAMAJKW1tc7p1L+W+/Q2EhKicnvD7/jJOZmQSEVZKXeea8ASO6Xc23flNrdlI2btw4nn/+eY4ePUqvXr2wsbFp8nxUVFSLBScIgiC0DMlkIiVmP9GrlpGfLFeHR6Ggfe/+REZNx7PduUstCGdLLEvkZNlJJoVMQqlo+X0TN2ZsZFnyMgBuaX8LIJeiaKjRo1AqGPdgF9YsisfNz44RszsgmUzoMjKo278flEpshwyhZts2ajZvwl47htIGtTmJc8yLJe/Ff8OpGnMKjQbfRZ9i1b07Knt7nG6/nco1a7AdMgSFhwdkZtLp0Rnse2q/OT6PsLZbLPZ61+yk7JFHHgHggw8+OOs5hUIhti0SBEFoQySjkWPbNhO7biXl+XJviUqjIXzICCImTsXJS8wNOp+F+xeyOXMzv074FW9bbyRJ4rP4z/gi/gtArqo/1G9oi15z8fHFvBv9LgB3dbrLvIH46V4yJ09rAjq7MPu1ftg4aMn/1zzqYmPNVfVthwzBfuIEarZto2rdOlSdPMBdrsLvJJVQ9sLLAFh1744+Px+3f83HdvBg8/VVDg4433EHgLn2qEqrIbSXK8mHSrBz0qBStZ0NvG80l7X35Y1A7H0pCMKNrLGulsMb1pCxcimpDfUAWNjY0H30BHqMnYSNo1MrR9i26Y16VqaspMHYwIaMDcztPJc/Ev8wJ2QAcUVxLZqUxRXF8W70u0hIzGg/g8d7PQ6AUW+iKEPeV9TNzw6Qq/bXx8VRs2MHALqqKlSOjrg/8wxK6zOV+21r8ig6tRd8h4OLUGi1OM26DfennjLvBXkpht7ZCTvXTNr3FnXJrqabdhan2PtSEIQbUU1ZKYfWreTIlvXo6uVkzNbZhV4TptB1xBi0VtatHOH14XjZcRqM8krU3bm7GRM4hrei3wLA19aXnJocEkoTWuRaRXVF/HvXvzlQIG+lFBUSxcv95B6t8oJaVn4YS+2p8hXKLUtI+noTHi88T+3uPeZzWHbtiueCBVgEBwGg8fNDn52Nd/5e6u28CLIpwrK+COcHH8T9icebHaPWUk2/qSFX+E6Fi7lpkzJBEIQbSWluNjGrl3N85zZMRgMAzj5+qP2CueWheViKZKxZDhceNn8fWxjLLyd+wWAy0MujF89GPsvMNTNJKE1AkqQrXhjx4aEPzQmZm5Ubz0Y+C0BjnZ5VH8eZEzIAq+SDGKvKyPv3i+a2wD9+x6pr1ybn9P34vzQkJlL09jt0TPhBblQocLzlliuKVbi6RFImCIJwHctLOsHBlctIjTkzEdsnLJzIqOn4de7G+g0bUKk1rRjh9envSZlBMvDj8R8BmNF+BqFOoWiVWqp11WRXZ1Orr8XBwgFvW+9LOne9oZ68mjz0Jj0pFSmsSZN3w3m85+NMbjcZBwt59CYtrpiaskbsXCzpOcSdgrffwaEqDbWXF4b8fADsxozBskuXs65h2bEjlh07UrNtO9UbNwLgMHkyWl8xh7AtE0mZIAjCdUYymUiLjSF61VJyTx43t7eL7Etk1HS823cEzkzUvlmZJBMHCw7Sw70HWqXWXFoityYXXztf83EHCg6QUJbAzA4zsdZY8+q+V9mesx2Avl592Z8vJ7wqhYrhfsPRKDWEOYdxpOQIK1NX8t3R7/Cw8WDdtHUoFUqK64r56cRPDPMbRnf37ubrGEwGvj76NT8m/EiNvqZJrJOCJ3Fvl3ubtOUmVQDQPtIDv8bjqHJ3YdG+PYG//0bZ//6HNiQEu5EjL9hTZz9xAtUbN2I7bBher716BXdTuBZEUiYIgnCdMBr0nNi9g5jVyynNyQJAqVLTafBwIiZNxcXHr5UjbD16k54v47+kr1dfIjzl1YZfHfmKRXGLGBUwiuK6YuoN9bhau7Indw9RIVGU1Zdh0WBBzO4YKnWVfHfsO+7oeAerUlcB4GPrw3+H/Zf3Yt5jSdIS5oTPwVojDwN3du3MkZIj/HDsBwySgdyaXLZkbiGhNIE/U/6krKGMJYlL+H3S7/jZ+SFJEgv3LzSXurDT2GGhtkCj1DAuaBwPdn2wyfuRJIncJLmgq/LXj8mL3wSA7bBhKK2scH3ooUu6L/ajRmG17S/Unp6i/tx14LKSstTUVL7//ntSU1P573//i7u7O+vXr8ff35/w8PCWjlEQBOGmpquv48iWDRxat5KaMrkyu9bKmq4jx9Jr/GRsnUWF9Q3pG/jyyJf8cvIX1kxdg0qh4n8J/wNgc+aZbQETy+UabacTr7+rM9Tx9dGvARjiO4R3Br+Dtcaal/q9xGM9H8Nea28+dmLwRH45+Qs605n5Xk/teMr8vVqhplpfzRPbnuDr0V+zKWMTy5KXoUDBq/1fZXK7yRescVZd2kBNWSMKkxHro9vN7XYjRzbvxgAaL69mv0ZoHc1Oynbs2MG4ceMYMGAAO3fu5PXXX8fd3Z34+Hi+/fZbli5dejXiFARBuOnUVpRzeP0q4jeto7FO3ufQxsmZnuOi6DZqHBbWNhc5w41PkiSqdFXsyZNXIlbrqvn48Me4WLmcNUQIYKGyYELwBFamrMQonSmJ1M6xHSkVKebH87rPM/eKAeZ5Xqd1cetChEcEMYUxTdrdrdz5V89/0d2tO3M2zCGxPJHxy8ebY3kq4immhk696PvKSpCTb/vqDGy7d8b1oQdRaLVYdel80dcK169mJ2XPP/88Cxcu5Mknn8TOzs7cPnz4cD799NMWDU4QBOFmVJ6fS8zqFSTs3Irx1LwwJ29fIidNo+OgYag1YuL+aZ/EfmLu3TptefJyLNXyJurPRT7HsuRl9PbszXO9n6NWX4ud1o7nIp9jZ9ZOntn9DAAPdH2An0/8THxxPD62PoQ5h533mgadkboqHfN7zOeBTQ8wK2wWi08sxiSZeLHviwz3Hw7A92O/54FND1BYVwhAuEs4szvOvuh7qiyuZ/+faQC4lB7D5dl7mhR4FW5czU7Kjh49yi+//HJWu7u7OyUlJS0SlCAIws0oPyWR6FXLSD64DyQJAK/QDkROnkG7Xn1QKEUl9b/Lqsri+4Tvm7SNDRzLhowN1Bvqae/Unts73s7sTmcSITut3JlgrbFmsO9g3JXumLQmBvgMwFZjy/y/5nNHxztQKBTEbs4i82gJYx/ogqWtnAinxRWz87ckaisamfFcBNGzo1EqlPTz7kdlY6U5IQMIdghm6aSlfHj4Q+KL4nm1/6uolKoLvqfcpHI2fpNAY70B+6p0AisOYjP43Za6ZUIb1+ykzNHRkfz8fIKCgpq0x8bG4uMjltoKgiA0hyRJZMQdInrVMrKPHzW3B/eMJDJqOj5h4WKC9nl8HPsxBpMBBQokJEYFjOLZyGfZmbOTOkMdj3R75ILztjRKDQ/ZPcTo0aOx19ozyHcQh2YfQq1UYzJJxKzLQFdvICm6gK7D/EiPL2b9l0dBzpfJOl6KR5A8z2yAz4BzXsPR0pFX+1/aqseKojrWLDqCodGITW0+nRO+wXHyaJTNqLwvXN+anZTddtttPPfccyxZsgSFQoHJZGLPnj08/fTT3HXXXVcjRkEQhBuO0WAgcd8uolctoyQrAwClSkXHgUOJmDQNV7+A1g2wjcuuymZThrwi8dcJv5JZlUlvr964Wrny5agvya7ObtJrdT5ahbbJ3DG1Uv5YLMmuRlcvF+FNjy0ipIc7m747bk7IAPKO5cOEph0Ul6OhRs/O3xIpSKvC0GjEsSKZbkcW4ThiKO5PPXnF5xeuH81Oyt544w3mzZuHn58fRqORTp06YTQauf322/m///u/qxGjIAjCDUPXUM+xvzYRs/ZPqkuKAdBYWtF1xBh6jp+MvatbK0d4ffjl5C9ISAzwGUC4azjhrmdW/nd3796kPtjlyDleav4+N7mC2E2ZGBqN2FVl0D5lCYd6PkNhZk2LVPTf/cdJkmPkvwtqQx2dEhfj/cKzON958flnwo2l2UmZVqvl66+/ZsGCBRw7doyamhp69OhBaGjo1YjvqhEbkguCcC3VVVYQu3ENcRvW0FArr8SzdnA8tZJyPJa2tq0c4fWjvKGc5cnLAbir49UZoUnbn2n+XpIUxP+VA4Bf7nbcg51QGnXo0VJeUEd1ej7Wrra4tfcEwKTTUbNtO1Y9uqNxdz/r3FUl9ZTl12IySlQW15N4UE7I/LO24J2/h8B/P4aT2A7pptTspGz37t0MHDgQf39//P39r0ZM14TYkFwQhGuhoiCfmDUrSNi+BYNermnl6OlF5KTpdBo8HLWYL9RsXx/9mjpDHWHOYfTz7nfe42orGzm0IZPOg31QKhWYTBJqjZLU2GLC+nliMBgwGSB2fTp5iRX0nBCCm78dy985REWRCQCPwoMUevQGQGWop9OsQbjNmY3dvT9TaR/Moe93kZSlxcJYw92fjqUhOpqkNz8n1aI7XoY/6fP1y2g8PAB5L8vtvySScqioyTAogHfebro6Z+Nw72M4Tp92dW6c0OY1OykbPnw4Pj4+zJo1i9mzZ9OpU6erEZcgCMJ1rTAthYOrlpG8fw+SJH/Ae4aEyispI/uivMgqPOHcCmoL+O3kbwA80fMJ89BhVUk9y949REhPdwbPbA/Ajl8SSY8vIfNYKXUVjRgNJiysNTTU6onfmk1dZSNqG0vyq7OQFEpyP47H01NpTshcShPoQTSpyZlk+Y0gpHI/bve8jtLCAndHA5UmSMqSk+pGlS0b7/mIcpMjVb5zkBQqik3d0Nz3Ip1fvB9N916s/ugwhVlyvTnbmhyUJj0KkxH34li6jmuH59OLr/XtFNqYZidleXl5/Pbbb/z666+89dZbdO3alTvuuINZs2bh6+t78RMIgiDcoCRJIvNoHNErl5J1LN7cHtS9F5FR0/Ht1EWspLxMcUVx/JnyJ3ZaO/QmPT3cezTpJUs8UEBdpY6j23IICHdBa6kiPV4u01RVXG8+rqFWrvtWW9EIgL5GA3/7IykokBOydinLCCGJoNWrcFm3ji5xcTg+cSdKCwsAut/eh5QfS5D+llxn2EeYv7e1V1FTBbEe02h86n0quk+g0OiHWl9L9yOLcFJXoQ0IQGFpidPTt2I3dmwL3zHhetTspMzV1ZX58+czf/580tPT+eWXX/jf//7HCy+8wODBg/nrr7+uRpyCIAhtlsloJHH/bqJXLaM4Qy76qVAqCRswhMhJ03ALuPIVeje7Z3c+S35tvvnxxOCJKBQKCtIrObYjl4z4YvNz2385ibWt/PFmWV9Mg5Uban0d/tlbqLN2xydvF3leAyh3DKXBSl5YEUwymQY/jGpLFCYjPZ+ejsvwgSi1WhynT8dx+vQm8bgP7EG7XZtIzgS1woBBkq/nZtfAqKeGYOdsyZqPY8lNgaNdHgIjIJnoVbGWsA/+D5v+/VCoRG+p0NQVbUgeFBTE888/T7du3ViwYAE7duxoqbgEQRDaPH1jA8e2bSZmzZ9UFctV29UWFnQdPoZeE6Zg73b2JG+h+eoN9U0SMoDh/sPR64xs+jqB6rIGc7u2sYKaMkdqyhpRGnX0jPuIcqcwbGtycdTUYMytwuP552lXW4POy5k/1xmRFCp6PToR5TdbSanzxV3Kw23snIvGNfjRYVisTKF9Hy+2fRtHQ52RcS8Mx85Z3k1g0hM92bc8lSN/ZSNJ0CnESM9PPhZ1x4TzuuykbM+ePfz8888sXbqUhoYGJk+ezJtvvtmSsQmCILRJ9dVVxG5YQ+zGNTRUVwFgZWdPj3GT6D56AlZ29hc5g9Ac8cXxTR772fnhauXKgVVpTRIy69p82qWu4EjXR+Tjcv4iaMFTOPzvR6xHDMb9uWcxlleg8ZCTZb1ej0vBOrp07IZ7Jx+GvjQNuy8202nGpW36bWmjYcjtHQG47T+DTy0kONP7pVIpGXhLKJ0GeFOcXU1ohDtKldiVQTi/ZidlL7zwAr/99ht5eXmMGjWK//73v0yePBlra+uLv1gQhMtSWl/Kgj0L6OPVhznhF/8NXrg6KosKObT2T45u24ShUZ6T5ODuQcTEaYQPHYHGwrKVI7wxHcw/CECERwSeNp7c0fEO6qt1xG3OAiAk9U+q7APwLY3GN9yZysz11Nj60aWLGscZM3CcMcN8LqVH095LS08I7SfvRmPhaEv/5y++Wfi5KFVKzrd2w9nbBmdvsXm8cHHNTsp27tzJM888w6233oqrq+vViEkQhL8xmAzcv/l+ksuT2ZW7izs73XnBrWOElleUkUb0qmUk7tuFZJIngrsHhhA5eTrt+wxAKeYGXRVGk5H/7P8Py5KXARAVEsXUUDlp2rciBYPehF11Jv55f6HINuJ8zz24PfE46pdeRpe+F59nP23N8AWh2ZqdlO3Zs+dqxCEIwnmsTV9Lcnmy+XFGVQbBDsGtGNHNQZIkshOOEr16GRlxh8zt/l260ztqBv5duomVlFfZlqwt5oTMQmVBf+/+ANRV6Ti6JQNQElSwneBlS1G7uKBydkahUuH9lphKI1yfLikpW7VqFePGjUOj0bBq1aoLHhsVFdUigQmCICcGscWxWOitGZR+C/n2qSSUJDRJynbm7MTd2p0w57BWjPTGYTIZSYneT/TKpRSkysmwQqGkfd8BREZNxyO4XStHeOPTGXVsz97O0zueBmCI7xAW9F2Ah41chHXPj7HojUpsq7MIf3AilmHi775wY7ikpGzKlCkUFBTg7u7OlClTznucQqEQ2xYJQgt5K/ot1latRVWnZvzJB/GoCaRdaU+OFR9gUsgkAJLKk5i3dR7uVu5suWWL6Lm5AgadjoQdW4lZs5yKAnmln1qjJXzYKCImTsXRw7OVI7x5fHvsWz6L+wwAa7U1CwcsxNHSEYCSzAqSjtaAQkE322ScblnYipEKQsu6pKTMdGoOxT+/FwTh6vkj+Q8AQvMi8KgJNLenZmVDX/n7fXn7ACiqLyKnJgc/O79rHeZ1r6GmhvjN6zi8fhV1lRUAWNrY0n3MBHqMnYS1g2OrxnezkSSJlSkrzY+f6/0cjpaORH+3m7iDNdhaGUFhhVtFAuEfPyZ+ERFuKM2eU/bjjz8yc+ZMLE5VNT5Np9Px22+/cdddV2dzWEG4mdTp60AClaTGu6rpcFlVjp56Qz251bkczD9Il/whVFoWk1CSIJKyZqguLeHQ2j85snUj+ga54rudqxsRE6bQefhotJZWrRzhzSm+OJ7cmlys1dZsn7kdK7UVkiRx8KAO0FJ2qjh/WITLOTf7FoTrWbOTsnvuuYexY8fi/o9/DNXV1dxzzz0iKROEFpBdnc2w1NsJLOuKQpJ7AmyUJdSaXHGq8uLF3S+yOXMznlVBTMl4nEZVHceKjzE2SGzVcjGlOVlEr1rGid3bMZ2abuHqH0hk1HQ69BuESn1FNbWFSyRJEuWN5ThbOjdp++XkLwCMDBiJlVpOjIt2x531+rC5469JnIJwLTX7p48kSefsLs7JycHBwaFFghKEm11OdQ4divs0aetsvZEDNXfgXuvPn5n/BcCnUt542cJozZGsTOh9zUO9buScTCB65VLSDkeb2/w6dSEyajqB3Xu12jCYwWQgtSIVTxtPHCwcqNXXYqO5sWtaVemq+NfWfxFfHM+HQz9kmP8wAD6L/4z16esBmB46HX1hEbmPPUZysQOE3mp+fZhjPlpnx9YIXRCuqktOynr06IFCoUChUDBixAjUf/tt0mg0kp6ezlixoaogtIis0hzgzFCkVlFNsOV+DtTcgUutL5Z6G7yq2uFXeWbVWUV2A0aTEdX5KljehCSTidRDB4letYy8pBNyo0JBaO9+RE6ajldoh2sThySxNWsrHZw7NBlizq/JZ9baWZQ2lGKttqa9U3uOlhzlv8P+yxC/Idcktmttc+Zm3o95n9yaXACe3/U844PHU1Zfxl/Z8t7JL4X+C68vVpO+fQfpqjBSQuXir716qWnf3w+H9oNbLX5BuJouOSk7veoyLi6OMWPGYGtra35Oq9USGBjI9H9s2NqWLVq0iEWLFonVokKbVJBfiv3fkjK1Qo+TVRUoGtGYLBiZPAffyqYJhX2VB2mVaYQ6hV7rcNscg17Pid3biFm1nLK8HABUajXhQ0bSa+JUnL19rkkcJ8tOsiljE86Wzrwd/TbBDsGsnHJmEvuatDWUNpSiVCipM9QRVxwHwDdHv2lTSZnBZGB16mraO7cn3CX8ss+z+Phi3ol+BwBbjS01+hrqDHUsTVpqPubRHo/S77vjVGzYQIlzOCldz1TjD53QE2dv27POKwg3iktOyl5++WUAAgMDmTlzJpaW1/d2IvPmzWPevHlUVVWJYVehzSkvquXvuyf6aI+hiJyDZWEuDbrgsxIyALdaP46VHLupk7LGulqObNnA4XUrqSkvA8DC2oZuo8fTc1wUNo5O1yyWBkMDj/31GHm1eea2tMq0JlNAtmVvA+C5yOcoqC1gf/5+TpSdIK44jpTyFNo5tX5NtHpDPc/seIYdOTuwVluzYvIKvG29L/n1RpOR8sZyUitSzQnZ7I6z+VePf7E0aSnvxrxLmHMY/b3742vny0RjZ5K3fE5OwHjSgyYA4Opny4Dp7XARCZlwg2v2nLI5c8S+e4JwtdWVGgCwtUgiSJVMpNNa6PwbrhuWk6NrWs3fS5NAvj4c11pfEkpizdvQ3Exqyss4vH4V8ZvWoauvA8DW2YVe4yfTZcRYLFphb97Fxxc3SchOK20oxdXKleK6Yo6WHAXkSe3u1vLiqSe2PcGWrC2sTF3JUxFPXdOY/0ln1PHYX4+xL18uvVJnqOOFXS/w2oDXCLAPuOjr9UY9D299mOiCaPPxk0Mm82TAPZT8520GxsbS78V3CYwcgUalwVhVRda995EWNIlcH7mn0NJGw5QnemBhrbl6b1QQ2ohmJ2VGo5EPP/yQP/74g6ysLHQ6XZPny8rKWiw4QbgZNRgaUFRrAfDTxjHY5lew8QGPcHzUn5Bz+kBFA7e7PIWtspSvi3/EwmjFkcws6NdqoV9zuqoKtn6ziJO7t2M0yImss48fkZOm0XHQUFTq1vkg1xl1fH/sewCs1FbUG+rNz6VXpuNq5cqGjA0AdHXtak7IAIb4DWFL1hZOlJ24tkGfwyexn7Avfx9Waite6P0Cbxx4g8NFh5m2cho/jP2BLm5dLvj6Nw6+wYH8A4D8vm3qJe74MZuU3cPgdM3Lu58gw8MDlYszhqJiGsurKeh/DwCOHtYMvq29SMiEm0azdzV+9dVX+eCDD5g5cyaVlZU8+eSTTJs2DaVSySuvvHIVQhSEm8vqtNXY1bsA4KWUK8vj2h5UGlydz8yBtNFm4aTOQ6NsxEmTCkBdroTOqDvrnDeavKQTrPnwLbLWLCFh+xaMBgPeHTox5dkF3P3eIjoPG9VqCRnA3ry9VOurcbdy581Bb2KrOTPsllGVQXZ1Np/GyptlTwie0OS1gfaB8nGVGdcq3HPSGXWsSFkBwMIBC5kaOpXvx35PN7du6Ew63o5+G0mSzvv69Mp0liYtRYECO60ddnUS7/ysgp0HwWRC2y7EfKyhsJDG4ycwlpRQ3H40RpUFjh7W3P5KH/w6Op/3GoJwo2l2T9nPP//M119/zYQJE3jllVeYNWsWISEhdO3alf379/Poo49ejTgF4aZgkkz8mPAjAxrkaQKWlvWYQkainPAutQcOYm97pmhzgDJD/sa1A/5ViZTpOuJa5UdiWeJFezCuR5LJRFpsDNGrlpF7MsHcHtyrN72jZuAT1qnVYvv5xM/8mfIn93a+lzGBY9iYsRGA0YGjGeE/gmEzh/HR94tZ2/AHGZUZbMzYSJ2hjp5uPelZNZS/fjyBi68tHft7YZHnDJKCwrpC6vR1WGuu/dAryPPdKhsrcbd2Z4T/CAA6u3bmg6EfMHHFROKL49matZWRASPP+fqfjv8EwFRlL8bmepCydx1uxTrUnp74fPopx9KtyIjOpmPiT3gO6YHWz4+8CiuSD6pBb6LzYB9RrV+46TQ7KSsoKKBLF/kHvq2tLZWVlQBMnDiRBQsWtGx0gnCTOVx4mLyyQmx1jgDUuPhjvO1zSr/8ipJPP0Xr7YS6QxQGyQoXbTbc/gd4dcPzjblQBx7VgaRUpNxQSZnRoOfknp1Er1pGaU4WAEqVmrCBQ6ixdWLirDvQaFqvV6y8oZyPDn1Eg7GBZ3Y+w58pf3K46DAA3cuGsvTtGBzcrLCI8WOScj7f2j0LgFapZb7z82z9/qT5XMd25FJRWEefkLEccF9PZlUmHV06XvP3lFiWyIeHPgQgKiSqSZkVd2t3ZnaYyQ8JP7Ate9s5k7LKxkpWpa7Cs0xi5s9HUNTUEXH6ySffZt3aegrTCwHQh91LrY8bjTUGju/Lw2Qy4R/uQufB12aFrND6DEYTu1NK6OrriLONtrXDaVXNTsp8fX3Jz8/H39+fkJAQNm3aRM+ePYmOjj5r6yVBEJonuiCaToUDUKDEWZ2J3sae2h07KPlUHurS5ZXj0/EY2cYe+Hg2QPsxNCQm4uIIlINznTe55Ymt+h5aiq6+jiNbN3Jo3UpqSksA0FpZ0XXkOHqOj8LSzoF169a1yLX25e3jyyNfcmenO829Qpfqt5O/0WBswNXKlYrGCvbk7QGgh2Vv0tfWY9SbKEyvAkBjskAhKZAUEneF30XZoaYleSoK5UUKnXIHEe26kYyqjGuelBlMBh7Z8ghF9UX42Ppwe9jt1FY2sPfzXXiEONL1lkj6ePXhh4QfiCuKO+c5tmRuQVlbz4LlKhQ1daBQIEkS+aMe5eS6mibHVhTWcWh9pvlx+94eDJ/TEZWq2bNrhOvMtsQiiqoaiM+p5JcDWWhVSgaFunLvwCD6t3Nt7fBaRbOTsqlTp7J161b69OnDv/71L2bPns23335LVlYWTzzxxNWIURBuGjF5h+iSL88x6m75J2W67tRs/avJMX2qvmRQgAaHwOE0pqeTPuMWtE5a6FqK0uBCcVbtdV3Zv7ainNgNq4nbtJbG2loAbJyc6Tkuim6jxmFhLVe71+v1V3SdRXGLSKtIo5tbN96NeReQe3gulpRlVmWyLGkZt7S/BSuNFT+f/BmFpOTp8Ofo4N2Ob459Q5hTGM47upKtrzjr9baNzvh4uzEn9B5+/17uURtgsY9DxggaDBpUGLFosCGktEeLzyuTJMm8+vN84oriKKovwsHCgd8n/k5Dej2/fbSVBqxISq/EePB9Os4dgQIFWdVZlNSXmM8XVxTHF/FfsDd3Ny/8acKt2IjetwOaJxdiyMvjZIz8kRM+2IfI8YEkxxSyZ2kKLj62eAbb4+xtS5chPiiUYtjyRpZVWseXO1P5+UBWk3ad0cTWk0XsSi5h93PDcLe3xGSSUF7Fvw8Go4nHfo9jWg8fhoe5t/qQebOTsrfeesv8/cyZM/H392ffvn2EhoYyadKkFg1OEG4mjcZGSlMasNE7YKEqwzr2GNL6VKpPFTi2DA+nISEBXTG4hRSARzjVGzeBXo+uSI+NIotaXKguuj4n+pfn5xKzegUJO7diPJVwOXn7EjFxKp0GD0d9BUOUZQ1lZFdn082tGyAPz30R/wUAmzI3mY9LqUghsyrzvOUedufu5uEtDwOQVZ2F3qSnsrGSqZnzydivxaKvjtduW0hDjZ7FR/eBAryC7MhPqzaf4y6v+7hn/C2k7C3BoDdhVVeIdvtPdLfcgM7GjTK7IDICJxBY1pX0qvTLfs/n8m7Muyw+vpgvRn7BAJ8B5zxmR84OAAb5DKJidzrrf8vHqLJCZWzEqLJgf0U4Gc+tYp6HI5/3KyO+KJ4RASMoqivisW2PUV1dSv8kie7pEtVOQRzp/BiNq4pQqbWAiR6j/ek/Ta6/1n2kP4FdXbFzsRQ9YzeJjQkFzPv5MAZT00Uit0b4cs+AIJ5deoSjuZX8uC8TNzsLFq49zjszujK1h+9ViWf1kTzWHslnT0oJe54bjo1F6+59e8VX79evH/363URr8AXhMpQ1lGGSTCSXJ7MkaQmzO86mp0dPJEkipjCG2KJYCmoLcKuQk4EgzSHqcrUoODW8pVDgOu8Rch6ZR22RFQ0VaipWnKRqT6z5Go51xdRqQF8h91gEOQThYNH2CyMXpCRxcNVSkg/ug1Or+bxCOxA5eQbtevVBobyyD2ujyciDmx/kZNlJPhj6Ad423jy367kmx4wPGk9FYwV78/by/bHveaLXE2fdu7SKNJ7afqZu2NasrQD41IbgkS8X7E3cX4BKrcTWSZ7K4aYpJ/TXf2Pt2psy546UO3Wgt3YAVXk6di9JBsA7fx8KwLqhBOuGEoynPqy8qjw5WLnvit57k/gr01h8fDEAK1NXnjcp2569HYAh3gPZtTABo4UXTvVZjH2oK9s315CfB3neA/HLbuCW3X8S1zWO4f7DWbBnAYP/KuH2HXKpC6NSw7GIx2hskN+P0WBCpVbSfaR/k+s5urfOQgah5eRW1ONuZ4HmVGJ9Ir+K73anozOauKWXHwNDXfn3iqOsjsvDKEkYTBK9A52ZP7wdSoWCPaklPDI0BDtLDY8MDeHhnw/z6bYU8/kXrjmBm60lga7WuNpacLKgmm6+8r/P/25NZkVsLtUNBgaFuvLi+I64219acXujSeKTrfJ17h8U3OoJGVxiUrZq1apLPmFUVNRlByMIN6JGYyO3rLoFnUmHVqWlqK6IzZmbeXfIu2xI32D+cAeYWiVPAfCUjjc5h9rNDduBA1FYWGCsayQvsSeN6VubHGNXVQkuoK6x4s71dzImcAzvDXnv6r/ByyBJEhlxh4hetYzs40fN7cE9I4mMmo5PWHiLDSOsS1/HyTJ5Mv2T259s8tyTvZ6kzlDHMP1kdu9IINe2kmXJy/gr6y9WTVmFo6UjIJe4eHnvy9QZ6oj0iKSoqJxMk/zDPKr8PiTAyl5LfZWO47vPFIx1jV+Fur6SgOzNGFUayp06UHSygBP7CjHoTDiXHce/cBehu3ZS8vnn1B9LwMMjEPRgrXcjtTSNal01dlq7K74Pn8d9bv6+Vl97zmPii+PJqMrAoUGF1/+SSLXohsJkIOr1Cdj6ujG1r0TKoSI2fZNAtu9wBh05xM8Zh9nqthXF5t3mhAwgN2Q09XoNds6WuPjaknGkhA59PbG2v7knct9otiUWce8P0QS72fLG1C5kldXx8spj1OrkXyjXHslnUKgr2xKLza/p6e/Iz/f3MSdxA0PPDKePDveknbstKUXy3EOFAkprdcz+9gCO1hp8naw4llvF9J6+zOrtx0dbks2vXRmXR1JhDX882Bc7y3P3rJ8sqEKrUhLsZsuaI3mkldTiaK1hTv/Alr41l+WSkrLT+15ejEKhEHtJCsI/RBdEU1RfdFb7wv0LqWysRK1UMypgFI4KF+z3y70ILvpsyv92rEVoKAqtFsuOHamPi6Mx3VxCFqWDA6bKSixKysAF7BvlH3AbMza2uaTMaDCQuG8X0auWUZKVAYBSpaLjwKFETJyKq39gi14voSSBDw59cFZ7O4d2jEi8C8vl3gSHOrJtRxKgYZD1DDKdEihvLOe3xN94qNtD7M3by8NbHsYkmWinDWP88YcoTKrhgP9qVFoFUrY1SqWCaU/3ZNfvyWQllAKgNjbgVhKPys0VY3EJNrUFAKSelAvJanWVhB//HqdpUajd3PB86SUAavbsQf1dGQaNDfZ1rhwqPMRQv6FXdB8kSWJv3l7z47SKtLOOaTQ2smDPArR6iYVLvInzdAFbCPTSYevrBsg/40MjPEiLKyYlpohStwEEb/mTP7Pf5JG1ckLmeOutmGzsyc7rAY0QOTGI0Ah3UmOLCep2c07evpF9vi0VkwQpRTXc+uWZnt0+Qc44WGnYdLzQnJD18HdkRJg7t/X2R6NUQMoWqDtVcH7LK+ARjiqgP0tnTuDPDA21OiN+ztY8+qs8IlBRp6eiTp7asOxwDssOyz8HR3fyYO7AIOb/EsuJ/Coe/ukw390dSXJRNWW1OgaFulGvM/L2hpP8sDcDS42StY8O4uf98py2Of0CsW0DvWRwiUmZyWS6+EGCIJzTjuwduFf7o0CJU50nA4uj2OO2mhPu+1BJamYY7icyeQh1VY3kShXYqwpQq9yBTPQODtiHdcDjxX8DYNm1C/VxceZz20+ciNNtM8l+6GEsquQffI71HkRkjyXD6VgrvNtz0zc0cPSvjcSs/ZPqEjlOjaUVXUeMoef4ydi7ujX7nAaTgRJjyXmfz6nO4e4Nd9NgbCDIIYiHuz3M5/Gfc3+X+wmv7sv6DUcpo5ayvDO9RrZ1zrzW4R1eSnqWX078go+tD+9Ev4NJMjHBK4rwXRMoLJZ/g++TdWYObc9wAzWv/5seo2dQnm+JjaoO3w0fY2FvTcj69TQmJqJYuZOEv+XmYYm/4NinB+7PPtMkbqvOnbGp/Z1Kx3Z4VXhxIP/AFSdlJfUlVOmqzI9za3JpNDZioTqzYn5lykrSK9OZfdiWFL97abRwQqs20fehYWedr0MfT1JiiihzCqN3XD39D9ejMYLV8KF4vPQSJ/YV0PhzIg5uVnTo44FSpaRDH88reg9C23Mst5KDGXJS1SvAiczSOiw1Sm6L9OP+wcGoFAq+2JHK+mMFOFpr+PquCKzRwcHP4cRqyI1pesKqXEjehKPFB9z98F5wDIKGKno8O4zyOh0zvtiHzmDi7v6B/LA3w/yyu/oF0jfYhe/vjmTmV/vYnVLChI93kVpcg0mCu/oFsCelhNRi+d96g97ElE/3UN1oQKmAWb2bDqm3praRGgrCDUqSJPamHyAq4VHUkgaDUo/apGFI9W1YGKwJLYnAsc6bZArNr/HXxtJYJa8wrOzbl47vvWuuw2XVpYu5B82iQwd83pNXDVr37o1uh1yKQWPSEpEzjvCCQa1afBSgrqpSXkm5cS0NNfJkd2sHx1MrKcdjaXt5G0wnlyfz3M7nSK5OxphgxMHSgRp9Db08etHdvTsAS5KW0GBsoItrF/7FK+QvreabW38idlMW25Oblg3pNzWEoowqUmOLqVhhR9fQvhxhP//eLSfDfZXD6Lp/EuXFddg4aKmtPLOYIiDUGvuvHqK6sRE2bmTcI49Qs2c3DdWZOD3yCCpbW6y7hOG+6QssGvwxqjSEpizD11uB3+efodBq5d4CSwdQqlDZ22OvrKISCCrxZH/+/iabmF+OlEp5qLULkbhmhrDXexWZVZm0d2pvPmZT5iY6Zkn0PR7IsTAnLLUSM18dZJ4f93feoY4olQoarFxxaHDBqqGUOmsVusnP8M3Tu9E3yCMm4YN9UIoJ/DesXw9mYUUDb/vuI2rMJAgeKc8LPfIH/PgomAzM7zSZ+fMfhl0fwOKXoKEKik9tIaayAKUK9HXQdSZ4hEPcL1B8En6cDC7tIHkjfv3m49f/UX6/tyel9TCykwfldTpWxuVhZ6mmX4i8A0oXXwc+u6MnD/10iOSiM6VXftwnl1xxt7PgmTEdeHX1caob5W3ZRnVwwXP1bOgxGzpNlsdLW1Gzk7LXXnvtgs+/dKoLXhAESK1IRZPniFqSkyq16cw8h8js8agkNVorFT1G+WNppUC76QkCNXvJSZFLbTZ6ejQ5n1WXM0Vhrbqe+d6mb19q/voLtaEKg9peft5gS2FdIUEOQVft/Z1PRWEBMWtWkLBtMwa9nMA4enoRMXEa4UNGoNZe2byiF3e/SHKFPJfkk/hPzO1apZatt2zFRmPDnyl/AjDLaS6HF+eABMveOYTJKE88t7TVMOO5COprdHgE2pN6uJjU2GLqqnT0PzwL37FeHDfFMlwRhcWmEMpNdVjaapj8RA9O7M0ndpM89NEu+nOkxkZzDCWffQaAQqPBqYsGfpoBRSewKS6g78GDgAmNnQ0+7/2Oojobfp0FJYlg7wN+fSBlK842c8kG3Gq9WV2xlg8Pf8gTPZ9oVmJW2VjJwn0L8TH4UFpRitqoZcDB2fKTDeWkV6abk7LyhnKqow+y4FcjiR16ANB+gN85EzIAraUaj2B78lMqKXMKwyd/Dym9x1GyIqPJcWH9RO/Yjcpkkth0vJAF6p+IKvkLfvwavLpDfTlUnKk7R85B2P0B1JWeabN2gaEvQNgEMBmg4Ci0HysnaB3GwxcDoSxV/gLY9yns+5Qe1q7g2RnWJ/Fe4GB6dx/EQKtMVMt/B6MeHPwY2nEiu54Zysr4fDzsLckqq2NJTDYTunpx38BgnGy0tHO35YPNSSQWVPOS+044uFnutQseClaO1/Aunq3ZSdmKFSuaPNbr9aSnp6NWqwkJCRFJmSD8zcnykwSUhzdpi/CL5lBOBCpJ/ufXIcxAhOXPUJELFn9hsvBElynPldB5NE3KNAEBKO3tMVVVYfm3BM2mX18AFFLTD+3C2mublBWmpRC9ahlJ+/cgSfK0B4/gUHpPnk673v1Q/q0y/OWqbKw0b9Ztq7ClRjrzG7HOpGNv3l70Jj1lDWUEGcOoWG8NUgMAJqOEUq1g0C2h+IY54+BmhYObFQABHWwJ6+fJyX0FIMGwwlt5ctTTrPwoFr3JSHB3NwZNC6D+9+9xXr+VDsPm41kUjbT9IEo7O4JXraT8558p/eZblLa2eN3RG/WOM6s8tXbg5FuJKXAYni8vROPuDN+MkhMykIduEpYD4NqwE2wGYy0Fo5AUfH/sewZ6D6S316UXoFuStIQNmRsIUgfRubIzwxPHmp/rUOBHWuWZeWXbsv7i9q16JKUVJR6nkrLeF06o/Do6k59SSblTGE4VSZSqxoARAru6UpBaSYd+nljZikn915zJKCdGFvagvnr3Pza7nPa1Mdyu/Vsdxfw4+f8aaxj4BGht4a+FckKmUMptkgS97ganv5Wdcfzb8KFrKNy5Ag4vBqUSnINhx7tgqIe6EkjbLl/i6G/cwW9nB7Z/EW5WTtzn6C8naiiY5+0D+fXwcw001tDDypHFrh3ATQWxS+XXjXqt1RMyuIykLDY29qy2qqoq7r77bqZOndoiQQnCjSK9PB3/CnlPRgd1AVaqWno0fkiB5jlydHLNrOCMlyD/zPyvkqwAJF02ah8f9E5OTc6nUChwun0W1Rs3YTd8uLld264dKlcX+Mf+0PllReB9ld7cKZIkkXU0noOrlpJ1NM7cHtitJ5FRM/AL79KiBRnji+MBaKcNY3T5ZP50+YnJHaJoNDby3bHv+PXkr6RUpGDX4MKYow9SZWjAxtGC4B5uHN2WQ5+oYDoP8aV23z7Kd+Zg06cPhe+8Q82WrXR95GG6L5jLb/85SOrhIjKPyrXEfMOcGDrOkfx7Z9OYLPfQ+WQ/AXo9qFT4zAxF89Ng3AKHYPPBK2itqtDseFoO2Ks75MehUIBP/3IY2xuqDsMfL0BlNli7wt1rYec7UHQC7DzxK9mLur4Og8aaZ48OYo39dtalr2tWUhZfJN+nQmMhluWWDCu9HdOpn/hakxvJFXHmY/M3rWZYnoIjXedgRI2TpzXugRde8endzhGASvsA4sNnIxmV+LR3ZNxDXVAoaPUinC0i5xAUHoPut4PqVC+3rhbK0kBtKScQra2xRk5WrJzhyO9yEtRQAU5BcN8WsLnExRX6BmislnuxlErQN6DIi8c36VsyTr6P511fY+fVAYPRxIdLNpF6ZB+fa76UXxtxL/SfD4UJoNJCwACwODU1ocds+R7a+zRNxC4koL/8dVrfR0AyycOitSXg3R0SVsCxZfIQZ9dbQW0F+fFwYpWclNb/balUUcJZlyAn+sz3/v2g++xLi+0qa5E5Zfb29rz66qtMmjSJO++8syVOKQg3hLyMcnwN4aCs4XaXeSgVcu9RsMUBcnTdsFRU4W2VCl1ng7Uz+joVZS+d6i15+inQnV0I1v3xx3F//PEmbQqFAqvu3ekY+xMp4bdQp5R/EBcXV1y192YyGkk6sIfoVcsoSpeHGRRKJR36DSIyajrugcGXdB5Jkngv5j1Wpq5EpVDha+fL4z0fJ9Izki/ivyChNIF3Br+DlVru0YotiiW4tBvD0+7CZFDzcNgb2NRaUFBcQndjJnHIpUKmlt4FBiXuAXZMmNcNKzsNPUcHYOtkQWNqKlkPPAB6A6jVYJDnl5R+9z2hc+fSdZgvR7blYNCb8A51ZGBIAVm3PISpqgqVgx3Gymo5IQM8htljW7NGfv8JS7BRLJM/QAAGPA6jXpU/IA4vhs0LYMPzZ968nRfM+A7cw+T/A1QXYp3WCa/UOLI1/XE4Yc/LaSY+1GzA0Pf/UCsv/mNbkiRz8lon1VGdnI/p1LA2gM7CnbKkRLYEbqHR2IjH7kQKPSIode6CSq1k5D2dLppUufrLSVujpQvgAgoYcXenq1p9/ZwkCRqroDIXtrwMru2h3zy5Z+bQD5C6Dfwi5Q9zfR3YuMtzlmw9UNUU0rPShOrnr+XEwcEPwqfKSVdtMSRtBE7NkQoZCokbIC8WpFNVBiLvhz4PynMC7b3O9PhIkjwsp1Rf+Rylxhp5ONDQCOk75Qnyxkbw7ik/f2w56KrPfl15OrwbIictwxfIQ3NZ+6AsXX5/FVly4pQXKydjdWXy+1Jp5XtUnY9aMtLr1Okq/jcNBj1A7t5lPFMbD6c64aod2mM3eiForeVerX+ytG+aYF0Ojfxvn4h7zrSFjoIpn5197KSP5D/LmmJQqcFogOp80NqAhZ38/8pcqMySf4lVqaHbLDkRbQNabKJ/ZWWleXNyQRBkVfnyXCNbi1RzQkavu+kQ/Rt5+k4EWBxC2W06TF4EQPWPPyLp9Fh264rNiBGwfv0lX8siOATXLVtpl3eAZSGvoGgMpKyk6Q/r5kwY15v0/JH4B8EOwfja+aJVavGw8UCvayRh2xZi1q6gslAu86DWWtBl+Gh6TZiCg7vHRc58RmJZIr+e/JVlycvMbWUNZbx58E1mhc1iUZx8X3bl7GJ04GgAYgtjGZg+A6VB/vGVe7LC/Nq+RJHplICNtRWeuR2QgIG3hGI6Gk3x/gO4PPgA5UtWUf7zz3JCBmAwYOmsp6FMg9TQQM68+fR64nHCB/ehorAO26ObKXrmPwBYemrw7Z2MvkZN9i5XHNvV4+SSJw/TjF4IiesheSMoVHIPwYhT0zmsnCB0tJyUndb/URj27zMfOKfZeaDoOJFOdbvJruxPkVsPAjM3MHBfFdH5B+jn1fei9zW7KouKhjKGJngTH1BCRLofAPaGEhqU1uiU1ngcMfAf/VNgMvGfdCNZQQMB6DXWH3d/O3Mh3yb+9nfHwkqNo4e1eb9Od3877JwvrWjnZdHVyl+27qCrg7zDctJ0co2cZJyWvEmeg6RUy4kRQPb+c55SCfgB5tUz9eVQcKTpQSotZO6Wv06zcob6Moj+Wv46zc4L9PWgqzmTlFk5ycN5p7uxpVP/Md/fC3xv1DXt8fm7gjP1/VAo5V8EHAOo7vkQJ7Sdidh6G0p9LZSmwJI55z7HuRh1UCVPn6jAlv3GjoQrMvBryIHNLxEAGCUF5Rp3NBbW2M3+VU7I2gqVBrx7tHYUl63ZSdnHH3/c5LEkSeTn57N48WLGjRvXYoEJwvXCaDJyoOAABbUF9PXqi7ett7ndUCbPoXJXnaorZusJw15EW5jAmJz35baw383nqt68BQCH8eObPfxjESL/lqqrUmOhLkPXGEhtWZ35+biiOB7Y/ADTQ6fzbOSzFz3/ryd+Ne8JCeBgsmaB5b2k/rWD+ir5FzBLO3t6jJlI9zETsLZv3u4Ba9PW8vyuM71G/+7zb7q6dmXuxrkklyfz2r4zi4piCmMYHTia7459R1Z6EZF6e1RaBVbejdRkaLF20KJrMGJoNDJeN4uAik6UGevwDnXEWVFK+sMPIekMVK5cgaFILqOhUJnwiqzE0KDEqV0tFWnWFB52pO7AATJn3Y7/D9/hlJ5BwetyQubcvgb37lUoNFo0Lra0d8uTc5SQETDhfXAOkufKlKbIH8T/HDZy6yAnaVV58kozvwsMRUbeh/+xGVgoamiwciWm59P0iH2fzT/Mpp++7KL3Nt7WmhmpQ3CRHqDL/l0oTfU02oOr4Sh1KhcKlF0Jy/Vi/L40nGug1tqDSsd2KDDS6cBwiDlPIvAPbpWPU8EQAHxL/gevjLyk1zV1qX/PTyUrdt5QW3Qm4fq74KHyPKLMPfLzfn2g0xTI2iv3/th5yT1gXl2htgSDpRPpBzcSHNoBVadJkHsIjq8E907gEiL/38YNor+RkyO/PvLkdAcfudds+xtQnCT/eVfny19/ZzLI17tSVk6gsZHnPEXeJ8eUvV9OGH17Q8hwaKzmQCHc9d1BGg3V9LH8P34YCVY1OXDgczlpcwoE7x4Y7Hwot/DBVFfBN8nWnKi1I7laSyn2eFBOe5saTtTaU4AzbpZgoSvnTuV6AhWFxJtCUPe8nSenD73y9yWcpdlJ2YcfftjksVKpxM3NjTlz5vDCCy+0WGBX26JFi1i0aJEoditcscXHF/P+ITnB6ufVj69GfwVAXk0e9vXyB7OvphBeLEBSapB0epRhE+U5DVpbpMDBGMvKMJaXU3foEAC2I5r/4aYNDgGgvlSDU3ElhdbQWCl/cEmSxJsH36TeUM9PJ37CJJmIahdFuEvTRQjlDeXU6mvxsfVhebI8jGpTryI83Z7QbFuOGeXdPezdPIiYOIXOw0ahsWh+70hKeQqv7H0FgD6efRhRMhPjz7YcbCznDtUCNnj8SLbjCXoWjMKpxpPD9tEcKjzEh4c+pEf5KAB82jth9M2k34hu+IQ6k5NYzpbvj2N3IpAy6rCwVjNghCM5992BpJPvw+mEzCm0FsfgOix79JV/sx70FI7pMdS88l9qCy1Bksi57x5Mp/Y8d+5Qg3sfUPR+Evo+DIZGFLveg8BB0Hn6mR4kheL884wUChj01Lmf+6egQWhn/8ik6GjWHehOHV4UeA1AlbQFQ9DFf3DHqSwJLe5OmSuoVB2x0pfQCHjbJVGFBwX6rtjpfXA+tUaiwENOEAMsDmGjurSEDMBdk0pyg5yU+WiPXOTo8zlHj9yFVJ/aMcHOCwIHyklS8FAwmcDG5dQxBXKPlfOpRS79Hjn3lfV6juc6Ejh0PCqNBnx6Qu/7zz5wwjmKMHcYK3+Z4yqUe5i0tvKXxkqOob5c/r9CASj+loMq/tbzeJ7vFSqw9z73BPSOEwHQG00YTRIGtQNPL91Jo0HukT/QEMBnde0IdLMh6pln0ajUVEkWbDtZxPubksgqqwPOzPHSqBT08nfiSI4F22qNWKiVPNQ/gHaNyWRZR/LmNmcArLUqdo+9wuFI4byanZSlp7fsBrmtZd68ecybN4+qqiocHNr+/oBC27Uzd6f5+79vIJ1elY5TvTyUp66Eku9/wlBSTPmPi7EbNgjP9l2prmlPydiJGPLP/IZt0akjWl8f9KfmLF0qbZD8ASQZldgUVEMwGGpUJJUnkVWVxfGSEwSXdSffLpVfTv7Cb4m/8fmIz+nvI/+ArTfUM2vtLAprC5nXYx66lBruPDYUVX0Gpz84y+31RM2aT8SQ8ShVl7+S8s+UP2kwNDBSNYWx2TNJiSkC5Er3KqwZ3jALybIC6wz5QyMj7Si/Ov8KEnSvl4fZ/MPsKC9KJ6jbODRarVwtXiGHqlAqGD3NhYq5URjrjKgtjVi5GajOtsCxgx7Pxx6AsInyhOFTlP798H+1EVNJJunvbkFXKb8/53AD7o8+iqL3/U0/HCf997Lf/yVpPwaP9mPoE5jHtsUnyfMeSP8jW4n596/09Tv/EKbeZED/4jhq7DoA0GDlSoOV/MuB1/z3sCpqhJ+zqLbzp9I+CJNSTZWdfJ8Do6ZB3/u5pERJknBPq4XP0lCqFHg9swS0/5yXc4kJ17mGSv9JYwko5MncToHg4Hv++Vp2rVCKw85D/vonB5+rdslGg5HbvtpPQm4VzjZaCqoa8HG0YlZvP97blMQnf8n16fJHt2daT1+iPt1BSU1jk3NEBjrx/LgwAlxscLW1oKpBz6GMcjp52+NspWLdumTmDwvG09Ga7/ak8+DgYJxtxKraq0UUjxWEK6Az6jiZn0T3vOHYNjqT5haHSTKhVChJKknGrkH+sGvcnUzxX4fMr6vetgtdTiiNyWe2vkGtRmljg8s9cy8rFpWtjXlLH4tGubfDotGO29fejlalpVveMPplTUbtZCKm/xL2l+3luV3P8fvE3/G29Wbx8cXkVufiUWZBwpe/MqLYCpCTTKXaD5VlJMfb76CbbwO9ryAhA4grjqNXzlja5QwjBbnM/YAZ7fAOdWTtoiNQ5QBxZ35Z8q/oxJbUJUxMfASLSkdAwuqTu7BMLaEmfi0aN0+MFZX06XgruaZwBs8Mpf7JCRjrjFg4GvF78W7U3UZTt+R9rGc+C77nmHOiVMHQ51ACARFHadi2HG1AANqBt7bqnJnQCA/2LEmmHjeMlh1IXbOUvk+NP+/xe9O2MuiwPUnhTX/ZVKskXEJ8sHBuALKotvUlttujSAolylNdgi5BHmBz6b+kenV2peswHU6e1micL30u4RUJGnRtrtMGHUwv46MtSdTqjMzu48+J/GpisyoAKKhqwMPegk9u70GImy0fbUnGcGpz+8+3p7ItsZiSmka8HSyZ2tOH+wYGk11eR0cve/MelAD2lhqGhbkDmH8xVCgU3N7Hn9v7tJ3K9zeqZidlDQ0NfPLJJ2zbto2ioqKztmA6fPhwiwUnCG3d0ZKjdMwaRM88eUjNtdaXsoYyXK1ciU85QRhBKE11aP+2xY02KAhderq5tILdqFF4v/cuSotzF+psDmOxPDxn0VgBgJvOhUZjI1Kjksg8ec6noVxJ352z8XDqymqvr3l82+O8PfAtNmxczMyEMKzq60+dTYFSE4pX+2FUFNth1JuIyLUhriCeW9rfctkxNhobqU1SMjJHjqdDH0869HHHzykPdDn0HGDJ7vXyqlP/Ts5kHS/Dr6ITHYp741vZAbVWScesxRgTywAlBStzAHnOnp36P0z46X30q76iILYQUOD16ktoxsjL3W2e+vWSYlQHdsH2ni4XP/Aa0Fio6NDXi6Pbc8j1Hojvqh+RnjChOM9qsRM/fUawNuys9oAurqjUSuxdrVBbgqFBY+7HMp5a0enkZdOs2BRKBYNmtr/4gcIVM5oknl92hLQSeaug+OwK83MPDg7Gy8GSab18sT+1EffCKZ3ZlVLC1hOF1OqMHMosx1Kj5Kf7+hDsJpercBI9Xm1Os5Oye++9l02bNjFjxgx69+59Y9SiEYTLsCxpGa/se4VplWfmCdk1OlNYW4i12prc7GLCANuaQhSAyskJtasL/v/7H3lPP0PtXrmXzOXeuS2SkAG4PvIwJZ99jmWDPBncot6Fh+pforSyArVB/gGstVLRUK3Hq7ojIxpnkZHzJz+seIQBtQ7IQ4gqVNpwVJa98HAwcEvEHvQW7ny3qhMODW6kHq+Bwc2PrUZXw/uH/p+9+46OqmgDOPzblk0vpBBSCS1ACISEjvSOgtIEQZQmghVFxQaCBeETxS6oKCh2QUBAlCq9BAglgUAgAdJ7L9vm+2PNSgQ2QYGEZJ5zPJLbdvbdvXffO3fK2/wW/xtd0u8FILSnL93vdIFv7rH0JmslVIjWC3DvPRIfp0SWxQnsdU50jzfv0y4kE/s/9gICk68ryqQ8UIDKXo2xyEDGS49QkGgLqHDu2BS7ATVj/KH/IqSbDyd2JJLh0ZpmZ+1I3Lga/7tGAubHzut//4g7Oo7g9CeL6Pp9DFFh5po0p3paCrLNj6satzM/0lMoFPg0rsfF6IodBlROJrR28uFJTaMzmNgck8bK/RcsCdnU7o1YsTcBJ1s1D3VrxMM9Gl+x35gOAYzpEMDK/Rd4ec1JvJ1tWTAi1JKQSTXTdZ+B69evZ+PGjXTt2vVmlEeSbgt/XvqTufvmojFo8Sjysyy31zuRWpBGVmkWroXmH0H74jRsggJptPE3y01MvcmTKNq7F7uwMGzbtLlh5XJ/6CHs2rYl/fXZ+Cb9SZJvD4hyxx1zA+ghbnPxbujE2WaL2bJiNb6xR/EV5nVCoUGtDUetDUOhNNeYRKgXoji4HxugiXoKsWV3ok2px7N/PsvdTe6mq4/5OnCtm7NCXSEbzm/A1daVdw+/S2JhIkqTEr88c3un4LyP4INVGPKKKUx3xahwQm3MJNT4Aqr484j9SwngKc5hbkemVIHvsY/IAWyDPDn5wCO0izuNc69+6BLOkvr6/8g9Zy67NqgB3h99e8NiW53cfR1p0MSFlLg8Urw7IZYswe/OESgUCrYseopWy/8kVbMMbz3kOQeR7xyEUqWg4z1BbPniNACBrdwtx/MKdL4iKavv53or35JUBcm5JYz5dP9fjfLNnh0QzKO9mjBroLk2VFXJuHD3dwokzN+VIA8HHLQy6a7prvsT8vX1xcnJ+kjPklSbFemLeHnPywD0096NEiVOqlTyTR4ohJrUjEwSTGctiYdrbhwOvbtUSFwcu3al4aqf0fj43NDaZqWdHY7dupEb4Evwrh9p6B3PQfvJ6MuMtHf7FTflKfZF+XL8z6cwGM2vq1A6Iuo3x7akE3a2Ku5odYp4Q1dapz6Lj+IwaF2gLI9GmuPEcie+eU35PmE+h1IP0darLaezT7Ow+0KMwkgr91Zo/hr53CRMPLPzGfYkmSdKdynxZGjydHzS/3q0pirEK/krSvNUXPzTG2MJgBFwwzmlhPrGJVza4U6DsvWU9g4gqTCAELs/0B26AGhxGDgEk709Hs+/jEajwS4igvR3P8RUWIy2SSMClq9A9S8nPK+JWnRpQEpcHqle4TSM/J2iXbuwDQ3F5/tdANjqQadScqTzaCiDZh29CQrzwLlJGe26tsbG9u/Lff0g80CyKrUS41+99bx8ZYenmubVX2O4mF2Mp5OW5t5O2NuomNClIVB5Mna5VvKzvW1cd1L29ttvM2vWLJYsWUJgYBWnTJCkWmRX4i5yS3MZmDiBgERzg3E/m5NEG8JQ6D1Iy8hiW/afDCt8DgD37Bjs2l45BZldSMgVy24Um8Ag2HUE79SdjHm6LwlnUkk6tJvPC9pjwtwWyd2mCLv6A8goiEBRqgIF9LT7H42T9hEMlORoOPOnD5rg1qhdnVAm70f4mXAtrc/kA/8jymcrxzJP4VrizbiC+0EhCPcK5/3e7+OideGLk19w6WQOoxNepECbjX9+MArxdzuoQMVRErb7UJou/ipzINqWLSj4bRP5F+3Iv2QLQoENBXS9+BI2HUPI23jWPGQF4DDoHjh1ynI8pZ0dvu8spvjwETymPoTS4fraR9V0Qa09QXGaYkc/SmzdSX//A/RBPhjVvuzuPJFEx13Y27XBMd8fpVpB274BKBQKnJvqaNLOq8KxAkLcCR8YiHeQM9u/iaUkX0c9n9oVr9tZcm4Jy/cmsCk6FZVSwcrJHQn2lpUhdcF1J2Xt2rWjtLSURo0aYW9vj0ajqbA+O7vygQ0l6Xa29eJWQlN70DDx7x58rqmncLBrSImNB/vOHsLJ6I0CJQ6FSWh1ediFhd3SMtoEhwGrSC6z5+LKTzhX6A6Ye8fVK9XRqUsjggu/QyiPc6zNtxw7aUdzu500EvsQJvMA4ZnRjhjLwHj87/GnnHwSKVQGoDFpaZ84mLDkPmhMWoIzOqA12HPSexePicfo7NOZH/auZdiZGWhMWtxKza8dGOpOYU4pWYlFuMWcsCRkDl0647t4MSoXFxIFFGzaBJdNrl54yRZXmxMUJbmi0GjwfOop8xAglyVlAI7du+PY/V80eLsN2Dpq8GnqQvKZPFLqt8Hu5DY4eZLzodPRaevjpR8JelCqFQx6OJR6Pg7XHFZFqVTQ+R5zO6SC7FLOHko3J31SBXvPZXI4IYepPRqhVaswGE1sOJHCllPpFJcZWDCiNZ5ON6Y9qM5goqjMwIfb4/h63wV0RnMN5uQ7gmRCVodcd1J23333kZSUxPz586lfv75s6C/VKTqjjkPxRxl+wVwLFt5JgXb9YmxPnsWpZVdKvEBTao9PobnruHt2DCoXezR+ftYOe0MJk4kkXTEHmviQ42AHhQCC+nnFNErPwa24DGIvcc6tMYFdEgi/NInw7mMQBz7n0m5PdGVu1O+qojA5HxC4jh5NcWQkunPnqJ94lMKAv7vFa0zmH6TyR7W9zo0lsnQTf5zazz3nn0Rj0mLnpKF1Lz+8A+zxK16H4eR6zh3NxJicjU3DhgR8+QWaBg0sx/R84gmKD0eibdwEr2efIWHUvZTm2JAaae6o4PXMTOo9+OB1j+NWGzRu60XymTxONm1HQOJ2DGoXMuu1tIxHqlSZE7KGoVWchBpo3cuf1r38b06Bb2N5xXqmfX2Y/FIDhWUGHuzSkAlfHuRMWqFlm/kbT7F4dBhJuSU426px+qvnY2GZgcMXcmju7UR9Z+uDKwsh+ObAReZvPEWx7u/BzDsG1WNCl4YMCKmGMdekanPdSdnevXvZt28fbW5g42RJul0cSj2EV3pjVEKNZ70SOp4bS9yZ+hhRWYahcCuuT6Ps1gB4ZkZhF9bmlty8GPR6Tu/ewaFfV5OddAkc7FCaBH7FZTQpKsE2NRuHO+4ApYLiyMMYcoq5uMuXwJ6JaA59TtZpR4qSNUAhieaB+3Hs1YsG8+Yi9HrODRqEf/w2GnqdQNOiKZviRwMQ3llNbqkbdk42RO9Mol3S36OcN/BXM9j3U2wVPvD7OihIRg2oL3piQoPnjCcrJGQA2kZBNP3zT8uQD/bt21N84AAASkdHXEaMvOmxrKmaRNRnz6o4HA2BLB7RgoCcRnjqldRv7ExoN1/cGjjgFehc+YGkCuLSCzmdXkQbP3OD+J1nM1nw22nyS80zQXy66zxro5JJzS/FzV5Daz9X/jyTwS9Hk6jvbMtnu87j5aTlfyNbs/pIEr+dTKFUb8LeRsXD3RtzX0d/vJxsKdUb2RGbzrHEPGKS88kp1pFdpCMxp8RSlkB3e+YNDaFnsNe1iivVYtedlDVv3pySkpLKN5SkWuhAygGCsswJV6OSn8lMcMKoU6FytEOrywWgZbq5R6JDSTLO+Qk4DbjKtC03UFlxMce3/MaRjWspzDE3H7Cxs6dli1Dqb92F6mISABpfXxq88Qaa+l4YsrK4MHYcugsXuHSgCR5NL5EZ7QIIlC4umPLy0Pj64vXsMwAoNBqchwwh65MlOCWfwyfwMJ0c9djZ6mkZv848+XZpHs7dJ7JvpzkBjehdjw4Jo1EmpELCX2U1+VCS5YCuoAhUKhyu0Yv78jG4vJ6ZSdrChZSejMZj+nRUjnW37ZO9sw2tuvlyfHsiTfJG42hwBSCsdwBNIuSPuN5oqjAQamJOMd8fvMTAVt78eSaDYp0BdwctO85kEORuz5m0AkShkpijBy0JWM9gT3bE/j1fZaivCyeS8kjNL8XHxZafpnfB19WOF1Yf57uDl1jy5zkAUvJKGb/soGU/V3sNucV6Fm85wwfbztLG35WzaQWW17mcVq3kqX7NuK9DAM62avkEqg677qRswYIFzJw5kzfeeIPQ0NAr2pQ5O8u7NKn2OnIpig755nGvlHvOkZVvbuvhfM8w7PdVnIKsQdI+VLZqnAcPuillKczJ5shv6zj2x0Z0JeYu845u9Qi/8x5a9xmI1t4e0xMlZH70EaUxp/Ce+wqa+uYfbrW7O/7LlnFh7FjK0tJJSnMDBI59+9Bg3jyKDx7EsVcvlLZ/P3px7NqVrE+WUJSqpSxXTVun1SjVfw0/enQlAOGKjdQb8Al23n7U3zcWUZBKQaoWdUgPcmIEebtPgck81pJ9+/aoqtCT2y40lIYrV97AyN3ewgcEErMnGZcy8yNKV19bGreV7cGiLuXywLIDtPRx5v0xbbmUU8JDX0WSXaTjw+1xV2z/9+RoSsCAh6MNmYU6S0LWyteZ9g3rMfvOluw5l8n5jCL6tayPj6sdAK8MCTE3wt9/kR7NPDkYn02J3sidoQ2Y0i2INn6u/Ho8ma/2XeDwhRwOXzDPsuHjYkuPYC9CfJzxdrZFq1ESEeiGvY0crkL6F0nZwIHmRxN9+vSpsFwIgUKhkBN8S7VWoa6QongFKqHGvjgFu/wMVG5uqNzcqHf/eJyj51i2VRtL8E47gMvAO1Da2d3QcmQnJxL562pidm7DaDDfddfz8aP90BE0v6Mn6stulJR2dng988xVj2Pj50vA8i9JmTOHksjD2LVpg+///ofS3h7nQVcmknZt2qC0t8dYXEz8717YeZTh0rCEMhrh0U6BEVdssnfR8NhUOK5CmIwkHfaj4LwJdp284nhOvXrekHjUNQ6uWu56rA0bPz6OrtRIt+HBKK5jeITaZv/5LDadTGX53oS//s5m4Hu7KNMbKdIZcdKqKSgzoFUrae7tRFJuCfd3CiSzsAw/V1u+2x2Lg5MzKyZ15Kt9CXywLY7hbX15+96/mx10a+pJt6YVE19bjYrX7wnl2QHNcbZVE59ZRGGZgdaXjfd2d5gvd4f5EptawImkPBp7OtDaz/W6hrOQ6pbrTsq2b99+M8ohSTVG+Q3GPx1KPUSDPHOPNfesU2j93Gi4drNl6AWn+rZQat42MGETNsYi6j32/A0rV/KZ0xxat4q4yP2WCZx9glvSfugIGoe3v+a0O9ZoGzWi4cqV6C5eROPtjcLm2tOuKDQa7MLDKdq9G4CSTC0lmVogm5xjGtBnYRfUCt/QGNRaI2mXIig4//dE6/YdOuD19FOgUlO0Zw+u99573eWVzHybuTF2bicKc8uo37BuPp0o1Rt56ZeTrDqSaFlWz8EGLyctp1MLALijiQdLxkew80wGTb0caVrfqcL5rdfraZAXw+DBndFoNMzsH8z4zoF4Omqr/AjRxc58E2RtpPxgbyfZg1KqkutOynr06HEzyiFJNcIHRz/gq+iv+ObOb2jm9vecfmlFacw/OJ+eeRMBcM09i8ejD1QYC8s1yB3n/edRCBP+iTuo16clNv9xLD8hBPFHIzm6cS2Jp/6ubWrcriPth4zAt3nL/3T8cjYBVZtouN7ECeguXECUlWFIN08kjkYDf/WELInPJiG/KWpXZ0rPmduyNXjjDVxHDK9wHLvQVjek3HWZg6sWB9cbMxzD7Sa9oJSpXx0m6lIuSgXc2doHncHIA50b0r5hPb45cIHU/FJm9GmGnY2KwaF/dyapLNnycrLeW1KSbqbrTsp27txpdX33WjpGkFQ3bDi/gVJjKevi1qFVa+nm2418XT6z98ymJF+Pa6k3CBMexjicRlVs52TXrDntPlmAADR2Rjxmvf6vy2E06Dm1azuXNq7iXJ65LYpSpaZFt560HzICd7/qGcLAsWtXmmz+A2NBARfGP4C6Xj0azH+D0pMn0fj7k/TkDHQJCRiyClC5uOD92qs49+9fLWWVapcSnZGjF3Pwr2fPmE/3k5Rbgoudhk/uD6dL44pDgEzsGlRNpZSk/+a6k7KePXtesezyOw/Zpky6XeWW5pKWl4FrWX1WxKwA4NPjn6JVaSkzltG9bCgAjoVJeHX2RfGPTi42IW1Rqk2YDAr8Hh+Ayr/FdZdBV1LMiW1/ELlhDYVZmQBobO1o028Q4YOH4lSv6uNP3UwqJycarfnF8rfG2zyWUsCXX5A4YwZqdw+8X5mDpn796iqiVIuYTIIHvzjIwYRs7G1UFOuMBHk48MWE9gR51N3euFLtc91JWU5OToW/9Xo9R48eZfbs2bzxxhs3rGCSdKvFZMXQLX4kwRkdWdfyQ5JdzgJQZiyjp3owrWL7YkDgmXkclyl3X7G/yqc5DUeoUajV2Iy9vnOhKDeHo5vWE/XHesqK/uqd6OKKXcOmjHzkSRxdXf/z+7sVNA0aEPTDD9VdDKmWSC8o5fNd8fwUeYmcYvMj8mKdEUetmuUT2xPoLhMyqXa57qTMxeXKiU379euHjY0NTz/9NIcPH74hBZOkW+1kZjSNMs21W6HJnQhN6c5592M46d1ofnEABiGolx1Di5J1aNo9d+UB1DZoXz4MwgQ29lV6zZzUZCJ/XU30n1sx/tUuy62BL+2GDKdppzv4Y8sWtLVsDkdJqsz22HRmrzlJcm4JJvH38vs6BJCWX8qDXRrKhEyqlW7YwCj169cnNjb2Rh1Okm65M4nnCBLm3pVBue3M/89pbVlfP+0QLRNW4n2XIzhd47GcpmqNhFPPneXQ2p85c3CvpSdlgybBtL97BI3bdUSpVNXJaYSkuiM1r5SErCI6NKyH8rIhIg4lZPPIyiOU6M1NYdr4u9KlsTv2GhWP9Goih5OQarXrTsqOXzY5MZh7h6WkpLBgwQLCbvGky5J0IxWcyr3mOu+UfXQo+Qrvvulouk77V8cXQnDh2BEOrlvFpei/z6NG4e3NPSlbhMiRvKVaLS2/lM93nWfvuSxiUvIRAno390KlVKBVK8kr0bM7LhMhoHszTxaNNE/4Lc8Lqa647qQsLCwMhUKBEKLC8k6dOvHFF1/csIJJ0q10qeASDS66XnWdRpdPV4/v8PZPBe9Q6PXidR3bZDQSu28Xh9atIuOCedR/pUpF8649aDdkOJ4BDf9j6SWp5sou0hGTnI/OaOTRb45aasAAVEoF206nX7HPPWE+vHZPK8sE35JUV1x3UhYfX3EqGaVSiaenJ7a2cmwX6fZ1IOUAnoX+cNnYqfa6dAYYX0WtNeHlkwL+HeHer0BbtUEg9aWlnNi+mcMbfiE/w/zDo9HaEtpnABF33o2zh5yrULp9ZBfpsNUor2s6oM0xacxadZzsIp1lWZi/K1O6BdEusB6Xcor5cFscYf6u2Nmo0KqVdGvqQRMvOdCqVDddd1IW+B8Hw5Skmmh/0j6aKHtiBHqWvsVFXRjtPX/Bw+2vEemb9of7vgelqtJjFefnEfX7eo7+voHSgnwA7JxdCB84hDYD7sTO8fp/cIp1BtZGJdPKx4VQvys720g1X1GZAXsb1RWP4s5nFHL0Yi5N6zvi7WLLofgc+rTwwlZT+XftZhNCsCcui2W7z7M9NgM7jYrezb24o6kHg0MbWEaz/yeD0cS8X2P4ev8FwFwjZjQJ+jT34pP7I7BRm2ef8HaxZcWkDrfs/UhSTVflpGzbtm089thj7N+//4pJx/Py8ujSpQtLliyhW7duN7yQknQjnc87T0phCl19uwJgEiYK9iZgVDugMpTQzPcAIZq9f++gsYfBiypNyPLS04hc/wsnt2/GoCsDwKW+N+3uGk5Izz5obP7d6OvxmUU8uPwwKXmluNpr2DOrNw7av0/d306k4ONqRxt/1391fOnmySnSEZWYC8D0lYcZHNqAd+4Ns6zfdDKFR745Yulh6GSrpqDUQK9gT5aOb2dJXqqDySR4btVxfj789zRGJXojG06ksOFECvN+jebd0WEMbPX3aPmbY9JYfSSR/FI9e+KyAHioWxBP9GnK2fRCWvu6oFZV33uSpJquyknZu+++y0MPPXRFQgbmYTIefvhh3nnnHZmUSTXe41sf52LBRV7q+BJjmo/hs+OfEXzeFzTgUXYajeavNi9qW5i4EdR24HbtGuL0hPMcWreK2H27ECYTAF5Bjelw90iaduyCsgq1a1ez40wGaxOUrM89S0qeeVLN3GI93x+6xOQ7zCOWbz2VxvRvjuCkVbPnhd44yzY4NcaZtAImfHGQ5L8+O4DVR5KYfWdL3BxsOHA+i2d/Oo5JQBMvR+LSCykoNU8wvz02g3e3nOG5gc1vebmFECzfm8D3By8Rm1aASqng/o4BTOgaRF6Jnh2x6fx2IpXYtAKe/D6Kn6bZEeThwGvrY/gx8u8ETqmAD8eGW6Y4Cg9wu+XvRZJuN1VOyo4dO8bChQuvub5///4sWrTohhRKkm6W1KJULhZcBOCNA2+gVWn58OgHzCyZTpEG/LXH4O6PIWYt9HoBfNpe9ThCCC5FH+fg2p+5cPyoZXlg67a0HzqCgFZt/lOPMZNJ8OQPxynWKSHF3B7tvg4BfHfwIp/tPI+How3/2xRLUm4JAAVlBr7ed4FHezX5168p/XsXs4o5EJ9Fp0bu+NezJy2/lLGf7SezUHfFtquOJHIiKY+1UckAtG/oxrcPdeLP2AzOZRTi5mDDcz8f58fIRJ7u1+yW1iyV6o0s+j2Wz3eb2w5rVAoWjWrD3WG+lm3C/F15vHdTpqw4xPbYDJ796ThKpYJTKfkoFDC2QwAlOiN9W9avMOekJEmVq3JSlpaWhkZz7btwtVpNRkbGDSmUJN0Mh9MOcy73HJO2t8WjyJ9vOm7g9X2vMekPG0oczOOTNa5/AlothbbjrnoMk8nI2QP7OLRuFWnnzSP+KxRKgrt0o92Q4dQPanxDyhqTkk+x7u9eagH17Jk7tCWbY1JJzS/l2Z+OozOaa+WUCjAJ+GJ3PJO6BmFnU/1tkeqSvXGZPLzysKWWa1SEH2fSCsgs1BFc34n372vLwYRsEnOKWfrneV7fcAowt7O6t50/zw0IRqNS0rdlffpSH73RxMLfTpNZWMauuEx6Bd+4DiGbTqay6WQKzw1sjo+rXYV1JxLzmPLVIdLyzY/enx0QzL3t/PF0uvKxu0qpYPHoMLot3E5sWgEA9RxsWHJ/BB2C6t2w8kpSXVPlpMzX15eTJ0/SpMnV78SPHz9OgwbyrkiqmVafXc0re1/BsRjut32PfFt4cL8bJzyX00D/EFkqGxxNqbg39QeN3RX763VlxPy5lchffyE3zdz4X22jpVWvfrS76x5cvLxvaHm3XzZMgEIBLw5ujlat4p4wXz7fHW9JyML8XZnavRHzN54iMaeEHyMv8WCXhje0LHVBUZmB6OR8Wvu5WG1gn12kY9XhRHaezeDBzg05fDGHpX+ewySgvrOWtPwyfvqrDZajVs0n94fTyNORYG8nknJL+HxXPEaTwNNJy4f3taVjI/crXkOjUjKkjQ/L9ybw2c7zBNd3wsNR+5/bly3bHc9r62MAKDOY+OT+CMu6i1nFTFx+kMxCHQ1cbHluYDDD2vpZPZ6rvQ2T7gjiva3mm5NXhrSUCZkk/UdVTsoGDx7M7NmzGThw4BXDX5SUlPDKK69w11133fAC3iwfffQRH330kZxAvQ7I1+XzfuS7tI0zEZDlY1me7RFOeIqONO9QlELPQM+3UTS5v8K+pYWFRP2xgaObfqU4LxcAW0cn2g68i7ABd2HvfHN6Qm6LNSdloxsZmTN+AA525tqKERF+lkdLw8N9LY3Gs4p0zF5zkk93nmdsxwA0sjG1Vfmlep747igXsooJ9XVhU3QqOoOJrk3c+WpSxytGjT98IYev9iXw24lUS0K862ymZf3ICD9ev6cVRy/msnjzGRp7OTD5jkY08nS0bOPrasfXkzuQU6SvtHfl6Pb+fL3/AnvPZdFlwTY8nbR8OaE9rXyv7/tm+qsHQUpeKQt/O21Z/tvJVGKS82noYY9JwMLfT5NZqCPEx5kfHu6Mo7ZqPw2TuwWx62wGjTwdGdrGp/IdJEmyqspJ2csvv8zq1atp1qwZjz32GMHBwQCcPn3akty89NJLN62gN9qjjz7Ko48+Sn5+/lXn85Rqj29ivmHgpkJaZA1HZ+NM+mVPg9K8OwHQxm4D9TVx0KgnAPmZGRzZuIbjW35HX2ZuqO3s6UXEncMI7dUPzU0cl++bAxc4ejEXgJauokINSYsGzrQLdOPwxRzGdgiwLB8V4cd7W86SlFvClpg0Bsm2PBYGo4n3tp7l8IUcHugcyM+HEzmZlE9qvvlzjc8ssmy7Jy6LjvO3MqytD0/2bUZeiZ75G06x4USKZZtQXxfcHGzYeSYDN3sNbw4PtfRA7NzYnc6NO1+zLF0ae1SpzC0aOPP15A7MWxdDbFoBGQVlPP7dUX59/I4qJ0ybY9J44rsjdPdSss9wHp3RRMegeng4adlwPIXXN8RwIauY9IJS9EZz8rZwROsqHx/A2VbD6ke6Vnl7SZKsq/LZV79+ffbu3cv06dN54YUXLCP6KxQKBgwYwEcffUT9+teYD1CSqokQgrgN39MteyiJft0tyxtwghRCLX8HO2wDB08y9S4c+ugdTu/5E9NftaieAQ1pf/dImnW6A5X6hk0Xe1WHL2Tz0i8nAXjojoa4GuOu2ObzB9uRkldKiwZ/94S21ai4O8yHZbvj2Xo6nYGtvOXUNMDOMxm8s/kMUZdyAdh7LsuyzlGrpk8L8xQ/93cKJC69kOd+Pk5mYRmf7Ypn1ZEkisoMlBlMKBUwPNyPBzoH0trPFaNJsCcukxAfZ9wd/91QJ5Xp0tiD35/qTm6xjsHv7SI+s4g5a07yzuiwSveNSc7nye+PUqI38XuSEpLMj1Rn9g/G3dGGP6JTK8QCoLm303XXxEmSdGNd1y9MYGAgGzduJCcnh7i4OIQQNG3aFDc32dVZqpmOZRyj0y41SYF3VFge4fIL23J9KFa44yQSKdblszN/COefe8KyjX9Ia9oPHUHDNuG3JMERQjB/o/kR07C2vjzbvym//XZlUuZqb4Orvc0Vy/s092LZ7nh+PpzI5pg0JnRpyFP9mt30cleH7CIdX++NZ8tpJe4tsikxQGGZnvYN6+HnZg/AV/sSmLM2GgB7GxUN3R2IScmnY1A9pvdsTNsAtwqDn7b1d8XZVk1ybimf7jxvqUnrEFSPuUNCaOnzdxKsUiro3szzlrxXV3sb3r+vLaM/3c/qo0l0auTOve39r7l9RkEZU1YcolhnRK1UYPjrEeadrRtY2nxN6hrE0p3nLZ1EwPwIVpKk6vWvbvvd3Nxo3779jS6LJN1wu7etoIFtH1AosbfVU1xq/hH21sbSwmELB3PDKdVv4sfc1sAFUCho1qEL7YeOwLvJjUlohBB8viueYp2REr2Rnw9fIiLQjecGNmdtVDIbjidzKacEo0lgNAlsNUqeH9T8uhPBdg3/bmSdV6Lnva1nmdG3aa2rMTOaBOM+P8CplHxAyf1fRFrW2WqUrJzckd9OprLsr7Z3Y9r781S/ZrjZ23AiKY/Wfi5XbXOnUCgsjyHvbe/PicQ83B1taOrlWO0xbNewHk/1bcqiP87w0poTBHk60P6vz7tYZ+CXo0k0dHdg59kMfjx0iZxiPY08HFgwLIRxyw7QwNWe+cP+rhl+ok9Tsop0hAe44e5ow47YDMZ2DLjWy0uSdIvc3GcxklSN9EY9Nmv3kOE5D4AB9q9wXtkJe2UmsaIFMRlx6HVJ6AGVWk1Ij760GzIMtwa+1g98nb4/dIk3Np6qsOz36DR2nc2sMOxFucd7N6W+sy16vf66XsdGraR3c68KEzyfzyyi8WWNzWsiIQRbT6Wz91wWJiHQapSM6xBIgLs9xy7lkllYRu/mXpbEaNWRRE6l5ONipybQTsfxbCVu9hrcHGw4n1HEyCX7LMee2r0RL1yW4EYEVq1W31GrpnPjK3tGVqdHejYhOjmf306m8vDXh1n7aFc8nbRMWRF5xaPIgHr2fP5gO/xdtcxua+SugZ0r1Ao6aNUsGtXG8veAkBvbe1iSpH9HJmXSba3MWIaN0gaFQsGBlAO8u+9/6ArzGdvxYdz1tgSlNudMsBYn0qinPEOiroCD2b4UGc2PuLRKPWHeRbSdsw4HtxvfnT8xp5h5v0Zb/lYo4LkBzVm5/4Jl4Ndn+jfj7jBfbNRKtGrlVR9NVtULg5pTz8GGXWczSMsvY++5LEtSJoQgOjmfhh4OVWrMXVCqZ8mf53Czt0GrUdHQ3Z5uTW/cI7u49EI+2h7H8cRczmUUVVi39mgyEQ3d2HDc3MD+w7Ft6duiPq9viGHV4SQApnVvRIO8GBpHdCXIy5kyvZFB7+0ivaCMRh4OzB7S8oaO8VXdlEoFb9/bhks5xZxMymfc5wfwdNJy+EIO9jYq7DQq/OvZ81ivJvRqbm4rp9frcbExT98kSVLNJ89U6bZ1Ovs0r62YSD2/xrw65AM2vf0kL/yWh8YIW9u/TrpvA1w9BiNMBdgY1/DZuY7oTOZhCBzd6hHRWE3r/DXY3DEdbkJCBvDjoUuU6k20C3Tj4/vDyS8x0MTLkS6N3Rm/7AA9g714tFeTG/Z4rGl9JxaNasP7W8/yzuYz7DuXyfhOgRhNgjlrT/LNgYt4OmkZHu5LiI8Ld4Y2qDD8w4HzWSTmlDCkjQ9PfHeU7bEVB4R+ul8znujT9D+Xc+eZDCavOGTp9adVKxkZ4YervYZNJ1M5l1FkScgA3tx4mm2n01l9xJyQhQe4Mr6jP1s3x9Dc2wmNRo2jVs2aR7sSl15I1yYeVwxrURvY26j5/IH2DP94Dxezi7mYXYyjVs1nD7SrcTV7kiRdP5mUSbelIl0Rv70ymZc351Joe5gPNnVl5B5BiZ0XRTZO9Dx8kdRzeZxsnIgxbzNJmAAV7k5K2rfxpvn0j1AZyyC6F7Qa8d/KUmZu05Nfqqd/S2+aeJlrpkwmwaq/kogHujTEy8kWLyfzPm38XTn2Sv+b1lapc2N32AwbT6Qy7OM9AJZhNjIKylj653kAPt91nnlDQ2jj58qnu86zcNNphIC5v0ZbRqhv5euMs62GveeyeGfzGUJ8nOnT4t/1tDYYTRhMgtfWx6A3Cro19WBi14a09nPF469ejGM7BjLr5+N4u9hyX4cAHv/2CEm5Jaw+koRCAR/eF87gUG8MBsMVx/dxtbtipPraxtvFlt9mdOf9rWdJyCzi5btaEuThUN3FkiTpBpBJmXRb2vbJSwzYnEOaVwT2xWmM2pNIfOBg4oPuxGRIRpm3mVJlFujMjw59HYvpMH0+QeEdUCj/auSt1kD4+P9cltlrT1pqcDadTGXdY+aenrvjMknKLcHZVk3/llcmMTez8Xhbf1cGhNTnj5g0SzJmp1Exf3grisqMxKYWsOZoEscT8xj28V48HLVkFpqn17HVKCkoNaBVK3n73jbc1do8KOi8X6P5ck8Cr284RWZhGe0b1sPH1Y6iMsM1h4VIyi1hXVQyWrWSqEu5bI9NtyR7LnYaPhwbXqGtE5gHWV05paPl7w/HhfPGhlNcyCpmWo9G3NlajsHmYqdh9l0tq7sYkiTdYDIpk247JalJ+Hz5B5f8ehHXZARKDPjlbyLeNhhD/vcIYzL8lXcpNY1p555Et8FtoF2nG1YGIQTbY9M5GJ9jScgAjifmkVlYhqNWbWlLNqytr9XR228GtUrJ0vHtSM8vZeOJFHJL9IxpH4C3y9+D3j7RpykLfjvN6qOJZBaW4WCj4oXBLbgztAExKfmE+rngbPt3wvR476b8eOgS8ZlFzFp1Ahc7DQ42KtIKyujQsB5ZRWV0DHJn8h1BONtp+CnyEh9ui6Og7MoaLTA3wv9nQnY14QFurJre5b8HRZIkqYaTSZl02yiJjkaflMS5D97CpPImrvHdCGFEpzvNWZGJKFoHgEKhQqlpgcq2HfYaNe1dHoXWc25cOXRGHvoqkt1xf0+zM6a9P8cS8ziVks+euEx2nc3kXEYRXk5aZvStvrHCvJxtmdA16KrrPJ20vH1vG14c3JyTyfm0aOCEl5M5aeva5MqR5+s52PBQ90a8u+UsNioleSV68krMPUT3nTf3/juTVsj3hy6iQGGZjijU1wVvF1saeTjQr2V9NCol8ZlFDJHT8kiSJFUgkzLptlCwdSuJT84AgwFb4EircRjKohCGIxj1hQAolTa0cUsm2Dmf34oeQW2jYIjtTGy9A8A71Orxr8fstSfZHZeJrUbJgBBvnG01PNM/mI92xHEqJZ8nv48yl0cBb41qg5vDv+9NeSu4O2rpUcWBUJ/s05SBrbzxdNQye+1JXOw03BPmy+nUAjwctXx/6OJfc0IKWvu5MLZDACMj/FD/Y1ywNv6uN/6NSJIk3eZkUibVeCUnTlgSslQXFZfcvchQH4ESHQAOagOte/YjIvlttMI8tML9NpPR2GpQ6bKh9TzzWBQ3wPrjyfx8OBGlAr6Y0L7CXIZ3NPHg053nLX+/NbJNlZOd24VCoaC5t3lk+4/HRViWd2xk7vk3ONSb6OR8VEpFhWmgJEmSpMrJpEyq0UxlZSQ//zyFKgUHgz0p0jihEgoQOjQqB3p5HaWFczrqpL8GDA3qDmpbbM/+ATpAbQut770hZcksLOPVX2MAeKxXkysml+4QVA9fVzv0RhMLR7auVWNkVZVCoZDzJ0qSJP1LMimTaixjYSHHHplGjKGItGB/UChQCVCofFDbtudur5UEBnlDdimU5YFrAAx5D8oK4Nx2UGthzLfgXPW2S+9uOcPK/Rf45P4ITiblEerrQmGZgZ8OJ7LtVDoleiNBHg482rvJFfvaalRse6YHSoXiqtP4SJIkSZI1MimTahwhBOcPH2T32wvINOnB1Tzul1LTGLVtO5RqX5rZ7ybQNgr6rYN6jaAoAxq0AeVfvRyn7wVbF3Cq+nha2UU6PtlxjjKDibGf7bcMbHq5EB9n3hrZBq366r0pr7VckiRJkiojkzKpxjAa9Jzes5PIX1eTeekCAAohSK1XipdiPDbCPGFyY/9supV9CvVbmR9XKhTg6l/xYJ7X3+Pxu4MXKTOYewzqjQKFAoQwH358p0DuDvMlPMC12ienliRJkmonmZRJ1U5XUsLxPzYQuWENhVnmYSbURhP+Wfkc7ghpTh0JvBSAWz0joztsRBX1hXkcsq4zblgD/mKdgeV7EwBzY/XNMWnMGticdg3rYatRWhq3S5IkSdLNIpMy6bqZdDoUSiUK9X/7+hTn5ZJ17BBfrvmWsmJzr0l7F1caFZbR4EQMqa3rs6FZLg8c7QVAO+P7qKJ2mndu1AtCR/6n17/cF7vjySgow8/NjndHt0WjUsgaMUmSJOmWkkmZdF2Kjx4l8dFHwWTC4/HHqTduHAC6xCTU9dxQ2ttXeoyc1GQOr/+Fkzu2YNSbBx91a+BLRP87cfjiK/Qno8FGw1udMghLHoBWb4+jOpvGtuY5HPFubW7Q/y+TpvXHk4m6mMvEO4LwcbFl5f4LfLT9HADPDgjGRi0b6UuSJEm3nkzKpCorPX2aiw8+iNCZE6m0115HGxSEsbCQpBlPofHzI+jnn1A5X/1RX+q5sxxa+zNnDu41N9YCtO5e9L1/Is06dSFz8btknYxG5erKuglNUeoKaJc0CIBODl+hcmkAj+wD23/3KDG/VE9hqYGnfziGzmji6/0XuDvMhx8jEwHo2sSdIa3lKPOSJElS9ZBJmVQlwmQi9ZU5CJ2euABBsT20Pq0g4+2FlJ67ACYT+osXSZk9G7/33vt7PyG4cOwIB9et4lL0ccvyoLbtCL/zHqLOJdC4fScMyalkf/U1ALavPMvK9FcZEfssCqGguct+gu3+hG5v/6uEzGgSfLDtLO9vPYvpsg6VZQaTJSF7ok9TnujdBKVSPrKUJEmSqodMyqRKCaORjMWLKTl2gjKNgj/aD0erNxFyZiMl0WcAyKhvwj1dQcHvf1ASFYU2NJTYfbs4tG4VGRfiAVAqlTTv2oPwvoPwCm6BwWDg2PkLlMbEkPr4E4iyMuzaRbDBO5VG0W2pV9IArY2RO7QfgL07hI37V+X/36bTLL1spH2AJfdHsOC3UyRkFdM2wJUZfZrKhEySJEmqVjIpkyqV+tpr5H7/AwAbu42keVZPAPZ1aEmnQ29T6ljC0v7d6HIyie7HLrD3rTeJs1VRWJgPgEZrS0BhKQFn43FXuZD94ecoH5mO6/Tp2KSlk/zmAky5udg0aUzusw/yw6k36Jf4MABtbX9EqyyGO14Cjd11l33/+Sw+3WVOyGYNbE5kQjY+rnYMCKlPs/qOfLEnnoe7N5YJmSRJklTtZFImXUF3OoqkaRNw7nMH9kOmWBKyNf2a4qLvad5IY0CHL8dbtmJHSxs6XxhGqfYg21uA3lAEhWCjN9Lc2482A+4ia9bzABRHRgKQ+ckSjEYTAV98gUmvxzY0lLJ3XmDi9kl45TbEtbQ+GmUZobbroEk/6PRIpeXWG00cSsimTG+iY6N6GE2CmT8eQwgY3c6f6T0bA40t2zfydOT1e27cROWSJEmS9F/IpEy6QuqcmZSmllHywxZsjyQBUNakjGzHvjjnQNOuHhSLQpL2lnI0KJjgCwWUlXwGGNCrVdgbjTRT2lH/1GlUMQnk7D8CgMrNDU2DBpTGxIAQ5CxdihKwjYjA/4P3eTvuMwzCQNf8uwBopt2BjY0Chn4Ayit7RO4+m8lH2+PwdbNjQIg3H247y7HEPAAaezoQ6O5AUm4J/vXsmD2k5S2JnSRJkiT9WzIpq20MOlBp/vVwEfkbN1B0PJk85yDsStJRnDoNNjC/px/d48yJTYf+TYg/HkN80Woa5MQC5tbzCpUX2IXh1HYlffq+wsVXPqXo2BlMxcXg4EDOl6/SwKcZ29+bQa9vTgGQfteddJ4/H6VGzeb4LXQ/dy/u6UEAhNj/AR2ngnODCmUUQrB48xne3xZnWfbzYXODfSdbNRqVknMZRZzLKEKpgHfuDcNRK7/qkiRJUs0mf6lqk/RTsLQ7hD8Idy667t2zV6wg7c0FZLq34njodNyzomlz4mO2dVLSLO0BEArcfLPYumwBCceOWPZTqgPpOno0h3YWQaGWyMIghv44DkcvDcVqTzS+Abx7t5IdB54CQOUrEN2cuW/obM6YjCgUCg6nHcYzvhkt07sC0MZ+LZ62idDlScCciG09lU5CVhEH4rPZHJMGwNiOAWQUlHExq5jmDZx4bmBzhBA8+X0UDlo1T/RuQruG9f5rZCVJkiTpppNJWS2SeuJ7nnYNZuDpn3gg4kHwrmJ7qdI8TFsWkLl4LQBRLXqgBLLqNSfDR8Mpr5E0Szag131LSrQ5GVIolNi6NMdoDCewdTAdhrYlr/gYZ3ZkoSzoQNdmMRAIs72z6RTRhoxj+Qy41J8LbtFEJA5gR9PfmdS/D2z6g0J9IfN3v0mXpAcB6B5ynNCs5dByFDi4k1FQxhPfHWXf+SxLkdVKBXOHhnB/p8CrvqVV07v86zhKkiRJUnWQSVkt8mt8Jl2jXyXaNYaUtdNo0HseNO1rfaeSXMTSbhw8kYdLqQPJnvVQqJsDIBD8GB5K0LlY9KaDAKg1NrTq3Y+IO4dRmKvl5J9JdB3ZBIA2nYM4syOLhtmhDD8+ExBsbrCGsuNr6Rb/MQBBOa0B6HRxKOfSj6M0FPPK9jk0i+yNvd4JB4cSWuYsMJctYgJ74zJ5fvUJLmYXY6tR0r2pJ3Y2Kh7t1YRm9Z1ufBAlSZIkqZrIpKwWKUr1QAME5LbknXwXHv1hNA3HroZGPa65j+HPhTylKWZQXH0Mbn4cDemDrUmHoewYhrKjBOUWA6BQ2dLxnntoO3AI9s4uALjWB79gN8uxPAOccPO2Jye1GK+iAAA0iWM44hlFk3+8rq3BgeXfvINW54ZPVh+cytxRKnT0tlmIylSCodmdPLPPnjXHDgAQUM+e5RPb08jT8cYFTJIkSZJqEJmU1SJFZWpc//q3+6VJzG4QyOz1T9Bs2j6w+ceclELAiZ/4OeYb1KmDudh0KAalHnXxEcp0W0GYp1JC6YRaG0GP+4cR1rcx1igUCu5+qi1p8fkolArWfRqJW2l93C4NAKB5XyWNxQXWRwkUWQEEJTxs2VelTme4y//wCqpHcdgSRu/140RyCiqlgvGdAnmiT1PqOdjcoEhJkiRJUs0jk7LaQghEiavlTyddPTpdGMWHDfNYvOJOVEVZ5hHxDSWQeRbsXEk48T0/O3ajR05vSsp2YNKdBkwAePgHorbvgK4sCDdvR0K6NfzrZQT7z2dTZjDSMcgdOxtVhWI4uGhpFOYJgLZNEcbD5kSqzLGAHkPvQm3TkwD7P7n0qxGAQpc0QsID6D94CBq7YWw6ncPbf8RyNj0fdwcbPrk/gg5BsqG+JEmSVPvJpKyWEAWpOBaZk6FWJz+j5P5HORelIyBxNC/bvoJOU8igg4tRABc0alwNJj61a0TvI57oyr6yHMe/ZSjt7x5JwzbhKP4xrMal7GIe+eYIJ5LMY4F5OGr58eFOXMwu5tVfY2ji5cibw0Nxd9QCMPieTnyS+AsuHnY8MmEM6r8SuAF9uvD5yY24+zrg62jPgDs7oNFo+HhHHP/bFAtAPQcbvnmoI829/93k45IkSZJ0u5FJWW2w5z2yt7yK2vQdKMC54AL1v3qB5LCnwOCK7cWnSa13gjfdjlGkLiQwzYkml1T0y1cCKQA00NjTa+5rNGgSfMXhjSbB5pg0Xll3krT8MhxsVDho1aQXlDH60/1kFJQBcD6ziFOp+fzySFc8HLUEePry5rzHAMgp0nE8MZdQXxeSC3VMe3YoJqOBjRs3ci6jiA+2n2fDCXNZJnUN4tFejS3JnSRJkiTVBTIpu92d/5M/di/gc/dgeqSoUZgMaMtyEWWCNvveI7Ljc3gU++Fe5E3LBHcUxSdQGPP+2lmFRt2MFonn6Tz/SRz/SsgMRhN/xKQR5u+Km70ND688zM4zGQA0q+/IV5M6YjCZGLB4pyUhu69DALvjMriUXcK9S/YR5OGArUbFwz0a4etqx9AP95CUW4KHo5bMwjLuDG3Aw90a8nO8kv0H96I3mgegfaJPU57u1+yWh1GSJEmSqptMym5nUd8Su/kl1hc+So9487hctqVZ+L33LkJXRvKs52l9+B3OhN9BVv4plCZzT0oUWlTaNrgqA2kb+SFODb1x6GLe32A08fSPx1h3LJkGLrb4u9lzMCEbO42KiV0b8nD3xrjYawB4b0xbVuxLYGr3RnRr6klceiHDP97D+cwizmcWAbA7LhP/enYk5ZYAkFloTuI2nEj5q2ZMCQh6Bnvy/KDm8nGlJEmSVGfJpOw2VXZyPUt+OkRx0XyCS+tbltuWZmPbvAtlTg5cGjaYU7HRGHIPA6BQOKLVhBCceBZdAxt8T3yInYstPoveRqFQ8Ed0Ki+tOWmp/UrJKyUlrxQnrZrlk9oTEVixwX3flvXp2/Lv127i5cimGd3ZeSYDpULBNwcvcuxSLnlJepy0aj4Y25bMQh2peSUs+uMMAGH1TDxxVzt6tfC+og2bJEmSJNUlMim7DRw8cRyf+p74ef01B2RpHh9+H4lt1hD+Wa9kFLls27CaU7v/xGQ0gEqJY6mORum5uBdlYmM4hcqkg5RDKB0dCVyxHG3jxsSmFvDk91GU6I242WuY0q0RH2w7i51GxVeTOhLq51Klsvq42jGmg3mMsl7NvZj7azTezrY82LkhAe7mYTmEEDSr74SXo4YLUbvp1tRDJmSSJElSnSeTshruwPFjHPw4g1Lbc3R5MJCkpHTsc05im9kdALWbHt+EKEwZx4j3ciVdeZH0P837+jYPocPdI/EPbITu7FkuTpyE0tERxx79Kdy1C5+FC9A2bkxhmYHp3xymRG+kW1MPlj3YHhu1klERftjZqHCy1fyrsns6aflobPgVyxUKBf1DvNHr9VyI+reRkSRJkqTaRSZlNdyebSfR0gD7UheiluYCNhRpA3AADO7HiEg6SkxBEjnudmDMBwHOLdpy57ix+DRrYTmOxt2dhj/+iMrFGZuAAITJhEKpRAjB86uOcz6jiAYutrw7OgwbtRIAL2fbannPkiRJklQXyaSsBivTlyHirpzf0b7UFYPuJOpT29ijEeBgh9Ik8M0pIFXpwxtlndi5K5+OiWeZfEcjywCvdqGtLMdQKM2J19f7L7D+eApqpYIPx4bLYSgkSZIkqZrIpKwaFWzdSnHkYbyefgqF5spHhJt37sHW4EipOh/vet+TVBKCNkOLofQwiCIMGlCjILRzN1p3uIN9Cz/hB/8+AOw6m8mus5n8GJnIy3e2wEatpI2fKyYhyC814Omk5ePtcXy26zwALwxuQUSg2xVlkCRJkiTp1pBJWTUpO3+exEfNA6vahbbCefDgK7aJ2X0OBxpjq9qLj3MTsuOPotPpAFAKLS0Vgu5Ll2Hn6obOYOLl8ELySvS8dncIBpPg053nuZhdzNSvzb0vPRxtKNObKCgz4O5gQ1aR+Vj3hPkwqWvDW/PGJUmSJEm6KpmUVYP8rDTiZ81Bb+eFUKqJ27KTsIEDUf71SPF41D727YnCLtETfekfmLKjOZJq7p2oMdkiHLvT/MIJur5yP7kKW6YuO8Cus5kAOGrV3NchALVKycgIPxb9HsvaY8koFQoyC3WWMmQV6fB1tWPu0BD6tvCSvR8lSZIkqZrViqRs/fr1zJw5E5PJxKxZs5gyZUp1F+maEs4eZf2iZBTuk8D9r4XFcGLZxzz40GNkZabxx5LjqApjMek3mNcrFLgVlZiHtSjUk+9iwLXgPA+eGM/h37ZVOH7bAFfUKnNy52SrYd7drZh3dyuKdQY+2BaHh6OWdoFuHLmYw4gIP5z/Zc9KSZIkSZJurNs+KTMYDDz99NNs374dFxcXIiIiGDZsGO7u7pXvXA0OrN6EQtERhTBiUJSh1ZswaBzJjKpP7IHdrF+6BEVRLqa/tncus6VlaSHeT81GqYCSebOplxXLqiY9OJxYAEBEoBsB9ez55WgSI8L9rvq69jZqZg1sbvm7jb/rTX6nkiRJkiRdj9s+KTt48CAhISH4+voCMGjQIP744w/uu+++ai7Z1RXEm2uxnPN38HJgFxbt/oS0oN4oDCdZ/07WX1sp8SwUNErPwa0wm2fueJRT283TFnmFT6XvpUjWNO7OnaENmDOkJfX/Grpi7tAQXOxkzZckSZIk3Y6U1V2AnTt3MmTIEHx8fFAoFKxZs+aKbT766CMaNmyIra0tHTt25ODBg5Z1ycnJloQMwNfXl6SkpFtR9H/FpDOXNU2bT1jeMc752FKq+xNhygJsUGkj8CtrS/tzcbgXZPFL4+6ccm+ISqlApVSQ7lCPb5v3J8Dfk8WjwywJGSATMkmSJEm6jVV7TVlRURFt2rRh0qRJDB8+/Ir1P/zwA08//TRLliyhY8eOvPvuuwwYMIDY2Fi8vLyqocT/Xualc+hUThhK9mDUJdKtJB4UoDIKnEQgJe53YWM00Ch+PjO7PUqZSsPFen78b3hr7gxtgAB2n81g3bFkZvYPtgzyKkmSJEnS7a/ak7JBgwYxaNCga65/5513eOihh5g4cSIAS5YsYcOGDXzxxRc8//zz+Pj4VKgZS0pKokOHDtc8XllZGWVlZZa/8/PzAdDr9ej1+v/6dirQ6/Ukr9fy2YYd5r91hzGU7AOMqABX7wb4dhvIF7uzeGbrEgwOidiUZrO47TCCenZGAbze0Z92gW6AAKBPsAd9gj0sx7+dlZf/dn8fN4uMj3UyPpWTMbJOxsc6GR/rqhqf64mfQggh/lOpbiCFQsEvv/zCPffcA4BOp8Pe3p6ff/7ZsgzgwQcfJDc3l7Vr12IwGGjRogU7duywNPTfu3fvNRv6z507l3nz5l2x/Ntvv8Xe3v6Gv6ekDfYIpXlEfWNZNPri31EpnPC8oyMOvoEolEqyy2Dr6WKaHdlLjmcDmvQKwc/hhhdFkiRJkqRbrLi4mLFjx5KXl4ezs7PVbau9psyazMxMjEYj9evXr7C8fv36nD59GgC1Ws3bb79Nr169MJlMPPfcc1Z7Xr7wwgs8/fTTlr/z8/Px9/enf//+lQbreun1en66uITmzYNRKVWknjaQcqIpXcffRdMO3Stsez8AI2/o69d0er2ezZs3069fPzRXmdGgrpPxsU7Gp3IyRtbJ+Fgn42NdVeNT/kSuKmp0UlZVQ4cOZejQoVXaVqvVotVeOb+jRqO5KV8614DGhPfsbz52n4E3/Pi1wc2KfW0h42OdjE/lZIysk/GxTsbHusricz2xq9EtxT08PFCpVKSlpVVYnpaWhre3dzWVSpIkSZIk6car0UmZjY0NERERbN261bLMZDKxdetWOnfuXI0lkyRJkiRJurGq/fFlYWEhcXFxlr/j4+OJioqiXr16BAQE8PTTT/Pggw/Srl07OnTowLvvvktRUZGlN6YkSZIkSVJtUO1JWWRkJL169bL8Xd4I/8EHH2T58uWMHj2ajIwM5syZQ2pqKmFhYWzatOmKxv+SJEmSJEm3s2pPynr27Ello3I89thjPPbYY7eoRJIkSZIkSbdejW5TdjN99NFHtGzZkvbt21d3USRJkiRJkupuUvboo48SExPDoUOHqrsokiRJkiRJdTcpkyRJkiRJqkmqvU1ZdStvz3Y9I+5WlV6vp7i4mPz8fDnw3lXI+Fgn42OdjE/lZIysk/GxTsbHuqrGpzy/qMqslnU+KSsoKADA39+/mksiSZIkSVJtVVBQgIuLi9VtatSE5NXBZDKRnJyMk5MTCoXihh67fF7NS5cu3fB5NWsDGR/rZHysk/GpnIyRdTI+1sn4WFfV+AghKCgowMfHB6XSequxOl9TplQq8fPzu6mv4ezsLL/QVsj4WCfjY52MT+VkjKyT8bFOxse6qsSnshqycrKhvyRJkiRJUg0gkzJJkiRJkqQaQCZlN5FWq+WVV15Bq9VWd1FqJBkf62R8rJPxqZyMkXUyPtbJ+Fh3M+JT5xv6S5IkSZIk1QSypkySJEmSJKkGkEmZJEmSJElSDSCTMkmSJEmSpBpAJmWSJEmSJEk1gEzKJEmSJEmSagCZlElSNZCdnq2T8bFOxsc6GR/rZHwqV10xkkmZJN1ChYWF6PV6FAqFvDBehYyPdTk5OZSUlMj4XIOMj3Xy/KpcdcdIJmX/gslkqu4i1HgyRlc6deoUw4YN44cffkCn08kL4z/I+Fh36tQp+vfvz1tvvUVxcbGMzz/I+Fgnz6/K1YQY1fkJyasqLi6OP//8k8mTJ6NUKjGZTJXO9l7XyBhd24ULFxgxYgTnzp2jsLAQW1tbhg4dio2NDUIIFApFdRexWsn4WHfx4kXuu+8+UlNT+f3337Gzs+PRRx/F3t5exgcZn8rI86tyNSVG8hezCs6ePUuXLl14/PHHWbRoEYAl6ZDMZIyuzWg0smrVKpo0acLBgwdxdXVl/vz5rFu3Tt6xIuNTGSEEv/32G97e3mzYsIHWrVvz008/8dFHH1lqhOryeSbjY508vypXk2Ikp1mqRHZ2NpMmTcJkMtGkSRM2btzIxIkTmTVrFoCsDULGqCqioqKIi4tj5MiRmEwm7rzzTtLS0njxxRcZMmQIWq22Tt+xyvhYl5KSwv79+xk2bBgA06dP5/Dhw4waNYpHHnkEBwcHGR8Zn2uS51flakyMhGRVRkaGuP/++8Wvv/4qLl68KF588UURHBwsFixYYNnGaDRWYwmrn4xR5XQ6XYW/y8rKxMCBA0Xbtm3FTz/9ZFm/Zs2a6ihetZPxse6f549erxfTpk0T7du3F//73/9EUVGREEKIL7/8shpKV/1kfKyT51flakqMZE2ZFeU1PFlZWbi7uwPm585Lly5l9erVFWqD9Ho9Go2mOotbLWSMri4zM5NLly5hb2+Pl5cXbm5ullgZDAbUajVlZWXcc889pKWlMWvWLLZv3866deuIjIzEx8enut/CTSXjY11KSgqxsbGo1WqaNGmCt7e3ZV15fPR6PU888QSHDx9mxIgRnD9/nmXLlnHu3DkCAwOrsfQ3n4yPdfL8qlyNjdFNTfluU9eq1TEYDEIIIS5evCheeOGFCrVBDz/8sJg/f/4tK2N1kzG6tmPHjolmzZqJxo0bCz8/PxERESH27dtXYRu9Xi+EMN+NDR48WGg0GuHg4CAOHz5cHUW+pWR8rDt27JgIDAwUTZo0ET4+PsLb21v8/PPPoqyszLJNeXzKa4S0Wq1wdnYWR44cqa5i3zIyPtbJ86tyNTlGMin7h1OnTokJEyaIkSNHismTJ4tTp06J0tJSIUTFRKQ86QgJCRHh4eFCoVCIgwcPVlexbykZo2tLSUkRAQEB4rnnnhOxsbHil19+EWPGjBEajUZ89913FbYtT2CnT58u6tWrJ06ePFkdRb6lZHysS09PF82aNROzZs0SycnJIjIyUjz11FNCpVKJBQsWiPz8fMu25fF55JFHhJubm4yPjI88v6qgpsdIJmWXOX36tHBychKjR48W06dPFyEhIaJp06bi3XffFdnZ2UKIiklHXFycaNGihXBzcxPHjx+vrmLfUjJG1h09elS0atVKxMfHW5YVFxeLZ555RtjY2Ij169cLIf6O0UcffSQUCkWduIMXQsanMufPnxfBwcEiMjKywvLFixcLhUIhPvjgAyHE3/H54osvZHyEjE85eX5VrqbHSCZlfzEajWL69Oli9OjRFZY/9NBDok2bNuKNN94QeXl5QgghTCaT0Ov14rnnnhNarbZOJBtCyBhVxY4dO4RCoRDnz58XQvx9YptMJvHoo48KZ2dncebMGcv2mZmZ4ty5c9VS1uog42NdVFSUsLGxEYcOHRJCVGx8/Oabbwq1Wn1FQnL5j0ttJ+NjnTy/KlfTYySTsstMmDBBDB8+XBiNRsvzZCGEePLJJ0VISIj4+eefhRDmDy87O1uMGDGiTt1hCCFjVBmDwSC6d+8uRo8eLbKysoQQf5/0iYmJonv37mLevHnCZDLVyR6pMj6VGzp0qOjYsaNIS0sTQpjbtphMJmEymcRdd90lHnjgAaHT6Sq0oapLZHyuTZ5flavpMarbg0f9g6urK3FxcSgUCkvPC4B3332Xxo0b89prrwGgUChwc3Pju+++o23bttVZ5FtOxsg6lUrF6NGjSUhI4P333yc/P98yRpuvry+Ojo6cPn0ahUJRJ8duk/Gp3MMPP4xGo+HZZ58lMzMTtVptGR/J29ubzMxMNBoNNjY21V3UaiHjc23y/KpcTY9R3fxUruHll18mJSWFCRMmAKDVaiktLQXgww8/JD4+ni1btli2V6vr3ixVMkbXJv4aXWb69Ol07dqVtWvX8sYbb5Cfn2/Zxt3dHU9PT4xGY50bRVvGp2oGDRrEvffeS0xMDNOnTyctLc3y46BUKnF1dUWn08n4yPhUIM+vyt0WMbrldXM1VHk15U8//SRcXV3F5MmTK6w/c+aMaNq0qaUtQ10kY2RdeU+d8ji9+uqromPHjiI4OFg8++yzYsyYMcLR0bHO9HL6Jxkf68rjU1JSIoQQ4quvvhLdu3cX7u7uYvz48WLo0KHC0dGxzrTP/CcZH+vk+VW52yFGsqbsL+Vzow0aNIh3332X1atXc9ddd3Ho0CGio6P5+uuvKSsrqxOD6l2LjNHf/jmXntFoRKVSceHCBUJDQ9mxYwezZ89m4cKF9O/fnxMnTqDVatm3bx8hISHVVOpbR8bHOvGPO/DL4xMYGMjq1asZP348X375JTNmzACgYcOGHDhwgNDQ0Goo8a0l42OdPL8qd9vGqNrSwRqkPHs+f/68WLZsmSgrKxP79u0TrVq1En5+fiIoKEg0bty4zgysdzUyRma5ubmWf/+zEWhCQoLw9fUVDz/8cIVOEEKIOtOwVsbHuvKGxUKY3/PlLl68KHx8fMS0adOuiE9dIeNjnTy/Kne7x6hOJWVXC3j5iZ+QkCA8PT3FhAkTKmx/6NAhcfToUZGSknLLylmdZIyuLTo6Wri4uIg33njDsuzyeE2cOFFMnTq1wo/JP39YajMZH+uio6OFWq0WTz75pGXZ5e//xRdfFE899ZSMj4zPVcnzq3K1IUZ1Jik7e/as+PTTTyvciZXLyckRrVq1ElOmTLF8gOU1Q3WJjNG1Xbp0SbRt21Y0a9ZM1KtXT7z55puWdeVx+OeEtnWJjI91SUlJokOHDiI8PFw4ODiIGTNmWNaV/yjU1dofIWR8KiPPr8rVlhjVia5xZ8+epV27dhQUFFBQUMCUKVNwdna2rC8oKGDevHkMGzYMhUIBmLvN1iUyRtdmMplYtWoVQUFBPPbYYxw8eJD58+cD8Pzzz6NSqerUZOv/JONjnRCC7du3ExgYyIwZM7hw4QITJ05EoVDwzjvvoFAoLBMg10UyPtbJ86tytSlGtf5bXlBQwNy5cxk5ciR+fn4888wzGAwGpk2bZkk6/P398ff3r+aSVh8ZI+uUSiWDBw/Gy8uLXr16ERYWhhCCN998EzCf9BqNBpPJVCfH/pHxsU6hUNCtWzecnJzo0qULXbp0QQjBpEmTEEKwePHiCmNt1TUyPtbJ86tytSpG1VNBd+ukpaWJt956S/z4449CCCHeeecdoVAoxMKFCy1TAtV1MkZVc3nbg4yMDLFgwQLh7OxsqSY3GAxi3bp1IiMjo7qKWK1kfKy7PD4Gg0F8++23QqvViqeeekoIYX48t3LlSnHixInqKmK1kvGxTp5flasNMar1NWVeXl7cd999+Pr6AvDUU08hhOCZZ54BsNQGGY1G0tPTadCgQXUWt1rIGF0pOTmZpKQksrKy6Nu3L0qlEqVSaXmM4uHhwaRJkwCYP38+QgiysrJ47733uHjxYjWX/uaT8bHu0qVLnDp1ioyMDPr164erqys2NjaW+KhUKkaNGgXAxIkTAXOX/U8++YS4uLjqLPotIeNjnTy/KldrY1SdGeHNUlZWJkpLS69YfnlD0bfffttSG5SRkSGeffZZMX78+KvuVxvJGF3bsWPHhL+/v2jZsqVQq9Wibdu24pNPPhEFBQVCiIodHDIyMsSbb74pFAqFcHNzqxMD58r4WHfs2DFRv359ER4eLmxsbERISIh49tlnRU5OjhCiYnwMBoP4+uuvZXxkfCzk+VW52hyjWpeUnTx5UowZM0a0b99eTJ06VSxbtsyyzmg0Vuge+/bbbwsbGxvRtm1boVKpRFRUVHUU+ZaTMbq2jIwM0aJFCzFr1iwRHx8v0tPTxX333Sc6duwoZsyYIfLz84UQFbtZjx8/Xjg7O4vo6OjqKvYtI+NjXW5urggPDxczZ84UWVlZoqSkRLzwwguiS5cu4u6777b0bL58ZPHJkycLZ2dnERMTU51FvyVkfKyT51flanuMalVSFhsbK1xdXcWUKVPE888/L0aMGCG8vLzEww8/bNnGYDBUeO7cvn174e7uXmem5pAxsu7EiROiYcOG4tixY5ZlZWVlYs6cOaJDhw7ipZdeskzzYjKZxNdffy3q169f6wfNLSfjY118fLxo1KiR2LFjh2VZWVmZ+OKLL0Tnzp3FuHHjLD8aJpNJbNy4UQQFBdX4u/cbRcbHOnl+Va62x6hWJWXz588XAwcOtGTI2dnZYuXKlcLR0fGKAU91Op147LHHhEKhqBPJRjkZI+tiY2NFUFCQ+PXXX4UQfz/O1ev14tlnnxVhYWFi586dlu3Pnz8vEhISqqWs1UHGx7qMjAzRqlUr8cEHHwgh/m54bDQaxUcffSTCw8PFV199Zdk+NTW11g+6fDkZH+vk+VW52h6jWpWUPfTQQ6JLly4Vlul0OrFq1Srh7OwsXnjhBcvyoqIisWjRotsme75RZIysKy0tFe3atRN33XWX5RFK+UlvMplEaGioeOCBByx/1zUyPtbpdDoxYsQI0aVLl6v+EPTv31/ceeed1VCymkHGxzp5flWutseohg/YcX0GDhxIamoqO3bssCzTaDQMHDiQl19+mU2bNhEbGwuAvb09Tz31FOHh4dVU2uohY3RtJpMJrVbLl19+yc6dO5k+fTpAhTGShg4dSnp6OkCdGzNJxsc6IQQajYaPP/6Yc+fO8cQTT5Cenl5hcu0hQ4aQmZlJaWlpNZa0esj4WCfPr8rVhRjVqqSsRYsW+Pn58dVXXxETE2NZbm9vz6BBg4iNjeXcuXOW5TV+ELmbQMbo2pRKJUajkVatWrFixQq+++47HnjgAdLS0izbxMfH4+bmhtForMaSVg8ZH+sUCgU6nQ4vLy82bdrEgQMHuP/++4mMjLTEIyoqCnd39zp1XpWT8bFOnl+VqwsxUojLb1NqgVWrVjFz5kz69+/PtGnTLLU8RUVF9OzZk1dffZVBgwZVcymrl4zR1ZWPb1NYWEhZWRlRUVGMHTuWwMBA6tWrh7u7O2vXrmXfvn2EhoZWd3FvOvGPEdRlfCr6Z3yMRiMqlYqsrCx0Oh0lJSUMGjQIR0dHDAYDjRo1YuvWrezevZvWrVtXY8mrh4yPdfL8ulJdvAbVmtsRvV4PwIgRI/j444/ZtWsXs2fP5rPPPuPo0aO88sorXLx4kVatWlVzSW+df+bbMkZm/4yLEMJysickJNCsWTMOHTpEnz59iI6OZvDgwfj6+uLl5cXBgwdv25O9qs6dO0dOTs4VCYeMj9k/78BNJhMGgwGVSkVCQgKtW7dm69atNGrUiEOHDjFjxgz69etH+/btOXToUK1POM6ePUtUVFSFZeUJmYyPvP5URZ2+Bt3qRmw3UnkPwvJGfvHx8eKJJ54QQgixZcsWMWXKFOHi4iJCQkJE8+bNxZEjR6qtrLdS+QB6lytvEFnXY3T69Gkxe/Zs8eCDD4rPPvtMnDp1yrLuwoULwt3dXUyePFmYTCZLzC7vIVbbRUVFCYVCUWHsunIXL14UHh4edTo+MTExYvr06eLuu+8Wzz//vIiMjLSsu3TpknBxcREPPfSQMJlMdSIe/1T+/fn444+vWHfx4kXh6upap+Mjrz+Vq+vXoNsqKUtLSxPHjx8XBw4cuGJdfHy8aNCggSXhEMKcrKWmpooLFy5YBiWs7Y4ePSruueceERcXd8W6hISEOh2j6Oho4eLiYun91bFjR+Hn5yc2b94shBDivffeEzNmzLiix07537djT57rERUVJRwcHMSsWbOuuv7999+v0/E5deqUcHZ2Fg8++KAYMWKE6Nevn7C1tbUM4fDLL7+ImTNn1oofhn8jKipK2NvbX/P78/PPP4unn3661n9PrkVefyonr0G3UVIWFRUlmjZtKoKCgixTdOzatUsUFBQIvV4v7O3txZQpUyp8KLXhA7oeUVFRQq1Wi2eeeeaKdTk5OcLR0bHOxshgMIj7779fjBs3zrLs6NGjYsqUKUKlUok//vjDsl1ddOrUKaFWq8Wrr74qhDDfcW7dulUsXbpU7NmzR6Snp1uW11WPPPKIuOeeeyx/p6WlidmzZwuVSiWWLFkihKi78Sn//jz//PNCCPN1ZdWqVWL+/Pniu+++s9wk1tXzS15/KievQWa3RVKWkpIiGjVqJF588UVx7NgxcejQIdG3b1/h4+MjPv/8cyGEEHv27Kn1H5Y1J06cEPb29uLll1+2LMvPz7d8kYUwP66sqzHS6XSiR48elh+Ncunp6WLatGnCzs5O7Nu3r5pKV72MRqOYN2+eUCgUlqlsevfuLdq0aSNcXFxEo0aNRJ8+fSqMoF0XDR8+XEyePPmK5W+88YZQKBRiw4YNQoi6c6NzuSVLlgiFQiHWr18vjEaj6NGjh2jfvr0ICAgQrVq1Eo0bNxZ79+4VQtTN+Mjrj3XyGvS32yIpi4yMFE2aNBGnT5+usHzixInC19dXfPfdd9VUspohLS1NuLi4iF69elmWTZs2TXTu3Fk0b95cDBw4UGRkZAgh6uYFsdyjjz4qOnfuLLKzsyssv3jxohgxYoQYPHiwyMvLq6bSVa/U1FQxdepUodVqRatWrcTw4cNFVFSU0Ol0YvXq1aJ///5i1KhRV22vWFfMnTtX+Pv7i6SkJCHE3+eSTqcT06ZNEy1atKhTo8//09y5c4VKpRKNGzcWI0aMELGxscJgMIiDBw+KUaNGiXbt2om0tLTqLma1kdcf6+Q1yOy26H1ZUFBAbm4uGo0GgOLiYgC++OILunfvztNPP01GRgZwZc+WusDLy4v+/fuTl5fHsmXL6NSpE3FxcYwaNYrHH3+cpKQkunfvTlFREQqFok7GCKB79+6UlJTw5ZdfUlBQYFnu7+/PkCFDiIqKIi8vrxpLWH3q16/P66+/zqRJk7C1teX111+nTZs2aDQahg0bxqBBg9i1a1edi4/JZLL8e9CgQQQEBPDmm2+Snp6OQqHAZDKh0WgYOXIkeXl5pKamVmNpb73Le6K+8sorzJs3D3t7e15++WWaNWuGSqWiffv23HvvvcTHx1cYT6qu6d69O6WlpfL6cw3l16DJkyfX7WtQdWeFVWE0GkXLli0rtOcoLS21/LtFixbi8ccfr46iVTudTmf599ixY4VKpRJ33313hceWSUlJIjAwUMycObM6ilgt4uPjxaeffio+//xzsWnTJsvyxx57TDRr1kx8/PHHFTo2REdHiyZNmojo6OjqKO4td634pKeniz179oiysjIhxN9tXH799VfRokWLCt+r2iwnJ8fy78vb+SxYsECEh4eLZ599ViQmJlqWJyYmiqZNm4rdu3ffymJWm2vFRwhzW6nyCaHLm0vs2bNHNG/e/KodkGqjpKQk8euvv4pVq1ZVmEx9+vTponnz5nX++iPEtWOUnJws9u3bV2evQTUyKSsqKhJGo9FyYgshxPr160VAQECFnoPlH9qYMWMsc13VFVeLkRBCvPTSS+L777+vsMxgMIgePXqIqVOn3soiVpvjx48Ld3d30alTJ9G4cWPLZOv5+flCCCEmT54sWrVqJWbMmCHi4uJERkaGeO6550SzZs1EZmZmNZf+5rtafCZNmiRSU1Ovuc+TTz4p+vXrJwoLC29hSatHTEyMCAoKErNnz7Ysu/zmZ86cOaJjx45iyJAhIioqSpw9e1Y8//zzIjAwsE48vrxafCproD5z5kzRpUuXCslcbXX8+HHRqFEj0aFDB+Hh4SHatWtXoYnNhAkTRGhoaJ29/ghx9Rj9+OOPlvVXa2ZTV65BNS4pO3HihOjbt6/o2bOnpUYjMTFRGAwG8fbbb4smTZqIhx56qMI+Y8aMEQ899JAwGo11os3UP2P0ySefiDNnzljWFxcXV9her9eLoUOHirfeeksIUbvblRUUFIjOnTtbak5TUlLEb7/9JurVqyf69OljadMyb9480a1bN6FQKERERITw9vau9WO0CWE9PgMGDBDnzp2rsP2FCxfEM888I+rVqyeOHz9eHUW+pS5evCjCwsJE06ZNRatWrcS8efMs68pvAoUQ4ssvvxSDBg0SCoVCtGrVSgQGBtaJ74+1+FwtMTt16pSYMWOGcHNzqxONtOPi4oSfn5947rnnRG5uroiMjBQPPvigmDRpUoWnO3X1+iOE9RgZDIYrfp/q2jWoRiVlZ86cEZ6enmLGjBnip59+EnPnzhUKhUIMGzZMHDt2TOh0OvHJJ58IHx8f0bZtWzF9+nQxbtw4YW9vL06ePFndxb8lrhWjESNGXPXRicFgEC+//LLw8fG54ge3NiopKRHh4eFX1BbGxsYKDw8Pcdddd1mWpaWlid9++03s3r1bXLp06VYXtVpUFp977rnH8uO6d+9eMWnSJNG8eXNx9OjRaijtrWUymcTChQvF4MGDxR9//CFeeeUV0bx582smZkIIceDAAREdHV0nasiqEp/LE7Pjx4+Lp556SoSGhoqoqKjqKPItVVZWJp5++mlx7733VvieLFu2TLi7u19RC5aZmVnnrj/XG6MDBw7UqWuQEDUsKXvyySfFmDFjKiybMGGCsLW1FcOHD7d0lT137pyYMGGCGDVqlHjggQfEiRMnqqO41eJaMbKzsxMjR44Uhw8ftizftm2bGDlypPDy8qozd2GFhYXC19e3wg9F+aOnY8eOCQcHBzF37tzqKl61q0p8XnvtNcu67du3V2g7VdulpKSI5cuXCyHMSXt54nH5d+byR5l1TVXic/mwO0ePHq0TCasQ5hued955R3z22WdCiL+fSJw6darCo+26OiyREFWP0eW2bNlSp65BNSopGzlypHj00UeFEMLS/uf1118X/fv3F82aNRMvvvjiFfvUtcH2rMUoODhYvPTSS0II85d/z549YsaMGXWq8agQQrz99tvCz89P/Prrr5Zl5T+kr7/+uujYsaPIysqqsxfHqsSntjemrark5OSrJh5r1qypc9eeq7lWfFatWlWNpao+58+ft/y7POFISUkRTZo0ERcvXrSsqys3yVdT1RhdPoVZXVKjkrKnnnpKNGjQwNKQLyUlRbi5uYnNmzeLTz75RNjZ2V1RzVub20ddTWUxsre3t3yxTSZTrb+rT05OFgcOHBCbNm2qML/nqFGjRLdu3cTvv/9eYfslS5aIFi1aiKKiouoo7i0n42Pd1eIjhKjQPjUpKcmSeLzyyitixowZQqFQWMYrq81kfKwrj89vv/1W4Sbv8lidPn1auLu7W67Ls2fPFm5ubiIzM7NO/H7JGF2fGpWUXbhwQXTp0kVotVoxcOBAYW9vb2nUn5mZKXx9fetMl/NrkTH627Fjx0RgYKBo1qyZcHFxEcHBweK7774TOp1OHDp0SNx1112iffv2lp5POp1OPPfcc6JHjx6WWsbaTMbHun/Gp3nz5uLbb7+1DFVweeKRnJws5syZIxQKhXBzc6sTd/EyPtZVFp/y2MTGxgpPT0+RnZ0tXnvtNWFnZ1cn4iOEjNG/UW1J2enTp8Xzzz8v7r//fvHWW29ZeuYUFBSIBQsWiPnz54uVK1datj9y5Iho2rRpnWo/JmN0benp6aJ58+bixRdfFOfOnRNJSUli9OjRolmzZmLevHmitLRUREVFiWnTpgm1Wi3atGkjOnXqJNzc3OpEg1EZH+uuFZ8WLVqIV155xfL49vK79PHjxwtnZ+c60RxAxse6qsZHCHPbu7Zt24rRo0cLGxubOpNsyBj9O9WSlEVHRwtXV1cxatQoMW3aNOHv7y/CwsIsk/oKcWVjyOeee06EhYVZpguq7WSMrIuOjhYNGza84uSdNWuWCAkJEYsWLRImk0kUFhaKffv2iddee00sWbJEnD17tppKfGvJ+FhnLT6hoaHif//7X4VHuJ9//rlwdXWtM22BZHysu574xMTECIVCIezs7OrEDU85GaN/55YnZQUFBWLAgAHiueeesyxLTEwU7u7uon79+hV6fgkhxM6dO8Xjjz8unJyc6syHJWNUuaioKOHn5yd27twphKg4NtsTTzwhAgMD68S4SNci42NdZfEJCgqqEJ/U1NQKDZRrOxkf664nPikpKeLRRx8Vp06dqpayVhcZo3/nlidlRUVFon379uLbb7+1/C2EEKNGjRJ9+vQRXbp0ERs3brRsv3v3bjF9+vQ6Mw6ZEDJGVdW+ffsKk7BfPjhju3btrhg6pK6R8bGuqvGpq70sZXysu57z658zr9QVMkbX75ZOSC6EoLCwkKSkJJKSkgCwt7cnMTGR6OhoHnjgAQoLC1m9erVln65du/LOO+8QEhJyK4tabWSMrq6oqIiCggLy8/Mty5YuXUp0dDRjx44FQKvVYjAYACwTsNcVMj7W/Zf4qFSqW1/gW0zGx7r/en7Z2tre2gJXAxmjG+OWJGVGoxEAhUKBl5cXL774Is899xyTJ09m9uzZtGjRgq5du/LAAw8we/ZstmzZQlZWluXDqwsflozRtcXExDB8+HB69OhBixYt+OabbwBo0aIF7733Hps3b2bUqFHo9XqUSvNXOj09HQcHBwwGA0KI6iz+TSfjY52Mj3UyPtbJ+FROxugGutlVcbGxsWLRokUiOTnZssxoNIrly5eL9u3bi4EDB4qFCxda1n3wwQeibdu2dWpsEhmja4uOjhbu7u7iqaeeEt988414+umnhUajsTQoLioqEuvWrRN+fn6iefPm4p577hH33nuvcHBwqBO9UGV8rJPxsU7GxzoZn8rJGN1YCiFuXooaFxdHx44dycnJ4fnnn+fpp5/Gw8PDsr60tBSFQoFWq7Use/zxx0lNTeXrr79Gq9WiUChuVvFqBBmja8vOzua+++6jefPmvPfee5blvXr1IjQ0lPfff9+yrKCggNdff53s7GxsbW2ZPn06LVu2rI5i3zIyPtbJ+Fgn42OdjE/lZIxuPPXNOnBRURFvvvkmQ4cOpX379jz22GMYDAaee+45S9JxeUJx+vRpli5dyooVK9izZ0+tfhxXTsbIOr1eT25uLiNHjgTAZDKhVCoJCgoiOzsbMLfBE0Lg5OTEwoULK2xX28n4WCfjY52Mj3UyPpWTMbrxblpSplQqiYiIwN3dndGjR+Ph4cGYMWMALElHebJRUFDA5s2bOXr0KDt37iQ0NPRmFatGkTGyrn79+qxcuZKmTZsC5nZ3SqUSX19fLly4AJjb4CkUCvLz83F2drYsqwtkfKyT8bFOxsc6GZ/KyRjdeDctKbOzs+PBBx/EwcEBgHvvvRchBPfddx9CCJ5//nnc3d0xGo2UlJQwffp07r//ftzc3G5WkWocGaPKlZ/sJpMJjUYDmO+80tPTLdu8+eabaLVannjiCdRqdZ064WV8rJPxsU7GxzoZn8rJGN1YNy0pAyzJRnn2PHr0aIQQjB07FoVCwYwZM1i0aBHx8fF8++23dSrZKCdjVDVKpRIhhOVkLq/6njNnDq+//jpHjx5Frb6pX+caTcbHOhkf62R8rJPxqZyM0Y1xSyKkUqkQQmAymRgzZgwKhYLx48ezbt06zp07x8GDB7Gzs7sVRamxZIwqV37Cq9Vq/P39WbRoEf/73/+IjIykTZs21V28aifjY52Mj3UyPtbJ+FROxui/u2Vpa3n2LIRg9OjRfPrpp0RFRXHkyJE60T6qKmSMrCu/89JoNHz22Wc4Ozuze/duwsPDq7lkNYOMj3UyPtbJ+Fgn41M5GaP/7pZ2f1AoFJhMJp5++mm2b9/O9u3bZbLxDzJGlRswYAAAe/fupV27dtVcmppHxsc6GR/rZHysk/GpnIzRv3dTxym7GqPRyPLly4mIiCAsLOxWvvRtQ8aockVFRZb2eNKVZHysk/GxTsbHOhmfyskY/Tu3PCkDKjQGlK5OxkiSJEmS6pZqScokSZIkSZKkiuSQupIkSZIkSTWATMokSZIkSZJqAJmUSZIkSZIk1QAyKZMkSZIkSaoBZFImSZIkSZJUA8ikTJIkSZIkqQaQSZkkSZIkSVINIJMySZIkSZKkGkAmZZIkSZIkSTWATMokSZIkSZJqAJmUSZIkSZIk1QAyKZMkSZIkSaoBZFImSZIkSZJUA8ikTJIkSZIkqQaQSZkkSZIkSVINIJMySZIkSZKkGkAmZZIkSZIkSTWATMokSZIkSZJqAJmUSZIkSZIk1QAyKZMkSZIkSaoBZFImSZIkSZJUA8ikTJIkSZIkqQaQSZkkSZIkSVINIJMySZIkSZKkGkAmZZIkSZIkSTWATMokSZIkSZJqAJmUSZIkSZIk1QAyKZMkSZIkSaoBZFImSZIkSZJUA6iruwDSlYQQ1V0ESZIkSbqtKRSK6i7CdZNJWQ0jhMBkMlV3MSRJkiTptqZUKm+7xEwmZTVIeUKmUChuuy+SJEmSJNUU5b+nt1tiJpOyGkgmZZIkSZL039yOTYFkQ39JkiRJkqQaQCZlkiRJkiRJNYBMyqQq+/LLL1EoFKxZswaA9PR0Bg4cSNOmTWnVqhU7d+6ssH1kZCSDBg0CICcnh3HjxtGsWTNCQkJ4/vnnLdsdOHCANm3a0KxZM3r37k1SUtIte0+1RcOGDfHy8kKv11uWbd++HYVCwYwZM25JGVq2bMn69esrLNPpdHh6enLkyJF/fdwdO3YQFhb2H0tXc3344YdMmDChuotxUzVs2JDg4GDCwsIIDg5mwYIFlnWRkZGMHj3a6v7Lly/nnnvuqfR1duzYgZ2dHWFhYbRu3Zo77riD48ePX3d558yZwzfffGM55qZNm677GGB+31FRUf9q35qusLBQNrO5CWSbshpKCEGJ3njTX8dOo6rSiZWQkMBnn31Gp06dLMuef/55OnXqxKZNmzh06BDDhg0jPj4ejUYDwC+//GK5kE6aNImuXbtaLnSpqakAmEwmxo0bx2effUavXr1YtGgRM2bM4KeffrrB7/TmEEJQYii5qa9hp7ar0mcUEBDAunXrGDFiBADLli2jXbt2N7Vsl5s8eTJffvkld911l2XZunXr8PPzIzw8vErHKO95rFRW//2iwWBArb69L5FCCAy6m9ubW21TtYbUP/zwA2FhYSQlJdGyZUt69+5Nhw4daNeuHT/88MMNK09wcLAlEXrnnXeYOHEihw8frvL+BoOBV1991fL3jh07yM3NZeDAgTesjDdTbfje1mXyk6uhSvRGWs75/aa/TsyrA7C3sf41MJlMTJkyhQ8++ICZM2dalv/444/ExcUB0L59e3x8fPjzzz/p27cvYP5B3rx5M3FxcURGRrJq1SrLvt7e3gAcPnwYtVpNr169AHj44Yd5+eWXKS0txdbW9oa+15uhxFBCx2873tTXODD2APYa+0q3mzhxIl988QUjRowgLy+P/fv3c99991FQUGDZZtGiRfz4448YDAa8vLxYunQpgYGBbN261RJ3nU7H008/zeTJkwGYMGECWq2WuLg4Ll26RKtWrfj++++xsbGp8Prjx4/nlVdeITMzEw8PDwC++OILJk+ezIkTJ5g+fTrFxcWUlpYyduxYXn75ZQDmzp3LiRMnKCws5NKlS2zevBlfX98qxeZq78fT0xN/f3+io6Mt37O5c+eSl5fH4sWLOXv2LDNmzCA9PZ2ysjKmTp3KY489Bpg72cyZM4eNGzfSs2dPHnjggWuWu6CggClTpnDs2DE8PT1p2bIlZWVlLF++3Gqsy/eLiorC09OTkJCQKr3Xf8OgM/Hpk3/etOMDTH2vBxqtqsrb+/r60rx5cy5cuECHDh3YsWMHM2bMICoqioyMDMaNG0dKSgoKhYKIiAi+/PLLCvsnJydz9913M336dCZNmmT1tQYOHMicOXMwGAzceeedZGVlUVJSQps2bfjss89wcHBgx44dPProo3Tq1InDhw/z0ksvsWHDBsLCwujZsydLlizBaDSyY8cOhg8fTnp6Oj4+Prz44osAxMbG0rdvX+Lj46ucDB06dIhZs2aRn5+P0WjkxRdfZNSoUTz00EMEBwfzzDPPABAfH0/nzp25dOkSALNnz2bbtm3odDqaNWvG0qVLcXNzY8KECSiVSuLi4khPT+f06dOMGzeO2NhYdDod/v7+LFu2zHI+LF26lLfffhtHR0eGDRvGnDlzLI3ir1W28v0WLVqEo6Mjw4cPr+InLl2P6r8dlWq8d955h65duxIREWFZlpWVhV6vt5zkYK6qv3jxIgBnz57F2dkZb29vYmJi8PPzY/r06URERNC/f3+OHj0KwMWLFwkMDLQcw8nJCWdnZ5KTk2/Ru6s9unbtSkJCAsnJyXz33XeMGjUKlervH8tvv/2W2NhY9u3bx5EjRxg3bhyPPPIIAOHh4ezevZujR4+ya9cuXn31VRITEy37RkVF8euvv3Lq1CnS0tIqJNjlvLy8GDBgACtXrgQgKSmJnTt3Mm7cOBo2bMjWrVs5cuQIhw8fZtWqVezfv9+y7759+/jqq6+IiYmpckJ2rfdjb2/PiBEjLOUQQrBixQomTZqE0Wjkvvvu4+233+bQoUPs37+fTz/9lEOHDlmOq1KpOHToEG+99ZbVcr/66qvY2dlx6tQpNm7cyN69e6sU61dffRWtVsvp06fZsGHDFY/9a7vTp0+TlZVFz549r1i3cuVKgoKCOHHiBMePH+ftt9+usP7EiRP069ePN954o9KEDOD7778nIiIClUrFt99+S2RkJCdPnsTFxYUPPvjAst2pU6d44IEHiIqKsiQgAGFhYUybNo1x48YRFRXFnDlzePzxx/n0008xGs1PMj7++GOmTp1a5YQsNzeXqVOn8s033xAZGcnmzZuZOXMmSUlJTJw40ZLUg/mx7bhx49BoNLz11ls4ODhw8OBBoqKiCA0NtdwggPkGd8OGDZw+fRqAd999l8jISI4fP063bt2YO3cuACdPnmTu3Lns3LmTI0eOYDAYqlS2kydP8sorr7Bz506OHj1KScnNfUJQV8mashrKTqMi5tUBt+R1rDl58iSrVq267h+Oyx9dGgwGDh48yPz581m6dCm//fYbd911FwkJCf+y1DWHndqOA2MP3PTXqKrx48ezfPly1qxZwzfffGN5XAywZs0aDh06ZEmuy39UwJxkT548mTNnzqBWq8nKyuLkyZP4+fkBMGzYMOztzbV1HTp04Ny5c1d9/cmTJ/PCCy8wY8YMVqxYwdChQ3FzcyM9PZ1HHnmEqKgolEolly5dIioqyvI4fPDgwdSvX/+64mLt/UycOJEpU6bwzDPPsGPHDtzd3QkNDSUmJobo6GjGjBlj2bagoICYmBjat28PUOHHvqSk5Jrl3rp1K4sXL0ahUODk5MTo0aMtNcfWynb5fi4uLowdO/aa8fyv1DZKpr7X46Yc+/LXqIrRo0ejVCqJjY1l8eLFeHp6XrFNp06dWLx4MTNnzqR79+4VHhlGR0czdOhQ1qxZQ5s2ba75OrGxsZY2iM2aNWPFihUIIVi8eDEbNmzAYDCQl5dHly5dLPs0atSIHj2qFqfg4GBatmzJ2rVrGTBgAN999x0nTpyo0r4Ae/fu5fz585b2tpeXu3fv3hgMBg4dOkS7du346quv+PXXXwHzdyovL89yQ6TT6WjYsKFl/1GjRuHk5GT5+9tvv+Xrr7+mtLSU0tJSS+31tm3bGDhwoOWG+qGHHrI8rrVWtpMnTzJo0CAaNGgAwPTp03nzzTer/L6lqpFJWQ2lUCgqfax4K+zatYuEhASaNm0KmNuCTZ06lXnz5qFWq0lNTbWc3AkJCQQEBADmC8iKFSsAc1snX19fyyPKQYMGodPpuHDhAgEBAVy4cMHyegUFBeTl5eHj43Mr3+a/plAoqvRo8VZ54IEHCA8Pp1mzZpbPrJwQghdeeIGpU6desd+0adMYPHgwq1atQqFQEB4eTmlpqWX95Y+SVSqV5e66S5cuFBcXo9VqOXDgAAMGDGDq1KlERkayfPlyPvnkEwBefPFFPDw8OHr0KGq1muHDh1c4vqOj43W/V2vvp3PnzphMJg4ePMjy5cuZOHGiZZ969epZbXx9eVkqK/flLm9XZa1s1va70RQKxXU9WryZytuUbdmyhSFDhtC7d29CQ0MrbNO5c2eioqLYsmULq1evZvbs2ZZadR8fH8rKyti2bZvVpOzyNmXlVq5cybZt2/jzzz9xdnbm/fffZ9u2bZb11/v9e/LJJ1m4cCEZGRn069fvum4ohBCEhIRUqFm93MSJE/nyyy8pLCzEw8ODVq1aWfb74IMP6N+//1X3u/w97N69m/fff599+/bh5eXFunXrmDNnzlX3++f39lplO3ny5DX3k24c+fhSsmr69OmkpKSQkJBAQkICnTp14tNPP2X69OmMGjWKJUuWAOZ2CElJSfTo0YOUlBQKCwstSUFERATOzs6WXlAHDx5ECIG/vz8RERHo9Xq2b98OmNssDBky5LZoT1YT+fj48Oabb7Jw4cIr1t1zzz0sWbKE7OxsAPR6veUHLycnh8DAQBQKBTt37uTYsWNVer29e/cSFRXFgQPm2kKVSsWECROYPn06BoOB3r17W47v5+eHWq0mNjaWzZs3/+f3au39gPnH7YMPPmDDhg2MHTsWMP9gOzs7V2inFBcXZznGP1krd+/evS21MIWFhfz4449VKlvfvn358ssvEUKQn5/Pd999959jcTvp27cv06dPr/DorVx8fDyOjo7ce++9fPDBB5w5c4bCwkIA3Nzc2Lx5M2vWrKnQEL8qcnJy8PDwwNnZmYKCggqPCCvj7OxMXl5ehWX9+/cnNTWV119/3dIesaq6dOlCfHw8W7ZssSyLiopCp9MB5trun376iSVLllSotb3nnntYvHgxxcXFABQXFxMdHX3V18jJycHJyQl3d3d0Oh1Lly61rOvVqxe///476enpgLlDUFXK1rt3bzZt2mTppFV+7ZdurOqvipFuWwsXLmT8+PE0bdoUGxsbVq5ciUajYe3atQwdOtSynUKhYMWKFTz00EOUlJSg1WpZtWoVWq0WMN/FPvzww5SWluLj48PXX39dXW+pViivFfqncePGkZWVZamxNBgMTJo0ibZt27JgwQIeeeQRXnvtNcLCwujY8d93Xpg0aRLz589n3rx5lrvpl19+mfHjx7NixQoaN25sSdaqqrxdYrnOnTvz008/XfP9gPnHLSAggBEjRuDm5gaAWq1m/fr1zJgxg8WLF2M0GvHw8ODbb7+96utaK/ecOXOYPHkyLVq0wMPDgzZt2uDq6gpYj/Xs2bOZMmUKzZs3x9PTkzvuuIOysrLrisftbvbs2TRp0uSKXpE7duzgnXfesdTGvvXWW7i4uFjWOzk5sWnTJoYNG8azzz7LW2+9VaXXe+CBB1i7di3BwcF4enrSrVu3CjX01gwbNoyvv/6asLAwhg8fzpw5c1AoFEyePJlvv/2Wzp07W91/wIABlh7pAPv372fDhg0888wzzJw5E71eT0BAgGWoIR8fHzp06MC6desqJFOzZs2irKyMjh07Ws6rWbNmXbWjyMCBA1m5ciXBwcG4u7vTt29fy1BD5W3RunbtipOTEwMHDrTE2M3N7Zpla9WqFXPnzqVbt26yof9NpBC34zwEtdTtOlfXPw0cOJDXX3/9lg7HIEm3ml6vx2g0YmtrS1FREQMGDODxxx+vdMwtqXa46667GD16NOPHj6/uoly3goICS/uz9957j02bNvHbb79Vc6lurNv191QmZTXI7folkqS6KD09nUGDBmE0GiktLeXuu+9mwYIF8tyt5SIjIxkzZgwtW7bkl19+qdDD+Xbx6KOPsmfPHvR6PT4+PixdupRGjRpVd7FuqNv191QmZTXI7folkiRJkqSa5Hb9PZUN/SVJkiRJkmoAmZRJkiRJkiTVADIpkyRJkiRJqgFkUiZJkiRJklQDyKRMqlTDhg3x8vJCr9dblm3fvh2FQsGMGTNu+uu3bNmS9evXV1im0+nw9PTkyJEjN/31bwcNGzYkODiYsLAwgoODWbBggWVdZGRkpcM0LF++3DItljU7duzAzs6OsLAwWrduzR133GEZFPh6zJkzxzIF1I4dO9i0adN1H0O6fVz+/WzRogVjx46lqKjoprzWjh07LNMs3Uo9e/a0jDX2b61du5YWLVoQFhZ2xdRNb7zxBmFhYZb/nJ2defrpp4GK52X5f+VzU/5zXUhICJ999tl/KifAzz//zPTp00lISEChUHD33XdXWP/KK6+gUCj+c0yWL19umc+z/O+qXKtuVzIpk6okICCAdevWWf5etmzZLRuHbPLkyRVGYAdYt24dfn5+hIeHV+kYJpMJk8l0M4pXY/zwww9ERUWxbds23nzzTQ4ePAhAu3bt+OGHH27Y65RPY3P8+HGGDx9+zcFqr8VgMPDqq68ybtw4QCZldUX59zM6Opq8vLzrGlW/prt8btP/YsmSJcyZM8cy4fjlXnrpJaKioiwzaGg0Gss5BH+fl+X/2dnZXXXd77//zmOPPUZBQcF/Kuvl8xu7uLhw5swZ0tLSAPP19rvvvrviPfwb/0zKajuZlNVUQoCu6Ob/V8URUSZOnMgXX3wBQF5eHvv3768wWfCiRYvo0KED4eHhDBw40DJa9tatW+ncuTNt27YlJCSkwpQeEyZM4OGHH6ZPnz40a9aM4cOHW6Yaudz48eP5/fffyczMtCz74osvmDx5MidOnOCOO+4gPDycli1b8vrrr1u2mTt3LiNGjGDAgAG0atWKlJSU6/sMqkAIgam4+Kb+d72j1vj6+tK8eXPLZ3B5zUFGRgb9+/cnNDSU1q1bXzWhSk5Opn379pbP25qBAwcSGxuLwWBgwIABtGvXjpCQkAo1ITt27CAkJITJkycTFhbGL7/8woQJE3j33XeJiopiyZIlfPPNN4SFhfHqq6/y2GOPMX/+fMtrxMbG4u/vb5lvU6o6IQT60tKb+t/1fj91Oh3FxcWWWRbg2tePuXPnMnr0aIYMGULLli3p3bt3hSmxFi5cSGhoKG3atKFTp06WKYgMBgOPPPIIbdq0ISQkhMjISMA8P6+rqyuzZ88mPDycpk2bsmfPHp566inCwsJo1aqVZY7H1NRUevXqRUREBCEhITz22GOWG7vly5fTq1cvRowYQWhoqOUGqNyqVato06bNVSeaj4uLo2/fvrRu3ZqwsDBLTdITTzzBrl27ePHFFytMln41a9assUxTd73y8/NxcHCwzDLQs2dPHn/8cdq3b0+TJk2YOXOm5TN9/fXXLTV3YWFhls9Fr9ezZ8+eCjNc3H///Xz11VcAbNmyhbZt21KvXj3L+vT0dIYPH05oaCitWrWqMFtBw4YNmTNnDp07dyYoKMhyHf/888+JjIy0fD4bN24EoLCwkPvuu4/Q0FDatWvH+fPnrzsONZWcZqmm0hfD/FswKfeLyWDjUOlmXbt25eOPPyY5OZl169YxatQoy6CJ3377LbGxsezbtw+VSsXXX3/NI488woYNGwgPD2f37t2oVCqys7Np27YtAwYMsEyZExUVxfbt29FqtXTv3p1Vq1Zx3333VXhtLy8vBgwYwMqVK5kxYwZJSUns3LmTb775BrVazdatW9FqtZSUlNClSxf69u1Lp06dANi3bx9Hjx69rgmDr4coKSE2/PovjNcj+MhhFPZVn/T89OnTZGVl0bNnzyvWrVy5kqCgIP744w+AK+Z8PHHiBGPGjGHx4sXXnPj4ct9//z0RERGoVCq+/fZb3N3dEULwyCOP8MEHH/D8888DcOrUKT7++GNLUr5hwwYAwsLCmDZtGrm5ubz77ruAOQkbMGAAs2bNQqVS8fHHHzN16lTUanm5ul6GsjLef3DkTX2NJ1b8jKYKc9WOHj0aOzs7EhISiIiI4N577wWsXz8ADhw4wOHDh3F3d2fMmDEsXbqUF154gRUrVrBq1Sp2796Ni4sLOTk5lqnbTp8+zbJly/j4449ZsmQJL730Er///jtgvqmMiIjgtddeY9myZQwYMIBff/2VxYsX89ZbbzFv3jx++uknXF1d+fXXX3F0dMRoNHL33Xfz448/MmbMGEu5jh49SnBwcIX3+c477/DLL7+wbds23N3dr4jDuHHjmDRpEg8//DBnz56lU6dOtG3blvfff5/jx48zY8aMSh/PLVu2jMmTJ1dYdu7cOcLDw1GpVEycOJFHHnnEsi42NpawsDB0Oh3nzp3jgw8+qDC/cExMDHv37kWv19O9e3e+++47Bg0axKJFi0hJScHOzo7i4mKUSnM9zvbt2+nSpUuF6aMefPBBBg4cyLPPPssXX3zBpEmTePPNNy3rH3/8cYKDg1m9ejXp6elERERYkmmA3Nxc9u3bR2ZmJo0bN2bixIlMmTLFct0vj8ny5cs5dOgQUVFRBAUF8fzzz7Nw4cIKSd7tTNaUSVU2fvx4li9fbjnhyq1Zs4YtW7YQERFBWFgY//vf/7h48SIAWVlZjBo1ilatWtG7d2+ysrIsd6JgnlfO3t4elUpFhw4drnpnCRUfYa5YsYKhQ4fi5uZGSUkJU6ZMITQ0lE6dOnHhwgWioqIs+w0ePPimJWQ1zejRo2nRogUtW7bk8ccfx9PT84ptOnXqxG+//cbMmTNZu3YtDg5/J+TR0dEMHTqUb7/91mpCVn6BDwsL4/Tp05ZJuRcvXkzbtm1p3bo1GzZsqPA5NGrUiB49elTpfQQHB9OyZUvWrl1LUVER3333HVOnTq16IKQaqfzxZWZmJg0bNmTWrFmA9esHmGtjy5Obzp07W64R69evZ9q0aRXmbSy/UWzSpIll/tbL9wGwtbW1/MC3a9cOR0dHyxylHTp04OzZs4D5EdysWbNo06YNbdu2JTIyssJ3ukuXLlckZK+//jpbt25l8+bNV03ICgoKOHLkiCWhatq0KXfccQe7du2qchwvXLjA7t27Kzy6DA8PJzExkSNHjvDLL7+wZMkSfvzxR8v68seXMTExnDt3jjfeeKNCe9wHHngAjUaDvb09999/P1u2bMHZ2ZmmTZty//33s3TpUrKzsy2J3Jo1axg2bFiFcvn5+eHn58f69es5fPgw/fr1q7B+y5YtPPzww4D5Rnv48OEVJj4fO3YsAB4eHjRq1Ij4+PhrxqC8Rq3839f63bgdyVvPmkpjb67FuhWvU0UPPPAA4eHhNGvWjKZNm1qWCyF44YUXrvrDOW3aNAYPHsyqVatQKBSEh4dTWlpqWX/53Vr5JMRgvuAVFxej1Wo5cOAAAwYMYOrUqURGRrJ8+XI++eQTAF588UU8PDw4evQoarWa4cOHVzi+o6Nj1WPxLyjs7Ag+crjyDf/ja1TFDz/8QFhYGFu2bGHIkCH07t37ijYdnTt3Jioqii1btrB69Wpmz57N0aNHAfNEyGVlZWzbto02bdpc83XKL/CXW7lyJdu2bePPP//E2dmZ999/n23btlnWX+/n8OSTT7Jw4UIyMjLo169fnUmsbzS1VssTK36+6a9xXdur1YwY8f/27iWkjTWKA/h/Yi6GqlnZIhJ0oSIqgnZjfUQEoyufvVFbNPVRKEkRCm1d+QAfPa63CAAABO9JREFUqFVUaAvNQhSxPkAUBRe2PlERLYq46EIp7cr6oo2SFhGD3oU4t6kaE63ciff/gwGZcTIzZPy+k3POmL9RVFSEhoYGm+MHcPYYYYutfVx/OV8XF5czf7exsRGbm5uYm5uDQqHA06dPzx1bIiIi8P79e3z+/BnBwcHnnicAh//bfGtrK1JTU61Kg0qlUvxZpVLh/v37mJqaErORv1KpVIiIiMDo6OiZPbmCIMDFxQWzs7OYmZnBxMQE7ty5g66uLsTExODdu3eoq6s7sV9+fj7y8/Oh1+vFrNpZfr9uR97ni9wTzoKZMqkShKOy4lUvDgwI3t7eqKmpwYsXL6zWp6WlwWg0iqWw/f19caI3mUzw9fWFIAiYnJzE0tKSXceamZkRG1qBoz+8vLw8GAwGWCwWsZfBZDJBpVJBLpdjeXkZw8PDdl/PnyAIAmQ3blzp4uigrdFoYDAYUFJScmLbly9f4O7ujszMTLx69QorKyv48eMHgKNMw/DwMPr7+1FRUeHQMU0mEzw9PaFUKmE2mx1q4lYqldjZ2bFal5iYiPX1dVRVVaGwsNChc6F/CYKAvxSKK10u8hU2Y2NjYpbJ1vhhS0pKCoxGo3jvbG9v/7GGe+Donvby8oJCocD6+jp6enrO3SchIQEtLS1ITk4+9clwDw8P3L59W8z6f/r0CdPT04iNjbXrnA4ODtDa2nqidLm2tib2u5nNZgwODiI8PPzU19jZ2cHCwoJVlu/t27fY39/H7u4uOjs7odFoYDabsbGxAbVajdLSUsTExGBxcREfPnxAUFDQqUFpWloanj9/Dr1ef2KbRqMRn/rc2tpCX1/fiWzaaU4bH64zZsrIIac1hmdnZ+Pbt29iCcBisaCgoADh4eGora3F48ePUVlZibCwMLGkcBEFBQWorq5GeXm5OBGUlJRAp9Ohra0Nfn5+Vo2n/2elpaXw9/fHwoJ1Fm9iYgKNjY3ip8v6+nqx/AMcTRpDQ0NIT09HUVER6uvr7TregwcPMDAwgMDAQNy8eRNqtVpsCj5Peno62tvbERYWhrt376KsrAyCIODhw4fo7OxEZGSk/RdOknXcU2axWODr6wuj0QjA9vhhi06nw9evXxEVFQW5XA43NzercthlPXnyBFqtFiEhIfD29oZGo7FrP7Vaje7ubmi1WrS3tyM6Otpqe0dHB/R6PV6/fg1BENDc3AwfHx+7XntkZAQymQzx8fFW63t7e/HmzRvI5XJYLBZkZGRYjdXHLQcAsLe3h5ycHKSkpIjbg4KCEB0dje/fvyM1NRX37t3D6uoqtFotfv78CUEQEBAQgNzcXNTU1JzZ8+bq6iqWpX/38uVLGAwGhIaG4vDwEMXFxXbNB48ePcKzZ8/Q1NRk9QDQdcUvJJcQZ/0CVaKrkJSUhKysLOh0uv/6VIiurbi4OLseLjgWEhKC8fFx3Lp162pP7JKcdT5l+ZKIJGV+fh7+/v6QyWRi8y8RScPHjx8lH5A5M2bKJMRZI3siIiIpcdb5lJkyIiIiIglgUEZEREQkAXz6UoJYUSYiIro4Z51H2VMmMcd1cCIiIro4Z+snAxiUSRLfEiIiostxtoAMYPlSkpzxRiIiIqLLYaM/ERERkQQwKCMiIiKSAAZlRERERBLAoIyIiIhIAhiUEREREUkAgzIiIiIiCWBQRkRERCQB/wBQxrNVXaLX+QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = pd.date_range(test3[\"Date\"][0],test3[\"Date\"][len(test3[\"Date\"]) -1 ], freq = 'ME')\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.plot(time,test3[\"R_40/60\"], label=\"40/60\")\n",
    "ax.plot(time,test3[\"R_MV\"], label=\"Mean-Var\")\n",
    "ax.plot(time,test3[\"R_MVL\"], label=\"Mean-Var Leveraged\")\n",
    "ax.plot(time,test3[\"R_RP\"], label=\"Risk Parity\")\n",
    "ax.plot(time,test3[\"R_RPL\"], label=\"Risk Parity Leveraged\")\n",
    "ax.plot(time[initial_fits:], [(mu_target+1)**t for t in range(0,len(time)-initial_fits)],\n",
    "         label = \"Benchmark of 75Bps/Month\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(5))  # Set a tick at the start of every year\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.legend(framealpha=0.05,loc='center', bbox_to_anchor=(0.5, -0.5), ncol=3,prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Cumulative return\")\n",
    "plt.title(\"Entire Period: 1990-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:551: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_24228\\3834158626.py:18: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_fits = 3\n",
    "\n",
    "test3, w0t,w1t,w2t  = bt.backtest_naive(ind=data_ol, mu_target=mu_target) \n",
    "time = pd.date_range(test3[\"Date\"][0],test3[\"Date\"][len(test3[\"Date\"]) -1 ], freq = 'ME')\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "ax.plot(time,test3[\"R_40/60\"], label=\"40/60\")\n",
    "ax.plot(time,test3[\"R_MV\"], label=\"Mean-Var\")\n",
    "ax.plot(time,test3[\"R_MVL\"], label=\"Mean-Var Leveraged\")\n",
    "ax.plot(time,test3[\"R_RP\"], label=\"Risk Parity\")\n",
    "ax.plot(time,test3[\"R_RPL\"], label=\"Risk Parity Leveraged\")\n",
    "ax.plot(time[initial_fits:], [(mu_target+1)**t for t in range(0,len(time)-initial_fits)],\n",
    "         label = \"Benchmark of 75Bps/Month\")\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(5))  # Set a tick at the start of every year\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.legend(framealpha=0.05,loc='center', bbox_to_anchor=(0.5, -0.5), ncol=3,prop={'size': 8})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Cumulative return\")\n",
    "plt.title(\"Entire Period: 1990-2023\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
